
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/image_lib.ipynb

import matplotlib.pyplot as plt
import numpy as np
import math, random


import torch

class ShowImg():
  # ----------------------------
  # Can display both image tensors and PIL image objects
  # ----------------------------
  @staticmethod
  def show_image(img, ax):
    #if ax is None: _,ax = plt.subplots(1, 1, figsize=figsize)
    ax.axis('off')
    if (isinstance(img, torch.Tensor)):
      img = img.permute(1,2,0)
    ax.imshow(img)

  # ----------------------------
  # ----------------------------
  @staticmethod
  def show_label(label, ax):
    ax.set_title(f'{label}')

  # ----------------------------
  # ----------------------------
  @staticmethod
  def show_mask(mask, ax):
    #!!!! what about OCV mask !!!! mask = mask.convert('RGBA')
    ax.imshow(mask, alpha=0.7, cmap="Reds")

  # ----------------------------
  #
  # ----------------------------
  @classmethod
  def show_grid(cls, x_imgs, y_labels, z_data=None, x_method=None, y_method=None, z_method=None, num_cols=10, figsize=None, **kwargs):
    assert(len(x_imgs) == len(y_labels))
    x_method = cls.show_image if (x_method is None) else x_method
    y_method = cls.show_label if (y_method is None) else y_method
    z_method = cls.show_label if (z_method is None) else z_method

    num_imgs = len(x_imgs)
    num_rows = int (math.ceil (num_imgs / num_cols))
    if (figsize is None):
      figsize=(num_cols * 3, num_rows * 3)
    fig,axes = plt.subplots(num_rows, num_cols, figsize=figsize)

    for img, label, ax in zip (x_imgs, y_labels, axes.flat):
      x_method(img, ax)
      y_method(label, ax)
      #self.show_image(img, ax)
      #self.show_label(label, ax)

    for i in range(len(x_imgs), len(axes.flat)): axes.flat[i].set_visible(False)


import PIL
from PIL import Image
import torch
from torch import tensor

class PilImg():
  #------------------------------------------------------
  # Get (width, height) of the image
  #------------------------------------------------------
  @staticmethod
  def pil_shape(img):
    w, h = img.size
    return w, h

  #------------------------------------------------------
  # Load the file as an image
  #------------------------------------------------------
  @staticmethod
  def pil_open (file):
    img = PIL.Image.open(file)
    return (img)

  #------------------------------------------------------
  # Convert image to RGB format
  #------------------------------------------------------
  @staticmethod
  def pil_rgb (img):
    img_rgb = img.convert('RGB')
    return (img_rgb)

  #------------------------------------------------------
  # Resize image
  # PIL.Image.NEAREST (use nearest neighbour), PIL.Image.BILINEAR (linear interpolation), or PIL.Image.BICUBIC (cubic spline interpolation)
  #------------------------------------------------------
  @staticmethod
  def pil_resize(img, newsz, resample=PIL.Image.BILINEAR):
    assert(isinstance(newsz, tuple) and (len(newsz) == 2))
    assert(resample in [PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC])
    img_rsz = img.resize(newsz, resample=resample)
    return (img_rsz)

  #------------------------------------------------------
  # List of Flip-Rotate transforms
  #------------------------------------------------------
  pil_fr_types = {
      'rotate_90': PIL.Image.ROTATE_90,
      'rotate_180': PIL.Image.ROTATE_180,
      'rotate_270': PIL.Image.ROTATE_270,
      'fliv_h': PIL.Image.FLIP_LEFT_RIGHT,
      'fliv_v': PIL.Image.FLIP_TOP_BOTTOM,
      'transpose': PIL.Image.TRANSPOSE,
      'transverse': PIL.Image.TRANSVERSE
  }

  #------------------------------------------------------
  # Apply Flip-Rotate transform
  #------------------------------------------------------
  @classmethod
  def pil_flip_rotate(cls, img, fr_type):
    assert (fr_type in ['rotate_90', 'rotate_180', 'rotate_270', 'fliv_h', 'fliv_v', 'transpose', 'transverse'])
    fr_code = cls.pil_fr_types[fr_type]
    fr_img = img.transpose(fr_code)

    return (fr_img)

  #------------------------------------------------------
  # Crop image
  #------------------------------------------------------
  @staticmethod
  def pil_crop(img, newsz, crop_corners, resample=PIL.Image.BILINEAR):
    assert(isinstance(newsz, tuple) and (len(newsz) == 2))
    assert(isinstance(crop_corners, tuple) and (len(crop_corners) == 4))
    assert(resample in [PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC])
    img_crop = img.transform(newsz, PIL.Image.EXTENT, crop_corners, resample=resample)
    return (img_crop)

  #------------------------------------------------------
  # Perspective transform
  #------------------------------------------------------
  @staticmethod
  def pil_perspective(img, newsz, matrix, resample=PIL.Image.BILINEAR):
    assert(isinstance(newsz, tuple) and (len(newsz) == 2))
    pers_img = img.transform(newsz, PIL.Image.PERSPECTIVE, list(matrix), resample=resample)

    return (pers_img)

  #------------------------------------------------------
  # Convert image to a tensor of bytes
  #------------------------------------------------------
  @staticmethod
  def pil_byte_tensor(img):
    # PIL .tobytes() converts the image object to raw data, one byte per pixel
    res = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))
    w,h = img.size
    return res.view(h,w,-1).permute(2,0,1)


import cv2
import imageio
import torch
from torch import tensor

class OcvImg():
  #------------------------------------------------------
  # Get (width, height) of the image
  #------------------------------------------------------
  @staticmethod
  def ocv_shape(img):
    h, w, d = img.shape
    return w, h

  #------------------------------------------------------
  # Load the file as an image
  #------------------------------------------------------
  @staticmethod
  def ocv_open (file):
    if (str(file)[-4:] == '.gif'):
      # OpenCV doesn't support .gif codec. So read the file into a numpy array
      # with ImageIO and convert from RGB to BGR, so that it is in OpenCV format
      img = imageio.imread(file)
      img = img.astype('float32')
      #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
      return (img)

    img = cv2.imread(str(file))
    return (img)

  #------------------------------------------------------
  # Convert image to RGB format
  #------------------------------------------------------
  @staticmethod
  def ocv_rgb (img):
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return (img_rgb)

  #------------------------------------------------------
  # Resize image
  # To shrink an image, it will generally look best with INTER_AREA interpolation,
  # whereas to enlarge an image, it will generally look best with INTER_CUBIC (slow)
  # or INTER_LINEAR (faster but still looks OK)
  #------------------------------------------------------
  @staticmethod
  def ocv_resize(img, new_sz, interpolation=cv2.INTER_LINEAR):
    assert(isinstance(new_sz, tuple) and (len(new_sz) == 2))
    img_rsz = cv2.resize(img, new_sz, interpolation=interpolation)
    return (img_rsz)

  #------------------------------------------------------
  # List of Flip-Rotate transform
  #------------------------------------------------------
  ocv_fr_types = {
      'rotate_90': [(cv2.rotate, cv2.ROTATE_90_CLOCKWISE)],
      'rotate_180': [(cv2.rotate, cv2.ROTATE_180)],
      'rotate_270': [(cv2.rotate, cv2.ROTATE_90_COUNTERCLOCKWISE)],
      'fliv_h': [(cv2.flip, 1)],
      'fliv_v': [(cv2.flip, 0)],
      'transpose': [(cv2.rotate, cv2.ROTATE_90_CLOCKWISE), (cv2.flip, 1)],
      'transverse': [(cv2.rotate, cv2.ROTATE_90_COUNTERCLOCKWISE), (cv2.flip, 1)]
  }

  #------------------------------------------------------
  # Apply Flip-Rotate transform
  #------------------------------------------------------
  @classmethod
  def ocv_flip_rotate(cls, img, fr_type):
    assert (fr_type in ['rotate_90', 'rotate_180', 'rotate_270', 'fliv_h', 'fliv_v', 'transpose', 'transverse'])
    for fr_fn, fr_code in cls.ocv_fr_types[fr_type]:
      img = fr_fn(img, fr_code)

    return (img)

  #------------------------------------------------------
  # Crop image
  #------------------------------------------------------
  @staticmethod
  def ocv_crop(img, new_sz, crop_corners, interpolation=cv2.INTER_LINEAR):
    assert(isinstance(new_sz, tuple) and (len(new_sz) == 2))
    assert(isinstance(crop_corners, tuple) and (len(crop_corners) == 4))
    assert(interpolation in [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC, cv2.INTER_LANCZOS4])
    tl_x, tl_y, br_x, br_y = crop_corners
    img_crop = img[tl_y:br_y, tl_x:br_x]
    img_crop = cv2.resize(img_crop, new_sz, interpolation=interpolation)
    return (img_crop)

  #------------------------------------------------------
  # Perspective transform
  #------------------------------------------------------
  @staticmethod
  def ocv_perspective(img, new_sz, src_coords, targ_coords, interpolation=cv2.INTER_LINEAR):
    assert(isinstance(new_sz, tuple) and (len(new_sz) == 2))
    matrix = cv2.getPerspectiveTransform(np.float32(src_coords), np.float32(targ_coords))
    # Switch source and target for OpenCV to get the same matrix coefficients as for PIL
    #cv2d_flip = cv2.getPerspectiveTransform(np.float32(targ_d), np.float32(src_d))
    pers_img = cv2.warpPerspective(img, matrix, new_sz)

    return (pers_img)

  #------------------------------------------------------
  # Convert image to a tensor of bytes
  #------------------------------------------------------
  @staticmethod
  def ocv_byte_tensor(img):
    img_bytes = torch.from_numpy(img.transpose((2, 0, 1)))
    return (img_bytes)


# Take a crop from the original image and then resize that crop to a given 'final_sz', as
# all final images should be the same size
def imgaug_random_resized_crop(orig_sz, crop_area_range=(0.08, 1.0), crop_aspect_range=(3./4., 4./3.), crop_pos='random'):

  # We are given three parameters to calculate the position and size of the cropped image
  #   1. The area of the crop as a percentage of the original image
  #         We are given a range of percentages and pick one at random
  #   2. The aspect ratio of the crop
  #         We are given a range of aspect ratios and pick one at random
  #         If no range is given, we take the aspect ratio of the original image
  #   3. The position of the crop within the original image
  #         We either centre the crop within the original image, or find a position at
  #         random
  assert(isinstance(crop_area_range, tuple) and (len(crop_area_range) == 2))
  assert((crop_area_range[0] > 0) and (crop_area_range[0] <= crop_area_range[1]) and (crop_area_range[1] <= 1.))
  assert(crop_aspect_range is None or
         (isinstance(crop_aspect_range, tuple) and (len(crop_aspect_range) == 2)))
  assert(crop_aspect_range is None or
         ((crop_aspect_range[0] > 0.5) and (crop_aspect_range[0] < crop_aspect_range[1]) and (crop_aspect_range[1] < 1.5)))
  assert(crop_pos in ['random', 'ctr'])

  orig_w, orig_h = orig_sz
  orig_area = orig_w * orig_h
  min_crop_area_pct, max_crop_area_pct = crop_area_range
  if (crop_aspect_range is not None):
    min_crop_aspect, max_crop_aspect = crop_aspect_range
  else:
    orig_aspect_ratio = orig_w / orig_h

  # Try 'num_attempts' times to get a proper crop inside the image
  num_attempts = 10
  for i in range(num_attempts):

    # Get the crop area as a random percentage of the original image area
    crop_area = random.uniform(min_crop_area_pct, max_crop_area_pct) * orig_area

    # Get the crop aspect ratio
    if (crop_aspect_range is not None):
      # Get a random crop aspect ratio within the given range
      crop_aspect = math.exp(random.uniform(math.log(min_crop_aspect), math.log(max_crop_aspect)))
    else:
      # No range has been provided, so the crop aspect ratio will be the same as the original image
      crop_aspect = orig_aspect_ratio

    # Calculate crop width and height from the crop area and aspect ratio
    #   crop_aspect = crop_w / crop_h
    #   crop_area = crop_w * crop_h
    crop_w = int(round(math.sqrt(crop_area * crop_aspect)))
    crop_h = int(round(math.sqrt(crop_area / crop_aspect)))

    # If the crop dimensions fit within the original image, get the crop position
    if (crop_w <= orig_w and crop_h <= orig_h):

      if (crop_pos == 'random'):
        # Get a random (left, top) position
        crop_pos_l = random.randint(0, orig_w - crop_w)
        crop_pos_t  = random.randint(0, orig_h - crop_h)

      elif (crop_pos == 'ctr'):
        # Get the (left, top) position if the crop is centred
        crop_pos_l = (orig_w - crop_w) // 2
        crop_pos_t = (orig_h - crop_h) // 2

      # Crop (right, bottom) position
      crop_pos_r = crop_pos_l + crop_w
      crop_pos_b = crop_pos_t + crop_h

      # Return coordinates
      return (crop_pos_l, crop_pos_t, crop_pos_r, crop_pos_b)

  # We weren't able to get an appropriate crop after all our attempts
  # So we fallback to squishing
  #
  # We will only get here if a crop aspect range was given and all the
  # random crop aspect ratios that we attempted did not work
  assert(crop_aspect_range is not None)
  if orig_aspect_ratio < min_crop_aspect:
    # Original aspect ratio was lower than minimum ie. image is narrow and tall
    crop_aspect = min_crop_aspect
    crop_w = orig_w
    crop_h = int(crop_w / crop_aspect)

  elif orig_aspect_ratio > max_crop_aspect:
    # Original aspect ratio was higher than maximum ie. image was wide and short
    crop_aspect = max_crop_aspect
    crop_h = orig_h
    crop_w = int(crop_h * crop_aspect)

  else:
    crop_aspect = orig_aspect_ratio
    crop_w, crop_h = orig_w, orig_h

  crop_pos_l = (orig_w - crop_w) // 2
  crop_pos_t = (orig_h - crop_h) // 2
  crop_pos_r = crop_pos_l + crop_w
  crop_pos_b = crop_pos_t + crop_h

  return (crop_pos_l, crop_pos_t, crop_pos_r, crop_pos_b)

from torch import FloatTensor

def _find_coeffs(orig_pts, targ_pts):
    matrix = []
    #The equations we'll need to solve.
    for p1, p2 in zip(targ_pts, orig_pts):
        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])
        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])

    A = FloatTensor(matrix)
    B = FloatTensor(orig_pts).view(8, 1)
    #The 8 scalars we seek are solution of AX = B
    return list(torch.solve(B,A)[0][:,0])

def _warp(final_sz, src_coords):
    w,h = final_sz
    targ_coords = ((0,0),(0,h),(w,h),(w,0))
    coeffs = _find_coeffs(src_coords,targ_coords)
    return coeffs, src_coords, targ_coords

def _uniform(a,b): return a + (b-a) * random.random()

def _default_crop_size(w,h): return [w,w] if w < h else [h,h]

def imgaug_perspective_warp(orig_sz, final_sz, magnitude=0.):
  orig_w, orig_h = orig_sz
  crop_w, crop_h = _default_crop_size(orig_w, orig_h)

  left, top = random.randint(0, orig_w - crop_w), random.randint(0, orig_h - crop_h)
  top_magn = min(magnitude, left / crop_w, (orig_w - left) / crop_w - 1)
  lr_magn  = min(magnitude, top / crop_h, (orig_h - top) / crop_h - 1)

  up_t, lr_t = _uniform(-top_magn, top_magn), _uniform(-lr_magn, lr_magn)
  src_corners = tensor([[-up_t, -lr_t], [up_t, 1+lr_t], [1-up_t, 1-lr_t], [1+up_t, lr_t]])
  src_corners = src_corners * tensor([crop_w, crop_h]).float() + tensor([left, top]).float()
  src_corners = tuple([(int(o[0].item()), int(o[1].item())) for o in src_corners])

  res = _warp(final_sz, src_corners)
  return res

import albumentations as A

albu_augs = {'Vertical Flip': A.VerticalFlip(p=0.5),
             'Horizontal Flip': A.HorizontalFlip(p=0.5),
             'Flip': A.Flip(p=0.5),
             'Random Rotate': A.RandomRotate90(p=0.5),
             'Rotate': A.Rotate(limit=286, p=0.5),
             'Transpose': A.Transpose(p=0.5),
             'Shift Scale Rotate': A.ShiftScaleRotate(shift_limit=0.8, scale_limit=1.4, rotate_limit=360, p=0.5),
             'Center Crop': A.CenterCrop(height=134, width=94, p=0.5),
             'Random Brightness': A.RandomBrightness(limit=1.3, p=0.5),
             'Random Brightness Contrast': A.RandomBrightnessContrast(p=0.5),
             'Random Gamma': A.RandomGamma(p=0.5),
             'Clahe': A.CLAHE(p=0.5),
             'Hue Saturation Value': A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=50, val_shift_limit=50, p=0.5),
             'RGB Shift': A.RGBShift(r_shift_limit=105, g_shift_limit=45, b_shift_limit=40, p=0.5),
             'Channel Shuffle': A.ChannelShuffle(p=0.5),
             'Jpeg Compression': A.JpegCompression(quality_lower=7, quality_upper=100, p=0.5),
             'Random Contrast': A.RandomContrast(limit=0.9, p=0.5),
             'Blur': A.Blur(blur_limit=17, p=0.5),
             'Gauss Noise': A.GaussNoise(var_limit=(10.0, 80.0), p=0.5),
             'Invert Image': A.InvertImg(),
}

def WAIT_imgaug_albu(img, aug_name, p=0.5, **kwargs):
  aug = albu_augs[aug_name]
  aug.p = p
  augmented = aug(image=img)
  return augmented['image']

def imgaug_albu(img, aug_name, mask=None, p=0.5, **kwargs):
  aug = albu_augs[aug_name]
  aug.p = p
  augmented = aug(image=img, mask=mask)
  return augmented['image'], augmented['mask']