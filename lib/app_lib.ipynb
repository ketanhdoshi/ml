{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "app_lib.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuU2oO7RGFVn1C20kSRndx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketanhdoshi/ml/blob/master/lib/app_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOrqHJtJU1ls"
      },
      "source": [
        "## Application utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djleAOicQZYn"
      },
      "source": [
        "**Todos**\n",
        "*   Move Corpus Bleu out of this file?\n",
        "*   Make set_data_path be regular methods not statics. Then you initialise an App object, set all the data paths for the app once, and then use those everywhere without having to pass them in\n",
        "\n",
        "**Done**\n",
        "*   DONE Make AppTabular child of AppBase\n",
        "*   DONE Make ArchTabular child of ArchBase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8UNSFTSWsmg"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHLPROiP6Lpk"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI5e1uoLdVMQ"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx-Xm5ShB3A7"
      },
      "source": [
        "import IPython.core.debugger as db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIU2MWywWrbA"
      },
      "source": [
        "#export\n",
        "\n",
        "from pathlib import Path\n",
        "import math\n",
        "from functools import partial\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QwN17d7_DKe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "gd_path = 'gdrive/My Drive/Colab Data/fastai-v3'  #change dir to your project folder\n",
        "gn_path = 'gdrive/My Drive/Colab Notebooks'  #change dir to your project folder\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, gn_path + '/exp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKg5U6q8WpLD"
      },
      "source": [
        "#export\n",
        "\n",
        "from nb_util import mse\n",
        "from nb_hooks import Hooks, DebugActivationHook\n",
        "from nb_arch import ArchBase\n",
        "from nb_training import Trainer, CudaCB, ProgressCallback, MetricsGrp, LossMetricsCB, DebugTracker, DebugYhatLossCB\n",
        "from nb_optimiser import HyperParams, Recorder, LRRangeFind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsjygTKEfwvV"
      },
      "source": [
        "### Define Text Translation Data Bundle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s95O1BhkMn3"
      },
      "source": [
        "#export\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from nb_data import DataBundle, CSVItemContainer, DfItemList, SentenceItemList, SentenceWordItemList, SentenceWordIdItemList, SortishSampler, SortSampler\n",
        "\n",
        "# ----------------------------\n",
        "# Collate function to convert a list of item tuples into a single tensor which is fed\n",
        "# as input to the model\n",
        "#\n",
        "# 'Samples' is a list of tuples ie. [(x1, y1), (x2, y2), ...] where 'xn' and 'yn' are \n",
        "# both lists of word ids in the sentence. All the sentences could have different lengths, so\n",
        "# after each 'xn' and 'yn' are converted to tensors, they are padded at the end to\n",
        "# make them the same length.\n",
        "# ----------------------------\n",
        "def seq_collate(samples, pad_idx=1, pad_first=False):\n",
        "  # Convert each sample sentence into a tensor and then create two lists of \n",
        "  # tensors ie. [tensor x1, tensor x2, ...] and [tensor y1, tensor y2, ...]\n",
        "  tx, ty = [torch.tensor(s[0]) for s in samples], [torch.tensor(s[1]) for s in samples]\n",
        "\n",
        "  # Use the Pytorch pad_sequence function to pad each sample tensor to the same length and then\n",
        "  # concatenate them into a single tensor. So 'px' and 'py' have shape (samples, max sequence length)\n",
        "  px, py = pad_sequence(tx, batch_first=True, padding_value=pad_idx), pad_sequence(ty, batch_first=True, padding_value=pad_idx)\n",
        "  return px, py\n",
        "\n",
        "#----------------------------------------------------\n",
        "# The custom sampler functions need to take a sort-key-function as an extra argument. \n",
        "# The key function needs the 'data' argument pre-bound using a partial.\n",
        "# \n",
        "# This is a standalone function rather than a lambda function, because pickle is not able to\n",
        "# save lambda functions.\n",
        "#----------------------------------------------------\n",
        "def len_key_fn(i,data): \n",
        "  return len(data[i])\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Text Translation from CSV data preparation pipeline\n",
        "#----------------------------------------------------\n",
        "class TextTranslationCSVDataBundle(DataBundle):\n",
        "  def __init__(self, csv_path, bs):\n",
        "    print ('--------- Text Translation DataBundle init', csv_path)\n",
        "\n",
        "    # Load all rows from the given CSV file\n",
        "    # Split randomly based on a percentage ratio for training and validation\n",
        "    # 'x' items are taken from 'fr' column as text sentences and\n",
        "    # 'y' labels are taken from 'en' column as class name labels\n",
        "    # Convert the 'x' items from Sentences to Words to Word Ids\n",
        "    # Convert the 'y' items from Sentences to Words to Word Ids\n",
        "\n",
        "    load_params = {'source': CSVItemContainer, 'target_cls': DfItemList, 'csv_path': csv_path}\n",
        "    split_params = {'split_procedure': 'split_random', 'train_ratio': 0.8, 'valid_ratio': 0.2}\n",
        "    extract_x_params = {'extract_procedure': 'extract_colval', 'target_cls': SentenceItemList, 'col': 'fr', 'lang': 'fr'}\n",
        "    extract_y_params = {'extract_procedure': 'extract_colval', 'target_cls': SentenceItemList, 'col': 'en'}\n",
        "    convert_x_params = [\n",
        "        {'target_cls': SentenceWordItemList, 'convert_procedure': 'SentenceToWord'},\n",
        "        {'target_cls': SentenceWordIdItemList, 'convert_procedure': 'WordToWordId'}\n",
        "    ]\n",
        "    convert_y_params = [\n",
        "        {'target_cls': SentenceWordItemList, 'convert_procedure': 'SentenceToWord'},\n",
        "        {'target_cls': SentenceWordIdItemList, 'convert_procedure': 'WordToWordId'}\n",
        "    ]\n",
        "\n",
        "    # We use different samples for training and validation. \n",
        "    dl_params = (\n",
        "        {'bs': bs, 'sampler_fn': SortishSampler, 'key_fn': len_key_fn, 'collate_fn': seq_collate},    # for training\n",
        "        {'bs': bs, 'sampler_fn': SortSampler, 'key_fn': len_key_fn, 'collate_fn': seq_collate}        # for valid/test\n",
        "    )\n",
        "    WAIT_dl_params = (\n",
        "        {'bs': bs, 'shuffle': False, 'collate_fn': seq_collate},    # for training\n",
        "        {'bs': bs, 'shuffle': False, 'collate_fn': seq_collate}     # for valid/test\n",
        "    )\n",
        "    self.display_params = {\n",
        "        'layout_procedure': 'display_texts'\n",
        "    }\n",
        "    super().__init__(load_params, split_params, extract_x_params, extract_y_params, convert_x_params, convert_y_params, dl_params=dl_params)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Since we use Sorting Samplers which require a key function (which also requires a partial wrapper)\n",
        "  # we have to override the parent DataBundle with a custom get_sampler() \n",
        "  # ----------------------------\n",
        "  def get_sampler(self, ds, in_train, bs, sampler_fn, key_fn, **kwargs):\n",
        "    key=partial(key_fn, data=ds.x)\n",
        "    # The two sampler functions take different arguments. Since we know the sampler\n",
        "    # functions we can hardcode their names. The sampler_fn that is passed in is the\n",
        "    # same, but we ignore it.\n",
        "    if (in_train):\n",
        "      sampler = SortishSampler(ds.x, key=key, bs=bs)\n",
        "    else:\n",
        "      sampler = SortSampler(ds.x, key=key)\n",
        "    return sampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t1ovSkv-Z0Q"
      },
      "source": [
        "### Bleu Score Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2pXTRx7-dHj"
      },
      "source": [
        "#export\n",
        "\n",
        "from math import exp\n",
        "\n",
        "class NGram():\n",
        "    def __init__(self, ngram, max_n=5000):\n",
        "      #print('===', ngram)\n",
        "      self.ngram,self.max_n = ngram,max_n\n",
        "    def __eq__(self, other):\n",
        "        if len(self.ngram) != len(other.ngram): return False\n",
        "        return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
        "    def __hash__(self):\n",
        "      hml = [o * self.max_n**i for i,o in enumerate(self.ngram)]\n",
        "      hm = int(sum(hml))\n",
        "      return hm\n",
        "\n",
        "def get_grams(x, n, max_n=5000):\n",
        "    return x if n==1 else [NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]\n",
        "\n",
        "def get_correct_ngrams(pred, targ, n, max_n=5000):\n",
        "    pred_grams,targ_grams = get_grams(pred, n, max_n=max_n),get_grams(targ, n, max_n=max_n)\n",
        "    pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
        "    precm = [(c, targ_cnt[g]) for g,c in pred_cnt.items()]\n",
        "    precl = [min(c, g) for c, g in precm]\n",
        "    prec, ln = sum(precl),len(pred_grams)\n",
        "    return prec, ln\n",
        "\n",
        "def corpus_bleu(preds, targs, max_n=5000):\n",
        "    pred_len,targ_len,n_precs,counts = 0,0,[0]*4,[0]*4\n",
        "    tmp_preds = preds.argmax(dim=-1)\n",
        "    tmp_preds, tmp_targs = tmp_preds.cpu().numpy(), targs.cpu().numpy()\n",
        "    for pred,targ in zip(tmp_preds, tmp_targs):\n",
        "        pred_len += len(pred)\n",
        "        targ_len += len(targ)\n",
        "        for i in range(4):\n",
        "            c,t = get_correct_ngrams(pred, targ, i+1, max_n=max_n)\n",
        "            n_precs[i] += c\n",
        "            counts[i] += t\n",
        "    #db.set_trace()\n",
        "    n_precs = [c/t if (t > 0) else 0 for c,t in zip(n_precs,counts)]\n",
        "    len_penalty = exp(1 - targ_len/pred_len) if pred_len < targ_len else 1\n",
        "    return len_penalty * ((n_precs[0]*n_precs[1]*n_precs[2]*n_precs[3]) ** 0.25)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFuApajVQJ_3"
      },
      "source": [
        "# Not used at the moment\n",
        "class CorpusBLEU(Callback):\n",
        "    def __init__(self, vocab_sz):\n",
        "        self.vocab_sz = vocab_sz\n",
        "        self.name = 'bleu'\n",
        "    \n",
        "    def on_epoch_begin(self, **kwargs):\n",
        "        self.pred_len,self.targ_len,self.n_precs,self.counts = 0,0,[0]*4,[0]*4\n",
        "    \n",
        "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
        "        last_output = last_output.argmax(dim=-1)\n",
        "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
        "            self.pred_len += len(pred)\n",
        "            self.targ_len += len(targ)\n",
        "            for i in range(4):\n",
        "                c,t = get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
        "                self.n_precs[i] += c\n",
        "                self.counts[i] += t\n",
        "    \n",
        "    def on_epoch_end(self, last_metrics, **kwargs):\n",
        "        n_precs = [c/t for c,t in zip(n_precs,counts)]\n",
        "        len_penalty = exp(1 - targ_len/pred_len) if pred_len < targ_len else 1\n",
        "        bleu = len_penalty * ((n_precs[0]*n_precs[1]*n_precs[2]*n_precs[3]) ** 0.25)\n",
        "        return add_metrics(last_metrics, bleu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie3Gl4VAnsEv"
      },
      "source": [
        "### App Base class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_-Bw9wgWKg0"
      },
      "source": [
        "#export\n",
        "\n",
        "class AppBase():\n",
        "  def __init__(self, loss_type='bin_classif', metrics_cbs=[]):\n",
        "    self._arch = None\n",
        "    self.db = None\n",
        "\n",
        "    self.debug_cbs = []\n",
        "    self.dtr = None\n",
        "    self.hooks = None\n",
        "\n",
        "    # Select the appropriate loss function for the type of problem\n",
        "    if (loss_type == 'bin_classif'):\n",
        "      # Binary classification problems\n",
        "      self.loss_fn = F.binary_cross_entropy_with_logits\n",
        "      #self.loss_fn = nn.BCELoss()\n",
        "    elif (loss_type == 'multi_classif'):\n",
        "      # Multi-class classification problems\n",
        "      self.loss_fn = F.cross_entropy\n",
        "    elif (loss_type == 'regression'):\n",
        "      self.loss_fn = mse\n",
        "    assert(self.loss_fn)\n",
        "\n",
        "    metrics_cbs = [LossMetricsCB()] + metrics_cbs\n",
        "    self.metrics_cbs = metrics_cbs + [MetricsGrp(metrics_cbs)]\n",
        "\n",
        "  # ----------------------------\n",
        "  # Create the debug settings\n",
        "  # ----------------------------\n",
        "  def create_debug(self, use_dtr=False, track_batches_per_epoch=5, disp_tb=False, disp_pd=True, debug_bkwd=False, debug_fwd=False, abort_iter=0):\n",
        "    dtr, hooks, debug_cbs = None, None, []\n",
        "    if (use_dtr):\n",
        "      dtr = DebugTracker(max_count=track_batches_per_epoch, disp=(disp_tb, disp_pd))\n",
        "      debug_cbs += [dtr, DebugYhatLossCB(fwd=False, bkwd=debug_bkwd)]\n",
        "\n",
        "      # Add hooks for the forward pass activations\n",
        "      if (debug_fwd):\n",
        "        # Arch and Model should be created already\n",
        "        assert(self._arch and self._arch.model)\n",
        "        arch = self._arch\n",
        "        model = arch.model\n",
        "\n",
        "        # Add Debug Hooks to the hook_layers and save a list of all the hooks\n",
        "        hook_cls=[[partial(DebugActivationHook, do_print=False, model=model, dtr=dtr)]]\n",
        "        hook_groups = arch.hook_groups()\n",
        "        hooks = Hooks(hook_groups, hook_cls)\n",
        "\n",
        "    if (abort_iter > 0):\n",
        "      debug_cbs += [AbortTrainCB(abort_iter)]\n",
        "\n",
        "    self.dtr, self.hooks, self.debug_cbs = dtr, hooks, debug_cbs\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Train the model\n",
        "  #----------------------------------------------------\n",
        "  def run_train(self, num_epochs=1, split_lr=[1e-3], weight_decay=0.2, one_cycle=False, app_cbs=[]):\n",
        "    assert(isinstance(one_cycle, bool))\n",
        "\n",
        "    train_dl = self.db.train_dl\n",
        "    valid_dl = self.db.valid_dl\n",
        "\n",
        "    # Loss function\n",
        "    loss_func = self.loss_fn\n",
        "\n",
        "    # Model\n",
        "    arch = self._arch\n",
        "    model = arch.model\n",
        "\n",
        "    opt_adamw = partial(optim.AdamW, betas=(0.9, 0.99), weight_decay=weight_decay)\n",
        "    lr_sched='one_cycle' if one_cycle else None\n",
        "    opt, hyper_cbs = HyperParams.set(model, module_groups=None, split_lr=split_lr, split=False, lr_sched=lr_sched, opt_func=opt_adamw)\n",
        "\n",
        "    gpu_cbs = [CudaCB(device = torch.device('cuda',0))]\n",
        "    track_cbs = [Recorder(), ProgressCallback()]\n",
        "    callbs = gpu_cbs + track_cbs\n",
        "    callbs += app_cbs\n",
        "    callbs += self.metrics_cbs + hyper_cbs + self.debug_cbs\n",
        "\n",
        "    loop = Trainer(train_dl, valid_dl, model, opt, loss_func, callbs, dtr=self.dtr)\n",
        "    loop.hooks = self.hooks\n",
        "\n",
        "    loop.fit(num_epochs=num_epochs)\n",
        "    return loop\n",
        "\n",
        "  # ----------------------------\n",
        "  # Learning Rate Finder\n",
        "  # ----------------------------\n",
        "  def lr_find(self, start_lr, end_lr, num_iter, weight_decay=0.01, app_cbs=[]):\n",
        "\n",
        "    train_dl = self.db.train_dl\n",
        "    valid_dl = None\n",
        "\n",
        "    # Loss function\n",
        "    loss_func = self.loss_fn\n",
        "\n",
        "    # Model\n",
        "    arch = self._arch\n",
        "    model = arch.model\n",
        "\n",
        "    opt_adamw = partial(optim.AdamW, betas=(0.9, 0.99), weight_decay=weight_decay)\n",
        "    opt, hyper_cbs = HyperParams.set(model, module_groups=None, split_lr=[start_lr], split=False, lr_sched='lrf', opt_func=opt_adamw, start_lr=start_lr, end_lr=end_lr, num_iter=num_iter)\n",
        "\n",
        "    gpu_cbs = [CudaCB(device = torch.device('cuda',0))]\n",
        "    track_cbs = [Recorder(), ProgressCallback()]\n",
        "    lrf_cbs = [LRRangeFind(num_iter)]\n",
        "    callbs = gpu_cbs + track_cbs\n",
        "    callbs += app_cbs\n",
        "    callbs += lrf_cbs + hyper_cbs\n",
        "\n",
        "    loop = Trainer(train_dl, valid_dl, model, opt, loss_func, callbs, dtr=None)\n",
        "\n",
        "    num_epochs = int(math.ceil(num_iter / len(train_dl)))\n",
        "    loop.fit(num_epochs=num_epochs)\n",
        "    return loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYOkRX-nIfmE"
      },
      "source": [
        "### Tabular To Be Sorted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfIBTN8u9HZZ"
      },
      "source": [
        "\n",
        "  # DONE Rossman - load using prepare\n",
        "  # DONE Rossman - run basic model\n",
        "  # DONE Test this - Change all convert methods for all ItemLists to take 'items' as the first argument\n",
        "  # DONE Change extract_select to have a flag - take all cat/cont or target. Also update the feature dict cat and cont cols accordingly\n",
        "  # DONE Remove unnecessary stuff out of HomeCreditDB\n",
        "  # DONE reduce_mem - should take flag to treat 'object' columns as categorical\n",
        "  # DONE ROC_AUC Callback\n",
        "  # DONE getobj() what about datatype of np array - if not float then make it float\n",
        "  # DONE Document stack trace\n",
        "  # DONE Document copysettingwitherror\n",
        "  # DONE Home Credit - One result\n",
        "  # DONE listing of cont/cat columns in prepare() and feature_dict. Naming of '_y' columns after join.\n",
        "  # DONE AppTabular run_train should take a flag to enable/disable hooks and dtr\n",
        "  # DONE Add aggregates for the 4 balance tables\n",
        "  # DONE Add relative values for amounts\n",
        "  # DONE Give two letter prefix to all columns from auxiliary tables so there is no name conflict\n",
        "  # DONE Split MetricsCB into AverageMetricsCB\n",
        "  # DONE AppTabular init() should take metrics as an argument\n",
        "  # DONE Generic Metrics Callback base class that AverageMetrics and ROC inherit from\n",
        "  # DONE Rossman - EDA\n",
        "  # DONE Utility fn to create 'subset' version of dataset\n",
        "  # DONE Rossman - One result, with correct accuracy/loss, take log if needed\n",
        "  # DONE Use One Cycle\n",
        "  # DONE Categorical columns missing values get set to -1. Check if we have any, and add +1 to all codes like in Fastai, so that missing becomes 0\n",
        "  # DONE Run with all data as training, no validation, and check what training loss we get for the rows (including the last 20% which would have been validation)\n",
        "  # DONE Calculate loss on the full accumulated yhat/yb for an epoch\n",
        "  # Same Model, Diff data:\n",
        "    # DONE Run train with 80% as normal. For validation, run the full 100% data. Here the model weights are fixed. Now see what loss and yhat we get for the first 80% data and for the final 20% data.\n",
        "    # DONE Flip train and validation data\n",
        "  # Same data, diff model:\n",
        "    # Toward the end of training - check yhat/loss on the last 10 batches or so. Then use those same 10 batches in validation and check yhat/loss.\n",
        "  # DONE Run the full data with only model forward and loss ie. no backward/opt, and see yhat and loss for first 80% and last 20%\n",
        "  # DONE Pickle App and Reload it\n",
        "  # DONE Torch.save Model and Reload it\n",
        "  # DONE Run prepare with full data and pickle it, and reload it\n",
        "  # DONE Use old MetricsCB\n",
        "  # DONE Use no metrics and just check loss\n",
        "  # DONE Use my adam_opt_func not Pytorch optim.Adam\n",
        "  # DONE Train a model for 2000 batches and then torch.save the model and reload it, before starting debugging.\n",
        "  # DONE Run with DTR and DebugYhat and check gradient change on the backward\n",
        "  # DONE Add Val Pred and Loss in DebugYhat\n",
        "  # DONE Check gradient with Rossman fastai.\n",
        "  # NONEED Use my df, sorted by Date/Store with fastai - create Databunch and model\n",
        "  # NONEED Use fastai df with my model\n",
        "  # DONE Make data as SequentialSampler\n",
        "  # DONE Check loss with both BSELoss and BSELossWithLogits\n",
        "  # DONE Still need to answer why outlier rows produce huge loss only in validation data, and not in training\n",
        "  # NONEED Compare some outlier rows with non-outlier rows to see how they are different\n",
        "\n",
        "  # ++++++++++ End-to-end run of Rossman with same results\n",
        "  # DONE Compute y_range via a param and dont hardcode it\n",
        "  # DONE Sequential Split should take a flag for 'test_rows' so that all sequential types are supported including by index, not just by random pct.\n",
        "  # DONE Remove hard-coded CompetitionDistance in reduce_mem()\n",
        "  # DONE Compute valid_idx automatically\n",
        "  # DONE Correct size for validation dataset\n",
        "  # DONE Make the optimiser AdamW usage generic in run_train() by passing in params for weight decay and betas.\n",
        "\n",
        "  # ++++++++++ Full visibility into end-to-end runs and results\n",
        "  # DONE Track training and validation loss - val loss not showing up in Tensorboard\n",
        "  # DONE Track all hyperparameters - mom etc - \n",
        "  # NONEED Track metrics - already being outputted per epoch, not critical to include them in DTR for now\n",
        "  # DONE Unique layer names\n",
        "  # DONE Recorder and DTR should quickly output all info from a run to quickly view all important parameters\n",
        "  # DONE Visualise all results in Tensorboard and/or Pandas matplotlib\n",
        "  # DONE Also have a separate function to create the Debug/DTR with the right arguments. Then run_train() uses that DTR.\n",
        "\n",
        "  # ++++++++++ Quicker turnaround during development by saving and loading pre-computed intermediate data state\n",
        "  # DONE Incorporate subsets of different dataset sizes as part of normal workflow\n",
        "  # DONE Load and save processed data from one run to the next\n",
        "  # DONE Load and save prepared data from one run to the next\n",
        "  # DONE Load and save model weights from one run to the next\n",
        "\n",
        "  # ++++++++++ Ensure reproducibility and no degradation of results by comparing with previous runs\n",
        "  # DONE Make generic utils to quickly compare data (prepared and processed and np array) from one run to the next\n",
        "  # DONE Make generic utils to quickly compare results from one model execution run using the results DFs\n",
        "  # DONE Generic utils/workflow to save good historical runs\n",
        "  # Generic function for reproducible runs as a single top-level flag\n",
        "\n",
        "  # ++++++++++ End-to-end run of Home Credit with same results\n",
        "  # DONE Check if correct LR rate is used - implement LR Find\n",
        "    # Recorder should plot a graph of Loss vs Log(LR), in addition to Loss vs iteration\n",
        "    # In lr_find() val_dl is None which will cause exception if num_epochs > 1\n",
        "    # Tune the exit condition in LRRangeFinder as per Fastai\n",
        "  # DONE Generic way to pass in different Settings to create_arch() and run_train().\n",
        "  # DONE Auto-try with different Settings values - for run_train(), create_arch() and later, for load_data()\n",
        "  # DONE DTR should track (1) DONE epochs (2) DONE metrics per epoch (3) DONE Settings per run (4) DONE Timing per epoch\n",
        "  # DONE Auto-way to easily store and compare results from these different runs\n",
        "  # DONE Display results from different runs\n",
        "  # DONE Smoothed moving average for training loss metric\n",
        "  # DONE Timing of run is too slow - run with Fastai using my df and measure timing\n",
        "  # DONE Have a flag for the HomeCreditDB to turn on/off add_col in check_missing(). Also missing threshold for dropping columns.\n",
        "\n",
        "  # ++++++++++ Compare Fastai and KD results with RandomSampler - why is Fastai still better\n",
        "  # DONE - removed truncation of last batch.\n",
        "  # Try with drop_last=True and check if results improve\n",
        "\n",
        "  # ++++++++++ Compare adam_opt_func timing with Pytorch optimiser.\n",
        "  # Change my implementation to use in-place computations using func_()\n",
        "\n",
        "\n",
        "  # ++++++++++ Generic Lib Features\n",
        "  # ++++++++++\n",
        "  # Auto detect GPU or not, and include Cuda Callback\n",
        "  # Don't hardcode loop.cbs[1] to get the Recorder. Have a general way to get a callback\n",
        "  # Fix HyperParams one cycle phases 0.3/0.7 and mom values .95/.85- create_OneCycleCB(split_lr, phases=[0.5, 0.5], mom_start=0.8, mom_mid=0.7, mom_end=0.8)\n",
        "  # Hyperparam naming - beta vs momentum for AdamW - cleanup how it is implemented in OptimParamCB\n",
        "  # DONE Hyperparam 'one_cycle' argument should be renamed to 'lr_sched' or something \n",
        "  # Trainer should take a Metrics param as a first class citizen rather than putting it in the Callbacks list\n",
        "  # Increase momentum in BatchNorm constructor\n",
        "  # Debug BatchNorm attributes - running_mean, running_var, learnable gamma and beta parameters can be accessed by displaying the weight and bias members of a batch norm layer\n",
        "  # Include primt_grad() with buffers in the DebugYhat\n",
        "  # Generic way to pass in first_div and final_div params to Create One Cycle\n",
        "  # Better filter criteria for epoch and batch for DTR\n",
        "  # In run_settings(), include a Run Description which can be the filename for saving a run\n",
        "\n",
        "  # ++++++++++ Tabular Features\n",
        "  # ++++++++++\n",
        "  # DONE Fill Missing adds an extra column to indicate that it was filled, and make the extra column categorical\n",
        "  # DONE Add a check in impute_values to warn about a high % of NaN or inf values, above some threshold. Or make a separate check_missing() converter. \n",
        "  # The default for Tabular split_param should be random, not sequential.\n",
        "  # Add a split_date() function\n",
        "  # split_idxs() should take a function which gets passed the train and test rows and returns the idxs for splitting\n",
        "  # Add a convert function to TabularItemList for ordinal category values\n",
        "  # Then remove columns which have a high missing %age eg. PCT_CREDIT_Refused, Cancelled, PCT_ANNUITY_Refused etc.\n",
        "  # db.make_subset() should be able to merge one related file at a time and create a subset for that file, and then loop to the \n",
        "  #     next related file rather than require a merge_all function which merges everything all at once. Look at the comments in\n",
        "  #     make_subset() for more details.\n",
        "  # DONE reduce_mem() downgrade of float values is dangerous - get rid of it\n",
        "  # Feature Dict stuff\n",
        "  # Read CSV with low_memory=False and/or giving a list of dtypes\n",
        "  # Do EDA with bivariate data_target, correlation, stack_hist\n",
        "  # Write a run_predict() method\n",
        "  # Add EDA or Converter logic for converting columns to the correct data types, because the initial could be garbage\n",
        "  # Normalise() - if std is 0, then what to do??\n",
        "  # Comments in Tabular Item List\n",
        "  # Normal Workflow - Break down the problem into smaller pieces\n",
        "     # Run with base-data ie only 'train.csv' columns with no related.\n",
        "     # Subset with say 10 batches - ie. 640 rows. Or with 10000 rows?\n",
        "     # Test with only continuous columns first\n",
        "     # Then add categorical columns\n",
        "     # Test that fill missing and normalise give us correct results\n",
        "     # Then add rollup of related, but only one table at first. Then slowly add more tables.\n",
        "     # Then make a subset of 100 batches, then 1000 and 10000\n",
        "  # https://stackoverflow.com/questions/55894132/how-to-correct-unstable-loss-and-accuracy-during-training-binary-classificatio\n",
        "  # https://stats.stackexchange.com/questions/352036/what-should-i-do-when-my-neural-network-doesnt-learn\n",
        "  #\n",
        "\n",
        "  # ++++++++++ Rossman Features\n",
        "  # ++++++++++\n",
        "  # Rossman - fix the sort order of Date and Store in the prepare()\n",
        "  # Rossman - add back Customer as a target columns\n",
        "\n",
        "  # ++++++++++ Home Credit Features\n",
        "  # ++++++++++\n",
        "  # Run with Fastai using my df and measure ROC AUC score\n",
        "  # Verify that ROC AUC is implemented correctly - right now it just stays flat\n",
        "  # Again compare scores and df with Aguiar\n",
        "  # Add columsn numerics to bins\n",
        "  # Convert FLAG_xxx columns from Y/N to bool\n",
        "  # Check if some numerics should be treated as categorical\n",
        "  # Include some more columns where mode/missing data is Ok\n",
        "  # Use automated feature polynomials\n",
        "  # Sort HC by Curr ID and Rossman by Date -> Store\n",
        "\n",
        "  # ++++++++++ Optional Util features Features\n",
        "  # ++++++++++\n",
        "  # Create a inspect stack trace utility, and simulate an error by returning int array from getobj. Put a try-catch around the loop.fit\n",
        "  # Make generic utils for Inspect Stack Trace and Memory Consumption in debug_lib\n",
        "  # Make generic example for Line Profiler timing measurements\n",
        "  # Cleanup stuff under Temp Obsolete and Random Stuff\n",
        "  # torch.set_num_threads(2)\n",
        "  # Dataloader num workers\n",
        "  # Make a separate NpItemlist\n",
        "  # In getobj or to_np(), split the categorical np array (np.int64) and continuous np array (np.float32) into two separate arrays\n",
        "  # Possible to incorporate remove_inf() converter inside fill_missing() or impute_values()\n",
        "  #\n",
        "  # Reduce RAM - del variables and call gc.collect regularly, pass in preset datatypes while reading, read fewer rows/skip rows, \n",
        "  # NODIFF - merge with index columns\n",
        "  # INCREASE - convert to Sparse type\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "554SaXdXi6-5"
      },
      "source": [
        "#----------------------------------------------------\n",
        "# So we rename the keys in the weights to correspond to the KD model module names\n",
        "#----------------------------------------------------\n",
        "def rename_wgt_keys(model, weights_path):\n",
        "  wgts = torch.load(weights_path)\n",
        "  #renamed_wgts=OrderedDict()\n",
        "  renamed_wgts={}\n",
        "  for old_key, new_key in zip(wgts.keys(), model.state_dict().keys()):\n",
        "    renamed_wgts[new_key] = wgts[old_key]\n",
        "    #print (old_key, new_key, torch.all(torch.eq(renamed_wgts[new_key], wgts[old_key])))\n",
        "  model.load_state_dict(renamed_wgts)\n",
        "\n",
        "def print_grad(self, model, before=''):\n",
        "    all_params=[]\n",
        "    # Use state_dict() not parameters() as it also returns buffers, not just parameters\n",
        "    for name, param in model.state_dict().items():\n",
        "      param_dict = {'name': name, 'shape': tuple(param.data.size()), 'requires': param.requires_grad, 'leaf': param.is_leaf, 'param': param.data.float().mean().item(), 'grad': (param.grad.mean().item() if param.grad is not None else 0)}\n",
        "      all_params.append(param_dict)\n",
        "    return pd.DataFrame(all_params)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUCGy94NZWOm"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from nb_util import accuracy, accuracy_thresh, mse, rmspe, save_pickle, load_pickle, DebugRand\n",
        "from nb_training import Trainer, CancelFitException, Callback, MetricsGrp, LossMetricsCB, AverageMetricsCB, RocAucMetricsCB, AbortTrainCB, ProgressCallback, CudaCB, DebugTracker, DebugYhatLossCB\n",
        "#from nb_optimiser import get_optimiser, Recorder, adam_opt_func, HyperParams\n",
        "from nb_optimiser import get_optimiser, Recorder, adam_opt_func, HyperParams, LRRangeFind\n",
        "#from nb_hooks import Hooks, Hook\n",
        "from nb_hooks import Hooks, DebugActivationHook\n",
        "from nb_util import test_near_zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTBNP8poFtJa"
      },
      "source": [
        "### Tabular Arch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOnfe-CuHE3u"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tabular model with Entity Embedding for categorical features followed\n",
        "# by Linear blocks\n",
        "#\n",
        "# 'emb_szs' is a list of tuples [(num_categories, embedding_dim), (), ...] with one\n",
        "# tuple per categorical feature\n",
        "# 'lin_hs' is a list of hidden sizes for each linear block [hid1, hid2, ...]\n",
        "#----------------------------------------------------\n",
        "class Tabular(nn.Module):\n",
        "  def __init__(self, n_cat, n_cont, emb_szs, emb_p, hidden_szs, hidden_ps, out_sz, out_range):\n",
        "    super().__init__()\n",
        "    self.n_cat, self.n_cont = n_cat, n_cont\n",
        "    self.out_range = out_range\n",
        "\n",
        "    # Embedding layers and Dropout for categorical features\n",
        "    self.cat_emb = nn.ModuleList([nn.Embedding(ln,dim) for ln, dim in emb_szs])\n",
        "    self.emb_drop = nn.Dropout(emb_p)\n",
        "\n",
        "    # BatchNorm layers for continuous features\n",
        "    # !!!!!!!!!!!!!\n",
        "    #self.cont_bn = nn.BatchNorm1d(n_cont, momentum=0.5)\n",
        "    self.cont_bn = nn.BatchNorm1d(n_cont)\n",
        "\n",
        "    # Input and output feature sizes for each layer\n",
        "    total_emb_dim = sum([dim for _, dim in emb_szs])\n",
        "    inp_sz = total_emb_dim + n_cont\n",
        "    n_ins = [inp_sz] + hidden_szs\n",
        "    n_outs = hidden_szs + [out_sz]\n",
        "\n",
        "    # Linear block layers with Linear, ReLU, BatchNorm and Dropout\n",
        "    layers = []\n",
        "    for n_in, n_out, drop_p in zip(n_ins, n_outs, hidden_ps):\n",
        "      lin = nn.Linear(n_in, n_out)\n",
        "      relu = nn.ReLU(inplace=True)\n",
        "      bn = nn.BatchNorm1d(n_out)\n",
        "      drop = nn.Dropout(drop_p)\n",
        "      layers += [lin, relu, bn, drop]\n",
        "\n",
        "    # Output layer\n",
        "    out = nn.Linear(hidden_szs[-1], out_sz)\n",
        "\n",
        "    # Wrap all the layers into Sequential\n",
        "    layers += [out]\n",
        "    self.layers = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, inp):\n",
        "    # Separate categorical and continuous features. The initial columns are\n",
        "    # categorical\n",
        "    cat_inp = inp[:, :self.n_cat].long()\n",
        "    cont_inp = inp[:, self.n_cat:].float()\n",
        "\n",
        "    # Pass each categorical feature through its embedding and dropout\n",
        "    if (self.n_cat > 0):\n",
        "      emb_vals = [emb(cat_inp[:, i])  for i, emb in enumerate(self.cat_emb)]\n",
        "      emb_val = torch.cat(emb_vals, axis=1)\n",
        "      emb_val = self.emb_drop(emb_val)\n",
        "    else:\n",
        "      # Empty tensor\n",
        "      emb_val = cat_inp\n",
        "\n",
        "    # Process the continuous features through batch norm\n",
        "    if (self.n_cont > 0):\n",
        "      cont_val = self.cont_bn(cont_inp)\n",
        "    else:\n",
        "      # Empty tensor\n",
        "      cont_val = cont_inp\n",
        "\n",
        "    # Concatenate the embedding and continuous values\n",
        "    combined_val = torch.cat([emb_val, cont_val], axis=1)\n",
        "\n",
        "    # Process the sequential linear layers\n",
        "    output = self.layers(combined_val)\n",
        "\n",
        "    if (self.out_range):\n",
        "      output = self.out_range[0] + torch.sigmoid(output) * (self.out_range[1] - self.out_range[0])\n",
        "    return output\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Create the Tabular architecture\n",
        "#----------------------------------------------------\n",
        "class ArchTabular(ArchBase):\n",
        "  # ----------------------------\n",
        "  # Create the Tabular model. Calculates the number and size of all the Entity Embedding\n",
        "  # layers for the categorical variables\n",
        "  # ----------------------------\n",
        "  def create_model(self, cat_szs, n_cont, emb_p, hidden_szs, hidden_ps, out_sz=1, out_range=None):\n",
        "\n",
        "    #def emb_sz_rule(cat_sz:int)->int: return min(50, (cat_sz//2)+1)\n",
        "    def emb_sz_rule(cat_sz:int)->int: return min(600, round(1.6 * cat_sz**0.56))\n",
        "\n",
        "    n_cat = len(cat_szs)\n",
        "    emb_szs = [(cat_sz, emb_sz_rule(cat_sz)) for cat_sz in cat_szs]\n",
        "\n",
        "    # Build the Tabular model\n",
        "    self.model = Tabular(n_cat, n_cont, emb_szs, emb_p, hidden_szs, hidden_ps, out_sz, out_range)\n",
        "\n",
        "  def hook_groups(self):\n",
        "    model = self.model\n",
        "    layer_modules = list(model.layers.modules())\n",
        "    hk_groups = [list(model.cat_emb) + [model.cont_bn, layer_modules[1], layer_modules[3], layer_modules[5], layer_modules[7], layer_modules[-1]]]\n",
        "    return hk_groups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhZFtLXjFvlZ"
      },
      "source": [
        "### Tabular Application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1L4wklKFaz4"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tabular Application\n",
        "#----------------------------------------------------\n",
        "class AppTabular(AppBase):\n",
        "  # ----------------------------\n",
        "  # Load the data using the Tabular Data Bundle\n",
        "  # ----------------------------\n",
        "  def load_data(self, app_db, main_file_path, test_file_path, related_csv_paths, steps=['load', 'post_load'], **kwargs):\n",
        "    if ('load' in steps):\n",
        "      self.db = app_db(main_file_path, test_file_path, related_csv_paths, **kwargs)\n",
        "      self.db.process(steps=['load'])\n",
        "\n",
        "    if ('post_load' in steps):\n",
        "      self.db.process(steps=['post_load'])\n",
        "      self.n_cont, self.cat_szs, self.n_tgt, self.tgt_range = self.db.col_szs()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Create the architecture\n",
        "  # ----------------------------\n",
        "  def create_arch(self, emb_p=0.04, hidden_szs=[1000, 500], hidden_ps=[.001, .01]):\n",
        "    self._arch = ArchTabular()\n",
        "    self._arch.create_model(self.cat_szs, self.n_cont, \n",
        "                            emb_p=emb_p, hidden_szs=hidden_szs, hidden_ps=hidden_ps, \n",
        "                            out_sz=self.n_tgt, out_range=self.tgt_range)\n",
        "    return self._arch\n",
        "\n",
        "  @staticmethod\n",
        "  def subset_path(app_dir, gd_path, subset_sz):\n",
        "    subset_root_path = Path(gd_path)/'data'\n",
        "    subset_data_path = subset_root_path/f'{app_dir}_{subset_sz}'\n",
        "    return subset_data_path\n",
        "\n",
        "  @staticmethod\n",
        "  def set_data_path (app_dir, gd_path, subset_sz, data_files):\n",
        "    root_path = Path.cwd()\n",
        "    download_path = root_path/app_dir\n",
        "\n",
        "    subset_data_path = AppTabular.subset_path(app_dir, gd_path, subset_sz)\n",
        "    debug_path = subset_data_path/'debug'\n",
        "    hist_path = subset_data_path/'hist'\n",
        "\n",
        "    if (subset_sz == 'full'):\n",
        "      # In this case data is taken from the download path, and subset data path is\n",
        "      # used only for debug data.\n",
        "      data_path = download_path\n",
        "    else:\n",
        "      data_path = subset_data_path\n",
        "\n",
        "    main_file_path = data_path/data_files['main']\n",
        "    test_file_path = data_path/data_files['test']\n",
        "    related_csv_paths = [data_path/file for file in data_files['related']]\n",
        "\n",
        "    return (root_path, download_path, data_path, debug_path, hist_path, main_file_path, test_file_path, related_csv_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67GwyU4Xe0L"
      },
      "source": [
        "### Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPRG233iuTeu"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ketanhdoshi/ml/master/lib/nb_export.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYy95Q_juc1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50490ae5-028b-4d96-8059-a38689913866"
      },
      "source": [
        "from nb_export import notebook2scriptSingle\n",
        "notebook2scriptSingle(gn_path + '/lib/app_lib.ipynb', gn_path + '/exp')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted gdrive/My Drive/Colab Notebooks/lib/app_lib.ipynb to gdrive/My Drive/Colab Notebooks/exp/nb_app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnLS3sqawF1"
      },
      "source": [
        "### Junk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5cBUtpsa03S"
      },
      "source": [
        "\n",
        "  def load_weights(self, weights_path):\n",
        "    weights = torch.load(weights_path)\n",
        "    self.model.load_state_dict(weights)\n",
        "\n",
        "  def save_weights(self, weights_path):\n",
        "    # Save the full model\n",
        "    torch.save(self.model.state_dict(), weights_path)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tabular Application\n",
        "#----------------------------------------------------\n",
        "class AppTabular():\n",
        "  def __init__(self, loss_type='bin_classif', metrics_cbs=[]):\n",
        "    self._arch = None\n",
        "    self.db = None\n",
        "\n",
        "    # Select the appropriate loss function for the type of problem\n",
        "    if (loss_type == 'bin_classif'):\n",
        "      # Binary classification problems\n",
        "      self.loss_fn = F.binary_cross_entropy_with_logits\n",
        "      #self.loss_fn = nn.BCELoss()\n",
        "    elif (loss_type == 'multi_classif'):\n",
        "      # Multi-class classification problems\n",
        "      self.loss_fn = F.cross_entropy\n",
        "    elif (loss_type == 'regression'):\n",
        "      self.loss_fn = mse\n",
        "    assert(self.loss_fn)\n",
        "\n",
        "    metrics_cbs = [LossMetricsCB()] + metrics_cbs\n",
        "    self.metrics_cbs = metrics_cbs + [MetricsGrp(metrics_cbs)]\n",
        "\n",
        "  # ----------------------------\n",
        "  # Load the data using the Tabular Data Bundle\n",
        "  # ----------------------------\n",
        "  def load_data(self, app_db, main_file_path, test_file_path, related_csv_paths, steps=['load', 'post_load'], **kwargs):\n",
        "    if ('load' in steps):\n",
        "      self.db = app_db(main_file_path, test_file_path, related_csv_paths, **kwargs)\n",
        "      self.db.process(steps=['load'])\n",
        "\n",
        "    if ('post_load' in steps):\n",
        "      self.db.process(steps=['post_load'])\n",
        "      self.n_cont, self.cat_szs, self.n_tgt, self.tgt_range = self.db.col_szs()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Create the architecture\n",
        "  # ----------------------------\n",
        "  def create_arch(self, emb_p=0.04, hidden_szs=[1000, 500], hidden_ps=[.001, .01]):\n",
        "    self._arch = ArchTabular()\n",
        "    self._arch.create_model(self.cat_szs, self.n_cont, \n",
        "                            emb_p=emb_p, hidden_szs=hidden_szs, hidden_ps=hidden_ps, \n",
        "                            out_sz=self.n_tgt, out_range=self.tgt_range)\n",
        "    return self._arch\n",
        "\n",
        "  # ----------------------------\n",
        "  # Create the debug settings\n",
        "  # ----------------------------\n",
        "  def create_debug(self, use_dtr=False, track_batches_per_epoch=5, disp_tb=False, disp_pd=True, debug_bkwd=False, debug_fwd=False, abort_iter=0):\n",
        "    dtr, hooks, debug_cbs = None, None, []\n",
        "    if (use_dtr):\n",
        "      dtr = DebugTracker(max_count=track_batches_per_epoch, disp=(disp_tb, disp_pd))\n",
        "      debug_cbs += [dtr, DebugYhatLossCB(fwd=False, bkwd=debug_bkwd)]\n",
        "\n",
        "      # Add hooks for the forward pass activations\n",
        "      if (debug_fwd):\n",
        "        # Arch and Model should be created already\n",
        "        assert(self._arch and self._arch.model)\n",
        "        arch = self._arch\n",
        "        model = arch.model\n",
        "\n",
        "        # Add Debug Hooks to the hook_layers and save a list of all the hooks\n",
        "        hook_cls=[[partial(DebugActivationHook, do_print=False, model=model, dtr=dtr)]]\n",
        "        hook_groups = arch.hook_groups()\n",
        "        hooks = Hooks(hook_groups, hook_cls)\n",
        "\n",
        "    if (abort_iter > 0):\n",
        "      debug_cbs += [AbortTrainCB(abort_iter)]\n",
        "\n",
        "    self.dtr, self.hooks, self.debug_cbs = dtr, hooks, debug_cbs\n",
        "\n",
        "  # ----------------------------\n",
        "  # Train the model\n",
        "  # ----------------------------\n",
        "  def run_train(self, num_epochs=1, split_lr=[1e-3], weight_decay=0.2, one_cycle=False):\n",
        "    assert(isinstance(one_cycle, bool))\n",
        "\n",
        "    train_dl = self.db.train_dl\n",
        "    valid_dl = self.db.valid_dl\n",
        "\n",
        "    # Loss function\n",
        "    loss_func = self.loss_fn\n",
        "\n",
        "    # Model\n",
        "    arch = self._arch\n",
        "    model = arch.model\n",
        "\n",
        "    opt_adamw = partial(optim.AdamW, betas=(0.9, 0.99), weight_decay=weight_decay)\n",
        "    opt_adam = optim.Adam\n",
        "    lr_sched='one_cycle' if one_cycle else None\n",
        "    opt, hyper_cbs = HyperParams.set(model, module_groups=None, split_lr=split_lr, split=False, lr_sched=lr_sched, opt_func=opt_adamw)\n",
        "\n",
        "    gpu_cbs = [CudaCB(device = torch.device('cuda',0))]\n",
        "    track_cbs = [Recorder(), ProgressCallback()]\n",
        "    callbs = gpu_cbs + track_cbs\n",
        "    callbs += self.metrics_cbs + hyper_cbs + self.debug_cbs\n",
        "\n",
        "    loop = Trainer(train_dl, valid_dl, model, opt, loss_func, callbs, dtr=self.dtr)\n",
        "    loop.hooks = self.hooks\n",
        "\n",
        "    loop.fit(num_epochs=num_epochs)\n",
        "    return loop\n",
        "\n",
        "  # ----------------------------\n",
        "  # Learning Rate Finder\n",
        "  # ----------------------------\n",
        "  def lr_find(self, start_lr, end_lr, num_iter):\n",
        "\n",
        "    train_dl = self.db.train_dl\n",
        "    valid_dl = None\n",
        "\n",
        "    # Loss function\n",
        "    loss_func = self.loss_fn\n",
        "\n",
        "    # Model\n",
        "    arch = self._arch\n",
        "    model = arch.model\n",
        "\n",
        "    opt_adamw = partial(optim.AdamW, betas=(0.9, 0.99), weight_decay=0.01)\n",
        "    opt, hyper_cbs = HyperParams.set(model, module_groups=None, split_lr=[start_lr], split=False, lr_sched='lrf', opt_func=opt_adamw, start_lr=start_lr, end_lr=end_lr, num_iter=num_iter)\n",
        "\n",
        "    gpu_cbs = [CudaCB(device = torch.device('cuda',0))]\n",
        "    track_cbs = [Recorder(), ProgressCallback()]\n",
        "    lrf_cbs = [LRRangeFind(num_iter)]\n",
        "    callbs = gpu_cbs + track_cbs\n",
        "    callbs += lrf_cbs + hyper_cbs\n",
        "\n",
        "    loop = Trainer(train_dl, valid_dl, model, opt, loss_func, callbs, dtr=None)\n",
        "\n",
        "    num_epochs = int(math.ceil(num_iter / len(train_dl)))\n",
        "    loop.fit(num_epochs=num_epochs)\n",
        "    return loop\n",
        "\n",
        "  @staticmethod\n",
        "  def subset_path(app_dir, gd_path, subset_sz):\n",
        "    subset_root_path = Path(gd_path)/'data'\n",
        "    subset_data_path = subset_root_path/f'{app_dir}_{subset_sz}'\n",
        "    return subset_data_path\n",
        "\n",
        "  @staticmethod\n",
        "  def set_data_path (app_dir, gd_path, subset_sz, data_files):\n",
        "    root_path = Path.cwd()\n",
        "    download_path = root_path/app_dir\n",
        "\n",
        "    subset_data_path = AppTabular.subset_path(app_dir, gd_path, subset_sz)\n",
        "    debug_path = subset_data_path/'debug'\n",
        "    hist_path = subset_data_path/'hist'\n",
        "\n",
        "    if (subset_sz == 'full'):\n",
        "      # In this case data is taken from the download path, and subset data path is\n",
        "      # used only for debug data.\n",
        "      data_path = download_path\n",
        "    else:\n",
        "      data_path = subset_data_path\n",
        "\n",
        "    main_file_path = data_path/data_files['main']\n",
        "    test_file_path = data_path/data_files['test']\n",
        "    related_csv_paths = [data_path/file for file in data_files['related']]\n",
        "\n",
        "    return (root_path, download_path, data_path, debug_path, hist_path, main_file_path, test_file_path, related_csv_paths)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}