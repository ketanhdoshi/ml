{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_lib.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y9nsrVG21R--",
        "-87N8MYeMfHl",
        "I99Ng3byKneS",
        "ljk77iuxLIVn",
        "M02SuyEbZHcq",
        "f67GwyU4Xe0L",
        "d-8wu2ZtMSnY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketanhdoshi/ml/blob/master/lib/training_lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTrvq0awIwon"
      },
      "source": [
        "## Neural Net Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "233jN_MC1KLk"
      },
      "source": [
        "**Todos**\n",
        "*   DebugYhatCB should be renamed, and stop printing things to screen - so change all usages of it in arch_lib etc\n",
        "*   DebugTracker should be auto created in Trainer but turned off with max_count = 0. Then you can call dtr.set_settings() and pass in all the disp, freq etc settings to activate TB etc.\n",
        "*   Clean up repr. Aand tb_results is still a bit messy\n",
        "*   Take photos of drawings in my paper notebooks\n",
        "*   Trainer should take a debug=True boolean, and create and initialise DTR within itself\n",
        "*   !!!!! IMP - DTR add_param and add_activation should be wrapped in torch.no_grad\n",
        "*   dtr.pd_results() should return separate run_df and epoch_df\n",
        "*   Get rid of MetricsCB and remove references to it from all files.\n",
        "*   Add dtr.compare_results() which calls dtr.pd.compare_batch_results() etc.\n",
        "*   Enhance the training loop so that it can pass multiple 'x' arguments to the model. So if the 'x' value is a list of values, it destructures them as *xb and passes them in as multiple arguments. Then use that with a Tuple Dataset (see Todos in data_lib) or with Tabular ItemList, pass the continuous and categorical as separate arguments\n",
        "*   DONE Enhance the training loop so that it can pass multiple 'y' arguments to the model. So if the 'y' value is a tuple of values, it destructures them as *yb and passes them in as multiple arguments.\n",
        "\n",
        "**Done**\n",
        "1. DONE Remove torch.no_grad from Callback processing\n",
        "2. DONE Add torch.no_grad in MetricsCB calc metrics\n",
        ". DONE Run Fastai callbacks notebook to see the effect of adding/removing torch.no_grad in AvgStats\n",
        "5. DONE Add DebugTrackRun graphical plotting\n",
        "7. DONE Tensorboard Pytorch\n",
        "9. DONE Document GANs\n",
        "10. DONE Document L1 and L2 regularisation\n",
        "12. DONE Complete ULMFit with datalib\n",
        "13. DONE Use datalib for CycleGAN and DONE - CUDA\n",
        "4. DONE DebugTrackRun - add fine-grained control to track only selected steps (just like we can track selected batches only)\n",
        "15. DONE (via Pandas) Comparison between two steps for the same data parameter\n",
        "16. DONE Clean up get/show results, activation/param_steps, debugtrackrun should be avbl in ctx, set_display, rename variables for operation, step etc\n",
        "17. DONE (via Pandas) DebugTrackRun - results with 3 separate lists for run, batch and steps\n",
        "18. DONE Output to Print Display (can be done via Pandas) and Dataframe ie. create DebugPrint and DebugDataframe\n",
        "23. DONE Add Comments to data_lib (GAN bundle), training_lib (Debug) and Cycle GAN\n",
        "24. DONE Move this file into lib and change the export\n",
        "24. DONE Recorder integrated with DebugTracker?\n",
        "24. DONE Use the timestr as the run_idx\n",
        "24. DONE DebugTracker output to SNS/Matplotlib? Maybe do that via pandas\n",
        "24. DONE Add DebugTrackRun comparison between two runs\n",
        "24. DONE Improve Hooks debugging capabilities and log to DebugTracker\n",
        "24. DONE Metrics and Hyperparams tracking going to DebugTracker. Rationalise with trainer.logger which Metrics and Progress use for output.\n",
        "24. DONE fix the accumulate_batch logic. Problem is that for Transformers the shape of yhat is (smaples, tgt_vocab_sz, seq) and since the seq len is ifferent in each batch, the yhat dimensions are different from one batch to the next and cannot be concatenated during accumulation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9nsrVG21R--"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHLPROiP6Lpk"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVF14yO71kuO"
      },
      "source": [
        "#export\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "import time\n",
        "import pickle\n",
        "from collections import OrderedDict\n",
        "from pathlib import *\n",
        "\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from fastprogress.fastprogress import format_time\n",
        "\n",
        "import torch\n",
        "from torch import tensor\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmkGsyG0TSRq"
      },
      "source": [
        "#!pip install torchviz\n",
        "import IPython.core.debugger as db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU23hChRz_Gb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b2843a-cb28-461f-8630-4c1e75ddc5cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "gn_path = 'gdrive/My Drive/Colab Notebooks'  #change dir to your project folder\n",
        "\n",
        "import sys\n",
        "sys.path.insert(1, gn_path + '/exp')\n",
        "\n",
        "from nb_util import get_mnist_data, accuracy\n",
        "from nb_data import MultiDimDataset, get_dls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUztOygXIrBu"
      },
      "source": [
        "#export\n",
        "\n",
        "from nb_data import Plotter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-87N8MYeMfHl"
      },
      "source": [
        "### Enhanced Training Loop (Step 6 - Create a Trainer class and Include Callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LluAXBoMl-I"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Define the list of callback events\n",
        "#----------------------------------------------------\n",
        "EV_BEGIN_FIT='begin_fit'\n",
        "EV_BEGIN_EPOCH='begin_epoch'\n",
        "\n",
        "EV_BEGIN_TR='begin_tr'\n",
        "EV_BEGIN_TR_BATCH='begin_tr_batch'\n",
        "EV_AFTER_TR_PRED='after_tr_pred'\n",
        "EV_AFTER_TR_LOSS='after_tr_loss'\n",
        "EV_AFTER_TR_BACKWARD='after_tr_backward'\n",
        "EV_AFTER_TR_OPTSTEP='after_tr_optstep'\n",
        "EV_END_TR_BATCH='end_tr_batch'\n",
        "EV_END_TR='end_tr'\n",
        "EV_CANCEL_TR_BATCH='cancel_tr_batch'\n",
        "EV_CANCEL_TR='cancel_tr'\n",
        "\n",
        "EV_BEGIN_VAL='begin_val'\n",
        "EV_BEGIN_VAL_BATCH='begin_val_batch'\n",
        "EV_AFTER_VAL_PRED='after_val_pred'\n",
        "EV_AFTER_VAL_LOSS='after_val_loss'\n",
        "EV_END_VAL_BATCH='end_val_batch'\n",
        "EV_END_VAL='end_val'\n",
        "EV_CANCEL_VAL_BATCH='cancel_val_batch'\n",
        "EV_CANCEL_VAL='cancel_val'\n",
        "\n",
        "EV_END_EPOCH='end_epoch'\n",
        "EV_END_FIT='end_fit'\n",
        "EV_CANCEL_FIT='cancel_fit'\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Define Exceptions for aborting the callback chain\n",
        "#----------------------------------------------------\n",
        "class CancelFitException(Exception): pass\n",
        "class CancelEpochException(Exception): pass\n",
        "class CancelBatchException(Exception): pass\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Base Callback class\n",
        "#----------------------------------------------------\n",
        "class Callback():\n",
        "  def process(self, event, ctx):\n",
        "    f = getattr(self, event, None)\n",
        "    if f:\n",
        "      f(ctx)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Class that runs the training and validation loop\n",
        "# It keeps track of the following while the loop is being executed:\n",
        "#     - Training and Validation DataLoader\n",
        "#     - Model, Optimiser, Loss Function, Callbacks, Hooks and Tracker\n",
        "#     - Number of Epochs (num_epochs) and Number of Batches (num_batches) in Current Epoch\n",
        "#     - Current Epoch (i_epoch) and Current Batch (i_batch) within Current Epoch\n",
        "#     - Current Training Batch Iteration (i_tr_iter) across all Batches so far\n",
        "#     - Data (xb) and Target Labels (yb) in Current Batch\n",
        "#     - Predicted Value (yhat) and Loss Value (loss)\n",
        "#----------------------------------------------------\n",
        "class Trainer():\n",
        "  def __init__(self, tr_dl, val_dl, model, opt, loss_func, cbs=None, dtr=None):\n",
        "    self.tr_dl, self.val_dl = tr_dl, val_dl\n",
        "    self.model, self.opt, self.loss_func = model, opt, loss_func\n",
        "    self.cbs = cbs\n",
        "    self.dtr = dtr\n",
        "    if (dtr is not None):\n",
        "      assert(dtr in cbs)\n",
        "    self.logger = print\n",
        "    \n",
        "  def add_cb (self, cb):\n",
        "    self.cbs.append(cb)\n",
        "    \n",
        "  #----------------------------------------------------\n",
        "  # Fire a callback event\n",
        "  #----------------------------------------------------\n",
        "  def fire(self, event, **kwargs):\n",
        "    for key, value in kwargs.items(): \n",
        "      #print (\"%s == %s\" %(key, value))\n",
        "      setattr(self, key, value)\n",
        "    for cb in self.cbs:\n",
        "      cb.process(event, self)\n",
        "    \n",
        "  #----------------------------------------------------\n",
        "  # Run one training batch\n",
        "  #----------------------------------------------------\n",
        "  def _tr_batch(self, i_batch, xb, yb):\n",
        "    try:\n",
        "      self.fire(EV_BEGIN_TR_BATCH, i_batch=i_batch, xb=xb, yb=yb, i_tr_iter=self.i_tr_iter+1)\n",
        "\n",
        "      # Run the forward pass and compute the loss\n",
        "      self.yhat = self.model(self.xb)\n",
        "      self.fire(EV_AFTER_TR_PRED)\n",
        "\n",
        "      yb = self.yb if isinstance(self.yb, list) else [self.yb]\n",
        "      self.loss = self.loss_func(self.yhat, *yb)\n",
        "      self.fire(EV_AFTER_TR_LOSS)\n",
        "\n",
        "      # Run the backward pass to compute gradients\n",
        "      self.loss.backward()\n",
        "      self.fire(EV_AFTER_TR_BACKWARD)\n",
        "        \n",
        "      # Now optimiser uses the gradients to update the weights and biases of all layers\n",
        "      self.opt.step()\n",
        "      self.fire(EV_AFTER_TR_OPTSTEP)\n",
        "\n",
        "      self.opt.zero_grad()\n",
        "      \n",
        "    except CancelBatchException:\n",
        "      self.fire(EV_CANCEL_TR_BATCH)\n",
        "    finally:\n",
        "      self.fire(EV_END_TR_BATCH)\n",
        "    \n",
        "  #----------------------------------------------------\n",
        "  # Run one epoch of training batches\n",
        "  #----------------------------------------------------\n",
        "  def _tr_epoch(self):\n",
        "    try:\n",
        "      self.fire(EV_BEGIN_TR, num_batches=len(self.tr_dl))\n",
        "      self.model.train()\n",
        "      \n",
        "      # Get data for the next batch\n",
        "      for i_batch, (xb, yb) in enumerate(self.tr_dl):\n",
        "        self._tr_batch(i_batch, xb, yb)\n",
        "\n",
        "    except CancelEpochException:\n",
        "      self.fire(EV_CANCEL_TR)\n",
        "    finally:\n",
        "      self.fire(EV_END_TR)    \n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Run one validation batch\n",
        "  #----------------------------------------------------\n",
        "  def _val_batch(self, i_batch, xb, yb):\n",
        "    try:\n",
        "      self.fire(EV_BEGIN_VAL_BATCH, i_batch=i_batch, xb=xb, yb=yb)\n",
        "\n",
        "      self.yhat = self.model(self.xb)\n",
        "      self.fire(EV_AFTER_VAL_PRED)\n",
        "\n",
        "      yb = self.yb if isinstance(self.yb, list) else [self.yb]\n",
        "      self.loss = self.loss_func(self.yhat, *yb)\n",
        "      self.fire(EV_AFTER_VAL_LOSS)\n",
        "            \n",
        "      self.fire(EV_END_VAL_BATCH)\n",
        "      \n",
        "    except CancelBatchException:\n",
        "      self.fire(EV_CANCEL_VAL_BATCH)\n",
        "    finally:\n",
        "      self.fire(EV_END_VAL_BATCH)\n",
        "    \n",
        "  #----------------------------------------------------\n",
        "  # Run one epoch of validation batches\n",
        "  #----------------------------------------------------\n",
        "  def _val_epoch(self):\n",
        "    try:\n",
        "      self.fire(EV_BEGIN_VAL, num_batches=len(self.val_dl))\n",
        "      # Run the validation loop\n",
        "      self.model.eval()\n",
        "\n",
        "      with torch.no_grad():\n",
        "        \n",
        "        # Get data for the next batch\n",
        "        for i_batch, (xb, yb) in enumerate(self.val_dl):\n",
        "          self._val_batch(i_batch, xb, yb)\n",
        "\n",
        "    except CancelEpochException:\n",
        "      self.fire(EV_CANCEL_VAL)\n",
        "    finally:\n",
        "      self.fire(EV_END_VAL)\n",
        "    \n",
        "  #----------------------------------------------------\n",
        "  # Run the complete loop for all epochs\n",
        "  #----------------------------------------------------\n",
        "  def fit(self, num_epochs):\n",
        "    try:\n",
        "      self.fire(EV_BEGIN_FIT, num_epochs=num_epochs, i_tr_iter=-1)\n",
        "\n",
        "      for i_epoch in range(self.num_epochs):\n",
        "        self.fire(EV_BEGIN_EPOCH, i_epoch=i_epoch)\n",
        "\n",
        "        self._tr_epoch()\n",
        "        if (self.val_dl):\n",
        "          self._val_epoch()\n",
        "\n",
        "        self.fire(EV_END_EPOCH)\n",
        "\n",
        "    except CancelFitException:\n",
        "      self.fire(EV_CANCEL_FIT)\n",
        "    finally:\n",
        "      self.fire(EV_END_FIT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vsiuICYQstz"
      },
      "source": [
        "### Callbacks - Metrics, Abort, Progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "585kP7dt5Uty"
      },
      "source": [
        "#export\n",
        "\n",
        "class MetricsGrp(Callback):\n",
        "  def __init__(self, metrics):\n",
        "    self.metrics = metrics\n",
        "    # !!!!! Register callbacks for each metric\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print headers for all the result columns\n",
        "  # ----------------------------   \n",
        "  def begin_fit(self, ctx):\n",
        "    # ['epoch', 'tr_loss', 'smooth_loss', 'val_loss', 'metric1', 'metric2', ..'time']\n",
        "    headers = ['epoch']\n",
        "    for metric in self.metrics: headers += metric.header\n",
        "    headers += ['time']\n",
        "    ctx.logger(headers)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Track start time at the beginning of each epoch\n",
        "  # ----------------------------   \n",
        "  def begin_epoch(self, ctx):\n",
        "    ctx.start_time = time.time()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print results at the end of each epoch\n",
        "  # ----------------------------   \n",
        "  def end_epoch(self, ctx):\n",
        "    # Flattened metric results and epoch time taken\n",
        "    values = [results for metric in self.metrics for results in metric._results()]\n",
        "    epoch_time = [format_time(time.time() - ctx.start_time)]\n",
        "    #for metric in self.metrics: values += metric._results()\n",
        "\n",
        "    # Epoch number, formatted metric results, and epoch time\n",
        "    res = [str(ctx.i_epoch)]\n",
        "    res += [f'{val:.6f}' for val in values]\n",
        "    res += epoch_time\n",
        "\n",
        "    ctx.logger(res)\n",
        "\n",
        "    # Report metrics to the DTR\n",
        "    if (ctx.dtr): self._report(ctx.dtr, values + epoch_time)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Report metrics to the DTR\n",
        "  # ----------------------------   \n",
        "  def _report(self, dtr, results):\n",
        "    headers = [header for metric in self.metrics for header in metric.header] + ['time']\n",
        "    epoch_metrics = {header:result for header, result in zip(headers, results)}\n",
        "    dtr.update_epoch(epoch_metrics)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Base class for all Metrics callbacks\n",
        "#\n",
        "# It handles some common functionality such as managing the metric result value (one or more)\n",
        "# that it computes per epoch. It resets that value at the\n",
        "# end of each epoch. It provides abstract methods to do any necessary computations\n",
        "# at the end of each batch and at the end of each epoch. The child class provides\n",
        "# implementations for these methods. It also accumulates the inputs (ie. preds and targs)\n",
        "# after each batch, which the child class can use for its end-epoch calculations\n",
        "# if it needs.\n",
        "#----------------------------------------------------\n",
        "class MetricsBaseCB(Callback):\n",
        "  header = ['metric']\n",
        "\n",
        "  def __init__(self, accumulate=False):\n",
        "    self.num_value = len(self.header)\n",
        "    self.accumulate = accumulate\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset any state, when training starts and at beginning of each epoch\n",
        "  # ----------------------------   \n",
        "  def _reset(self, begin_fit=False):\n",
        "    pass\n",
        "\n",
        "  # ----------------------------\n",
        "  # Return the metric values\n",
        "  # ----------------------------   \n",
        "  def _results(self):\n",
        "    values = [self.value] if (self.num_value == 1) else self.value\n",
        "    values = [val.item() if (isinstance(val, torch.Tensor)) else val for val in values]\n",
        "    return values\n",
        "\n",
        "  # ----------------------------\n",
        "  # Do any required calculations at the end of the batch. A flag indicates if it\n",
        "  # is a training or validation batch.\n",
        "  # Functionality gets implemented within the child callback.\n",
        "  # ----------------------------   \n",
        "  def _calc_batch(self, ctx, is_val=True):\n",
        "    pass\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset the accumulated values\n",
        "  # ----------------------------   \n",
        "  def _reset_accumulate(self):\n",
        "    # Accumulated 'yhat' predictions and 'yb' targets\n",
        "    self.yhat, self.yb = None, None\n",
        "\n",
        "  # ----------------------------\n",
        "  # Accumulate the target and preds after each batch so that they\n",
        "  # can be used for end-of-epoch calculations\n",
        "  # ----------------------------   \n",
        "  def _accumulate_batch(self, ctx):\n",
        "    if (not self.accumulate):\n",
        "      return\n",
        "\n",
        "    if (self.yhat is None):\n",
        "      # Initialise for the first batch of the epoch. Cloning copies the type, device\n",
        "      # and size of the tensor.\n",
        "      self.yhat = ctx.yhat.clone().detach()\n",
        "      self.yb = ctx.yb.clone().detach()\n",
        "    else:\n",
        "      # Concatenate this batch data to the accumulated data from previous batches\n",
        "      self.yhat = torch.cat((self.yhat, ctx.yhat.detach()))\n",
        "      self.yb = torch.cat((self.yb, ctx.yb.detach()))\n",
        "\n",
        "  # ----------------------------\n",
        "  # Do any required calculations at the end of the epoch\n",
        "  # ----------------------------   \n",
        "  def _calc_epoch(self, ctx):\n",
        "    pass\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset all metrics when training starts\n",
        "  # ----------------------------   \n",
        "  def begin_fit(self, ctx):\n",
        "    self._reset(begin_fit=True)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset all metrics at the beginning of each epoch\n",
        "  # ----------------------------   \n",
        "  def begin_epoch(self, ctx):\n",
        "    self.value = 0. if (self.num_value == 1) else [0.] * self.num_value\n",
        "    self._reset_accumulate()\n",
        "    self._reset()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Calculate training metrics for each batch\n",
        "  # ----------------------------   \n",
        "  def after_tr_loss(self, ctx):\n",
        "    with torch.no_grad():\n",
        "      self._calc_batch(ctx, is_val=False)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Calculate validation metrics for each batch\n",
        "  # ----------------------------   \n",
        "  def after_val_loss(self, ctx):\n",
        "    self._calc_batch(ctx)\n",
        "    self._accumulate_batch(ctx)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print results at the end of each epoch\n",
        "  # ----------------------------   \n",
        "  def end_epoch(self, ctx):\n",
        "    with torch.no_grad():\n",
        "      self._calc_epoch(ctx)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Calculate an Average value per epoch using the given metric function\n",
        "#----------------------------------------------------\n",
        "class AverageMetricsCB(MetricsBaseCB):\n",
        "  header = ['avg']\n",
        "\n",
        "  def __init__(self, metric_fn):\n",
        "    self.metric_fn = metric_fn\n",
        "    self.header = [metric_fn.__name__]\n",
        "    super().__init__()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Count of total number of sample rows in an epoch\n",
        "  # ----------------------------\n",
        "  def _reset(self, begin_fit=False):\n",
        "    self.total_sz = 0\n",
        "\n",
        "  # ----------------------------\n",
        "  # Add up the value returned by the metric function for each batch. It will be\n",
        "  # averaged at the end of the epoch. Metrics are computed only for validation batches.\n",
        "  # ----------------------------   \n",
        "  def _calc_batch(self, ctx, is_val=True):\n",
        "    if (is_val):\n",
        "      batch_sz = ctx.yb.size(0)\n",
        "      self.total_sz += batch_sz\n",
        "      self.value += self.metric_fn(ctx.yhat, ctx.yb) * batch_sz\n",
        "\n",
        "  # ----------------------------\n",
        "  # Compute the average at the end of the epoch\n",
        "  # ----------------------------\n",
        "  def _calc_epoch(self, ctx):\n",
        "    self.value = self.value / self.total_sz\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Track the Training and Validation Loss per epoch, already \n",
        "# calculated by the loss function.\n",
        "# This is the only metric which is computed for both training and validation\n",
        "#----------------------------------------------------\n",
        "class LossMetricsCB(MetricsBaseCB):\n",
        "  header = ['tr_loss', 'smooth_loss', 'val_loss']\n",
        "  beta=0.98\n",
        "\n",
        "  # ----------------------------\n",
        "  # Count of total number of sample rows in an epoch\n",
        "  # ----------------------------\n",
        "  def _reset(self, begin_fit=False):\n",
        "    self.total_sz = 0\n",
        "\n",
        "    # Initialise only once when training starts, but don't reset after each epoch\n",
        "    if (begin_fit):\n",
        "      self.mov_avg = 0\n",
        "      self.n = 0\n",
        "\n",
        "  # ----------------------------\n",
        "  # Add up the loss for each training and validation batch\n",
        "  # ----------------------------   \n",
        "  def _calc_batch(self, ctx, is_val=True):\n",
        "    if (is_val):\n",
        "      # Validation loss\n",
        "      batch_sz = ctx.yb.size(0)\n",
        "      self.total_sz += batch_sz\n",
        "      self.value[2] += ctx.loss * batch_sz\n",
        "    else:\n",
        "      # Training loss\n",
        "      loss = ctx.loss\n",
        "      self.value[0] += ctx.loss\n",
        "\n",
        "      # Smoothed training loss based on moving average\n",
        "      self.n += 1\n",
        "      self.mov_avg = self.beta * self.mov_avg + (1 - self.beta) * loss\n",
        "      self.value[1] = self.mov_avg / (1 - self.beta ** self.n)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Compute the average at the end of the epoch\n",
        "  # ----------------------------\n",
        "  def _calc_epoch(self, ctx):\n",
        "    # Calculate Training loss\n",
        "    # Smoothed Training loss is already updated after each batch\n",
        "    self.value[0] = self.value[0] / len(ctx.tr_dl)\n",
        "\n",
        "    # Calculate Validation loss\n",
        "    if (self.total_sz > 0):\n",
        "      self.value[2] = self.value[2] / self.total_sz\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Roc Auc score per epoch\n",
        "#----------------------------------------------------\n",
        "from sklearn.metrics import roc_auc_score\n",
        "class RocAucMetricsCB(MetricsBaseCB):\n",
        "  header = ['roc_auc']\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(accumulate=True)\n",
        "\n",
        "  def _calc_epoch(self, ctx):\n",
        "    yhat = torch.sigmoid(self.yhat)\n",
        "    #yhat = F.softmax(ctx.yhat, dim=1)[:,-1]\n",
        "    roc_score = roc_auc_score(self.yb.cpu().numpy(), yhat.cpu().numpy())\n",
        "    self.value = roc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmyCd5q1RIXt"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Callback to calculate training and validation metrics\n",
        "# We are given a dictionary of metric names and metric functions {'accuracy': accuracy_fn, 'f1': f1_fn, ...}\n",
        "#----------------------------------------------------\n",
        "class MetricsCB(Callback):\n",
        "  def __init__(self, metric_dict):\n",
        "    self.metric_dict = metric_dict\n",
        "    self._reset()\n",
        "  \n",
        "  # ----------------------------\n",
        "  # Reset all our metrics to 0\n",
        "  # ----------------------------   \n",
        "  def _reset(self):\n",
        "    # Reset training and validation metrics\n",
        "    # Training metrics are [metric1_tr_value, metric2_tr_value, ...]\n",
        "    # Similarly, validation metrics are [metric1_val_value, metric2_val_value, ...]\n",
        "    self.metrics_tr = len(self.metric_dict) * [0.]\n",
        "    self.metrics_val = len(self.metric_dict) * [0.]\n",
        "\n",
        "    # Reset total training loss and total validation loss\n",
        "    self.tot_loss_tr = 0.\n",
        "    self.tot_loss_val = 0.\n",
        "  \n",
        "  # ----------------------------\n",
        "  # Format the metric values for training or validation. Calculate the average\n",
        "  # value of that metric by dividing by number of iterations\n",
        "  # ----------------------------   \n",
        "  def _results(self, tot_loss, metrics, nv):\n",
        "    # Format the loss value\n",
        "    res = ['{0:.6f}'.format(tot_loss/nv)]\n",
        "\n",
        "    # Format the metric values\n",
        "    for i, metric_name in enumerate(self.metric_dict.keys()):\n",
        "      res += ['{0:.6f}'.format(metrics[i]/nv)]\n",
        "\n",
        "    return (res)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Calculate values of each metric using the metric function and accumulate it\n",
        "  # by adding it to the sum of all previous values of that metric \n",
        "  # ----------------------------   \n",
        "  def _calc_metrics(self, metrics, ctx):\n",
        "    for i, metric_fn in enumerate(self.metric_dict.values()):\n",
        "      metrics[i] += metric_fn(ctx.yhat, ctx.yb)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print headers for all the result columns\n",
        "  # ----------------------------   \n",
        "  def begin_fit(self, ctx):\n",
        "    # ['loss', 'metric1', 'metric2', ..]\n",
        "    metric_names = ['loss'] + list(self.metric_dict.keys())\n",
        "    # ['epoch', ...metric names..., 'time']\n",
        "    headers = ['epoch'] + [f'train_{n}' for n in metric_names] + [f'valid_{n}' for n in metric_names] + ['time']\n",
        "    ctx.logger(headers)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset all metrics at the beginning of each epoch\n",
        "  # ----------------------------   \n",
        "  def begin_epoch(self, ctx):\n",
        "    self._reset()\n",
        "    ctx.start_time = time.time()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Calculate training metrics for each batch\n",
        "  # ----------------------------   \n",
        "  def after_tr_loss(self, ctx):\n",
        "    with torch.no_grad():\n",
        "      self.tot_loss_tr += ctx.loss\n",
        "      self._calc_metrics(self.metrics_tr, ctx)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Calculate validation metrics for each batch\n",
        "  # ----------------------------   \n",
        "  def after_val_loss(self, ctx):\n",
        "    self.tot_loss_val += ctx.loss\n",
        "    self._calc_metrics(self.metrics_val, ctx)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print results at the end of each epoch\n",
        "  # ----------------------------   \n",
        "  def end_epoch(self, ctx):  \n",
        "    res = [str(ctx.i_epoch)]\n",
        "    res += self._results(self.tot_loss_tr, self.metrics_tr, len(ctx.tr_dl))\n",
        "    res += self._results(self.tot_loss_val, self.metrics_val, len(ctx.val_dl))\n",
        "    res += [format_time(time.time() - ctx.start_time)]\n",
        "    ctx.logger(res)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZZLCRSxbYIi"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Callback to test aborting of training\n",
        "#----------------------------------------------------\n",
        "class AbortTrainCB(Callback):\n",
        "  def __init__(self, abort_iter=5):\n",
        "    self.abort_iter = abort_iter\n",
        "\n",
        "  #def begin_tr_batch(self, ctx):\n",
        "  #  print(ctx.num_epochs, ctx.i_epoch, ctx.num_batches, ctx.i_batch, ctx.i_tr_iter)\n",
        "\n",
        "  def after_tr_optstep(self, ctx):\n",
        "    # +1 because i_tr_iter starts from 0\n",
        "    if (ctx.i_tr_iter + 1 >= self.abort_iter):\n",
        "      raise CancelFitException()\n",
        "  \n",
        "#----------------------------------------------------\n",
        "# Callback to show progress indicators using Fastai's progress widget\n",
        "# Two progress bars are displayed - the first one shows the number of epochs and\n",
        "# the second one shows the batches within the epoch\n",
        "#----------------------------------------------------\n",
        "class ProgressCallback(Callback):\n",
        "  def begin_fit(self, ctx):\n",
        "    # master_bar displays the epoch progress and the child progress_bar displays the batch progress. \n",
        "    # We create one at the beginning of each training/validation phase, and update it at the end of each batch. \n",
        "    self.mbar = master_bar(range(ctx.num_epochs))\n",
        "    self.mbar.on_iter_begin()\n",
        "    # Change the logger to the write function of the master bar, so everything gets written to the progress bar\n",
        "    ctx.logger = partial(self.mbar.write, table=True)\n",
        "        \n",
        "  def end_fit(self, ctx): self.mbar.on_iter_end()\n",
        "  def end_tr_batch(self, ctx): self.pbar.update(ctx.i_batch)\n",
        "  def end_val_batch(self, ctx): self.pbar.update(ctx.i_batch)\n",
        "  def begin_tr(self, ctx): self.set_pbar(ctx.tr_dl, ctx.i_epoch)\n",
        "  def begin_val(self, ctx): self.set_pbar(ctx.val_dl, ctx.i_epoch)\n",
        "        \n",
        "  def set_pbar(self, dl, i_epoch):\n",
        "    self.pbar = progress_bar(dl, parent=self.mbar)\n",
        "    self.mbar.update(i_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alykHwifyt_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5dc538f-aae6-4584-fa36-558e9e70844c"
      },
      "source": [
        "def get_linear_model(inp_size, n_classes, lr=0.5, nh=50):\n",
        "    model = nn.Sequential(nn.Linear(inp_size,nh), nn.ReLU(), nn.Linear(nh, n_classes))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)\n",
        "  \n",
        "def run_mnist(cbs, num_epochs, repro=False, dtr=None):\n",
        "  x_train,y_train,x_valid,y_valid = get_mnist_data()\n",
        "  train_ds,valid_ds = MultiDimDataset(x_train, y_train), MultiDimDataset(x_valid, y_valid)\n",
        "  train_dl,valid_dl = get_dls(train_ds, valid_ds, bs=512)\n",
        "  n_classes = y_train.max().item()+1\n",
        "  loss_func = F.cross_entropy\n",
        "\n",
        "  if (repro):\n",
        "    torch.manual_seed(0)\n",
        "  model, opt = get_linear_model(train_dl.dataset.x.shape[1], n_classes=n_classes, lr=0.5, nh=50)\n",
        "  loop = Trainer(train_dl, valid_dl, model, opt, loss_func, cbs, dtr)\n",
        "  loop.fit(num_epochs)\n",
        "  return(loop)\n",
        "  \n",
        "abort_cbs = [AbortTrainCB()]\n",
        "metrics_cbs = [MetricsCB({\"acc\": accuracy})]\n",
        "progress_cbs = [ProgressCallback()] + metrics_cbs\n",
        "_ = run_mnist(metrics_cbs, 1, True)\n",
        "_ = run_mnist(progress_cbs, 2, True)\n",
        "_ = run_mnist(abort_cbs, 1, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['epoch', 'train_loss', 'train_acc', 'valid_loss', 'valid_acc', 'time']\n",
            "['0', '0.675446', '0.800317', '0.303038', '0.912171', '00:00']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      \n",
              "    </div>\n",
              "    \n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_acc</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>valid_acc</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.675446</td>\n",
              "      <td>0.800317</td>\n",
              "      <td>0.303038</td>\n",
              "      <td>0.912171</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.297040</td>\n",
              "      <td>0.912553</td>\n",
              "      <td>0.248718</td>\n",
              "      <td>0.929237</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I99Ng3byKneS"
      },
      "source": [
        "### Cuda Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1KkLIKSKps4"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Callback which puts the model, inputs and targets on the same device\n",
        "#----------------------------------------------------\n",
        "class CudaCB(Callback):\n",
        "  def __init__(self, device):\n",
        "    self.device=device\n",
        "\n",
        "  def _do_data(self, data):\n",
        "    if (isinstance(data, list)):\n",
        "      device_data = [d.to(self.device) for d in data]\n",
        "    else:\n",
        "      device_data = data.to(self.device)\n",
        "    return device_data\n",
        "\n",
        "  def _do_batch(self, ctx):\n",
        "    #ctx.xb, ctx.yb = ctx.xb.to(self.device), ctx.yb.to(self.device)\n",
        "    ctx.xb, ctx.yb = self._do_data (ctx.xb), self._do_data (ctx.yb)\n",
        "  \n",
        "  def begin_fit(self, ctx):\n",
        "    ctx.model.to(self.device)\n",
        "    \n",
        "  def begin_tr_batch(self, ctx):\n",
        "    self._do_batch(ctx)\n",
        "\n",
        "  def begin_val_batch(self, ctx): \n",
        "    self._do_batch(ctx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljk77iuxLIVn"
      },
      "source": [
        "### Tensorboard and Pandas Integration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NSm5OyXLQUv"
      },
      "source": [
        "#export\n",
        "#----------------------------------------------------\n",
        "# Pytorch integrates with Tensorboard via torch.utils.tensorboard.SummaryWriter, which is \n",
        "# a Pytorch-compatible version of Tensorflow's SummaryWriter, and is used in a similar way\n",
        "# \n",
        "# The SummaryWriter must be opened, giving it a file path where it writes the metrics.\n",
        "# Then any results that you want to track can be written to this SummaryWriter. Finally\n",
        "# that data can be flushed and the SummaryWriter is closed.\n",
        "#----------------------------------------------------\n",
        "\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Outputs debug results to Tensorboard for visualisation\n",
        "#----------------------------------------------------\n",
        "class DebugTensorboard():\n",
        "  def __init__(self, log_dir='tbtry'):\n",
        "    self.run_id = None\n",
        "    self.writer = None\n",
        "    self.log_dir = Path.cwd() / log_dir\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Initialise the Summary Writer at the start of a run, so that result data can be written to it\n",
        "  # for visualisation by Tensorboard\n",
        "  #----------------------------------------------------\n",
        "  def start_run(self, run_id):\n",
        "    self.run_id = run_id\n",
        "    run_path = self.log_dir / self.run_id \n",
        "    self.writer = SummaryWriter(run_path)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Close the Summary Writer at the end of a run, so that result data written so far is flushed\n",
        "  # to Tensorboard\n",
        "  #----------------------------------------------------\n",
        "  def end_run(self):\n",
        "    self.writer.close()\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Histogram\n",
        "  #----------------------------------------------------\n",
        "  def add_hist(self, tag, data, step):\n",
        "    self.writer.add_histogram(tag, data, step)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Scalars\n",
        "  #----------------------------------------------------\n",
        "  def add_scalar(self, tag, data, step):\n",
        "    self.writer.add_scalar(tag, data, step)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Image and Model Graph\n",
        "  #----------------------------------------------------\n",
        "  def add_image_graph(self, arch, images):\n",
        "    grid = torchvision.utils.make_grid(images)\n",
        "    writer.add_image('images', grid, 0)\n",
        "    writer.add_graph(arch, images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KESBQWZ3qhU1"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Outputs debug results to Pandas\n",
        "#----------------------------------------------------\n",
        "class DebugPandas():\n",
        "  #----------------------------------------------------\n",
        "  # Create a tuple of 4 dataframes from the result rows\n",
        "  # (run + epoch rows, batch rows, layer rows, all rows)\n",
        "  #----------------------------------------------------\n",
        "  def create_dfs (self, all_rows):\n",
        "    all_df = pd.DataFrame(all_rows)\n",
        "    run_df = self._create_subdf(all_df, 'run')\n",
        "    epoch_df = self._create_subdf(all_df, 'epoch')\n",
        "    run_df = run_df.append(epoch_df)\n",
        "\n",
        "    batch_df = self._create_subdf(all_df, 'batch')\n",
        "    layer_df = self._create_subdf(all_df, 'layer')\n",
        "    return ((run_df, batch_df, layer_df, all_df))\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a subset of the full dataframe containing only the rows\n",
        "  # of the given row 'sub_type'\n",
        "  #----------------------------------------------------\n",
        "  def _create_subdf(self, all_df, sub_type):\n",
        "    # Select only the rows of the given sub type\n",
        "    sub_df = all_df[all_df['row_type'] == sub_type]\n",
        "\n",
        "    # Exclude any columns which have only NaNs everywhere. \n",
        "    sub_cols = sub_df.columns[sub_df.notna().any()].tolist()\n",
        "    sub_df = sub_df[sub_cols]\n",
        "\n",
        "    return sub_df\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Plot standard metrics after a training run, based on the result dataframes.\n",
        "  # Columns that contain results for any additional application-specific metrics can \n",
        "  # also be passed in.\n",
        "  #----------------------------------------------------\n",
        "  @staticmethod\n",
        "  def display_metrics(run_df, batch_df, app_metrics=[]):\n",
        "    p = Plotter()\n",
        "    run_cols = ['tr_loss', 'smooth_loss', 'val_loss'] + app_metrics\n",
        "    run_df[run_cols] = run_df[run_cols].astype('float64')\n",
        "    p.plot_grid ('line', run_df, run_cols, 'epoch_id')\n",
        "    p.plot_grid ('line', batch_df, ['loss', 'lr', 'mom'], 'iter', hue=\"batch_type\")\n",
        "    p.create_subplot ('line', batch_df[batch_df['batch_type'] == 'train'], 'iter', 'loss')\n",
        "    p.create_subplot ('line', batch_df[batch_df['batch_type'] == 'val'], 'iter', 'loss')\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # TODO: !!!!!!!!! This is the method that should be called externally to compare\n",
        "  # the results of two different runs. Internally, this method should call the below\n",
        "  # methods to compare batch_results, activation_results and param_results and then\n",
        "  # return a consolidated status.\n",
        "  #----------------------------------------------------\n",
        "  def compare_results(dtr1, dtr2):\n",
        "    pass\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Compare the batch result dataframes for two runs. If they are equal it prints a\n",
        "  # status of 'Matched'. It returns a merged dataframe with the differences of the\n",
        "  # important columns.\n",
        "  #----------------------------------------------------\n",
        "  @staticmethod\n",
        "  def compare_batch_results(batch_df1, batch_df2):\n",
        "    batch_df1 = batch_df1[['batch_type', 'batch_id', 'pred', 'loss', 'lr']].reset_index(drop=True)\n",
        "    len_df1 = len(batch_df1)\n",
        "    batch_df2 = batch_df2[['batch_type', 'batch_id', 'pred', 'loss', 'lr']].reset_index(drop=True)\n",
        "    batch_df2 = batch_df2[:len_df1].reset_index(drop=True)\n",
        "\n",
        "    diff_df = batch_df1.merge(batch_df2, how='inner', left_on=['batch_type', 'batch_id'], right_on=['batch_type', 'batch_id'], suffixes=('_1', '_2'))\n",
        "    assert(len(diff_df) == len_df1)\n",
        "    diff_df['diff_pred'] = diff_df['pred_1'] - diff_df['pred_2']\n",
        "    diff_df['diff_loss'] = diff_df['loss_1'] - diff_df['loss_2']\n",
        "    diff_df['diff_lr'] = diff_df['lr_1'] - diff_df['lr_2']\n",
        "\n",
        "    unmatched_df = diff_df[(diff_df['diff_loss'] != 0.0)]\n",
        "    if (len(unmatched_df) != 0):\n",
        "      print ('Unmatched')\n",
        "    else:\n",
        "      print ('Matched')\n",
        "    return diff_df\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Compare the layer activation result dataframes for two runs. If they are equal it prints a\n",
        "  # status of 'Matched'. It returns a merged dataframe with the differences of the\n",
        "  # important columns.\n",
        "  #----------------------------------------------------\n",
        "  @staticmethod\n",
        "  def compare_activation_results(layer_df1, layer_df2):\n",
        "    # Get the activation rows\n",
        "    layer_df1 = layer_df1[(layer_df1['step_type'] == 'activation')]\n",
        "    layer_df2 = layer_df2[(layer_df2['step_type'] == 'activation')]\n",
        "\n",
        "    # Nothing to do if there are no activation rows\n",
        "    len_df1 = len(layer_df1)\n",
        "    len_df2 = len(layer_df2)\n",
        "    if ((len_df1 == 0) or (len_df2 == 0)):\n",
        "      print (f'No activation rows. df1: {len_df1}, df2: {len_df2}')\n",
        "      return None\n",
        "\n",
        "    # Get the columns to be matched\n",
        "    layer_df1 = layer_df1[['batch_type', 'batch_id', 'layer_name', 'out_activation']].reset_index(drop=True)\n",
        "    layer_df2 = layer_df2[['batch_type', 'batch_id', 'layer_name', 'out_activation']].reset_index(drop=True)\n",
        "\n",
        "    # If one dataframe has more rows, get the same number of rows from both dataframes\n",
        "    layer_df2 = layer_df2[:len_df1].reset_index(drop=True)\n",
        "\n",
        "    # Merge the columns of the two dataframes by joining on batch id\n",
        "    diff_df = layer_df1.merge(layer_df2, how='inner', left_on=['batch_type', 'batch_id', 'layer_name'], right_on=['batch_type', 'batch_id', 'layer_name'], suffixes=('_1', '_2'))\n",
        "\n",
        "    # Check that all rows got merged\n",
        "    assert(len(diff_df) == len_df1)\n",
        "\n",
        "    # Check that there is no difference between the activation values of both dataframes\n",
        "    diff_df['diff_activation'] = diff_df['out_activation_1'] - diff_df['out_activation_2']\n",
        "    unmatched_df = diff_df[(diff_df['diff_activation'] != 0.0)]\n",
        "\n",
        "    if (len(unmatched_df) != 0):\n",
        "      print ('Unmatched')\n",
        "    else:\n",
        "      print ('Matched')\n",
        "\n",
        "    return diff_df\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Compare the layer param result dataframes for two runs. If they are equal it prints a\n",
        "  # status of 'Matched'. It returns a merged dataframe with the differences of the\n",
        "  # important columns.\n",
        "  #----------------------------------------------------\n",
        "  @staticmethod\n",
        "  def compare_param_results(layer_df1, layer_df2):\n",
        "    # Get the param rows\n",
        "    layer_df1 = layer_df1[(layer_df1['step_type'] == 'param') & (layer_df1['batch_type'] == 'train')]\n",
        "    layer_df2 = layer_df2[(layer_df2['step_type'] == 'param') & (layer_df2['batch_type'] == 'train')]\n",
        "\n",
        "    # Nothing to do if there are no param rows\n",
        "    len_df1 = len(layer_df1)\n",
        "    len_df2 = len(layer_df2)\n",
        "    if ((len_df1 == 0) or (len_df2 == 0)):\n",
        "      print (f'No param rows. df1: {len_df1}, df2: {len_df2}')\n",
        "      return None\n",
        "    \n",
        "    # Get the columns to be matched\n",
        "    layer_df1 = layer_df1[['batch_type', 'batch_id', 'layer_name', 'param_mean', 'param_std', 'grad_mean', 'grad_std']].reset_index(drop=True)\n",
        "    layer_df2 = layer_df2[['batch_type', 'batch_id', 'layer_name', 'param_mean', 'param_std', 'grad_mean', 'grad_std']].reset_index(drop=True)\n",
        "\n",
        "    # If one dataframe has more rows, get the same number of rows from both dataframes\n",
        "    layer_df2 = layer_df2[:len_df1].reset_index(drop=True)\n",
        "\n",
        "    # Merge the columns of the two dataframes by joining on batch id\n",
        "    diff_df = layer_df1.merge(layer_df2, how='inner', left_on=['batch_type', 'batch_id', 'layer_name'], right_on=['batch_type', 'batch_id', 'layer_name'], suffixes=('_1', '_2'))\n",
        "\n",
        "    # Check that all rows got merged\n",
        "    assert(len(diff_df) == len_df1)\n",
        "\n",
        "    # Check that there is no difference between the param and grad values of both dataframes\n",
        "    diff_df['diff_param'] = diff_df['param_mean_1'] - diff_df['param_mean_2']\n",
        "    diff_df['diff_grad'] = diff_df['grad_mean_1'] - diff_df['grad_mean_2']\n",
        "    unmatched_df = diff_df[(diff_df['diff_param'] != 0.0) | (diff_df['diff_grad'] != 0.0)]\n",
        "\n",
        "    if (len(unmatched_df) != 0):\n",
        "      print ('Unmatched')\n",
        "    else:\n",
        "      print ('Matched')\n",
        "\n",
        "    return diff_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M02SuyEbZHcq"
      },
      "source": [
        "### Debug Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4RUtfNjtEQJ"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# This is a generic way to gather and report all metrics that are generated while running a model.\n",
        "# It has three key components:\n",
        "#   1. Collectors - any Callback, Hook or other component anywhere in the system can be 'probes' that collect data metrics\n",
        "#        about any aspect of the system. This could be high-level metrics, or low-level debugging information. They send the\n",
        "#        data they collect to the Debug Tracker\n",
        "#   2. Tracker - this is really the heart of the system. It is the core component which consolidates all data from all\n",
        "#        the various Collectors\n",
        "#   3. Reporters - these display the collected data through different output mediums for easy visualisation and analysis.\n",
        "#        eg. Tensorboard, Pandas, Pickle and potentially Matplotlib. This display could be in real-time while the run is in progress\n",
        "#        or at the end, after the run has finished\n",
        "#\n",
        "# Data Metrics are gathered at five levels:\n",
        "#   1. Run - this captures information relevant to the end-to-end run as a whole\n",
        "#   2. Epoch - this represents an epoch.\n",
        "#   3. Batch - this represents a mini-batch within an epoch. This captures batch-level information for all batches within\n",
        "#        an epoch.\n",
        "#   4. Step - this represents an intermediate operation (eg. forward, backward) during the execution of a batch. No metrics\n",
        "#        tracked for the Step, it is only needed to group Layers at the next level.\n",
        "#   5. Layer - this represents an internal data element of the model eg. a layer or composite layer, or a weight parameter\n",
        "#\n",
        "# These levels form a hierarchy, with each level being nested within the level above it. So, a Tracker captures multiple\n",
        "# Runs, each of which contains multiple Epochs, each of which contains multiple Batches. Each Batch has multiple Steps, and \n",
        "# each Step has multiple Layers within it.\n",
        "#\n",
        "# In general, Run, Epoch and Batch normally capture high-level metrics that are 'externally' reported, while Step and Layer\n",
        "# capture low-level metrics for debugging the internal working of the model\n",
        "#\n",
        "# This gives us one consistent mechanism for all metrics in the system, rather than have many different custom ways to \n",
        "# gather and report metrics eg. different debugging callbacks and hooks which gather different metrics for different models\n",
        "# and then report them differently by plotting custom graphs, printing to the screening or via Tensorboard. We also have\n",
        "# various other callbacks that do specific tasks like the MetricsCB, the Recorder that calculate different metrics \n",
        "# and statistics and then display them in different ways. Similarly the Optimiser has a custom method to print out\n",
        "# hyper-parameter values for various parameter groups. All of these can be consolidated to work in a consistent way.\n",
        "#\n",
        "# It also enables us to save metrics from a run and load them later for analysis. We could also potentially compare\n",
        "# metrics from one run with another, to examine trends and figure out if we're improving. Or even check whether two\n",
        "# runs give us identical results as a debugging test to ensure that we haven't broken anything when making code changes\n",
        "# to our application.\n",
        "#----------------------------------------------------\n",
        "\n",
        "#----------------------------------------------------\n",
        "# The format of the data is as follows:\n",
        "# Run:\n",
        "#   runs = [run_one, run_two, run_three, ...], where each is a DebugRun object\n",
        "#   run_one = {'run_id': 'Run-3 Mar 2020 5.14pm', 'num_epochs': 3, epochs=[epoch_one, epoch_two, ...]}\n",
        "#   Each epoch is a DebugEpoch object\n",
        "#   We could also track architecture settings 'hidden_sz': 1000, or 'graph': graph, for the model graph\n",
        "# \n",
        "# Epoch:\n",
        "#   epoch_one = {'epoch_id': 0, 'num_tr_batches': 75, 'num_val_batches': 75, batches=[batch_one, batch_two, ...]}\n",
        "#   Each batch is a DebugBatch object\n",
        "#   We could also track 'metrics': metrics\n",
        "# \n",
        "# Batch:\n",
        "#   batch_one = {'batch-id': 2-12, 'iter': 19, 'type': 'train', 'pred': 2.1982, 'loss': 0.0372, 'steps': [step_one, step_two, ...]}\n",
        "#   Each step is a DebugStep object\n",
        "#   We could also track 'hyper_params': hyper_params\n",
        "#   eg. hyper_params = {'lr': [lr_gr1, lr_gr2, lr_gr3], 'mom': [mom_gr1, mom_gr2, mom_gr3]}\n",
        "#   Validation batches we don't have to track param_steps, and rarely activation steps.\n",
        "#\n",
        "# Step:\n",
        "#   step_one = {'step_id': 4, 'step_type': 'activation', 'step_operation': 'fwd', 'layers': [layer_one, layer_two, ...]}\n",
        "#   step_two = {'step_id': 5, 'step_type': 'param', 'step_operation': 'discriminator loss', 'layers': [layer_one, layer_two, ...]}\n",
        "#   Each layer is a DebugLayer object\n",
        "#\n",
        "# Layer:\n",
        "#   For activation steps, used during both 'backwards' and 'optimisation'\n",
        "#     layer_one = {'layer_name': '0.weight', 'data_mean': 0.234, 'data_std': 0.038, 'req_grad': True, 'grad_mean': 0.82, 'grad_std': 0.283}\n",
        "#   For param steps, used during the 'forward' pass\n",
        "#     layer_one = {'layer_name': 'input':, out_activation: 2.282}\n",
        "#     layer_two = {'layer_name': '0':, out_activation: 2.282}\n",
        "#     layer_three = {'layer_name': 'loss':, out_activation: 2.282}\n",
        "#\n",
        "# Results:\n",
        "#   run_results = [row_one, row_two, ...]\n",
        "#     Rows can be of different types, and are flattened ie. no nested sub-lists\n",
        "#     Rows include the ID fields from all its parent objects eg. a batch row includes the 'run_id' and 'epoch_id' from \n",
        "#     its parent run and epoch respectively and a layer row includes the ID fields from its parent run, epoch, batch and step.\n",
        "#       row_one = {'row_type': 'run', 'run_id': 'Run-3 Mar 2020 5.14pm', \n",
        "#                            'num_epochs': 3}\n",
        "#       row_two = {'row_type': 'epoch', 'run_id': 'Run-3 Mar 2020 5.14pm', \n",
        "#                            'epoch_id': 0, \n",
        "#                            'num_tr_batches': 75, 'num_val_batches': 75}\n",
        "#       row_three = {'row_type': 'batch', 'run_id': 'Run-3 Mar 2020 5.14pm', 'epoch_id': 0,\n",
        "#                            'batch-id': 2-12, 'iter': 19, 'type': 'train', \n",
        "#                            'pred': 2.1982, 'loss': 0.0372}\n",
        "#       row_four = {'row_type': 'layer', 'run_id': 'Run-3 Mar 2020 5.14pm', 'epoch_id': 0,\n",
        "#                            'batch-id': 2-12, 'iter': 19, 'type': 'train', \n",
        "#                            'step_id': 4, 'step_type': 'activation', 'step_operation': 'fwd', \n",
        "#                            'layer_name': 'input':, out_activation: 2.282}\n",
        "#\n",
        "# Note that here we're choosing to group Layers (ie. data) by Step (ie. operation) since the same 'operation' can be \n",
        "# performed on many layers one after the other. In other words, we're sorting by operation first and data second. \n",
        "# However we may sometimes want to sort by data first and by operation second. eg. analyse all changes to \n",
        "# a layer activation, or a weight parameter as it proceeds across different operations. This can be easily done at reporting\n",
        "# time. The Tensorboard reporting shows graphs by data anyway. And the Pandas results are flattened, allowing us to easily\n",
        "# sort by operation or by data.\n",
        "#----------------------------------------------------\n",
        "\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tracks information for a complete Run, consisting of mini-batches over a number of epochs\n",
        "#----------------------------------------------------\n",
        "class DebugRun():\n",
        "  # List of fields which uniquely identify a Run row\n",
        "  _id_names=['run_id']\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create an empty object with a unique run id.\n",
        "  # Data is stored in a dictionary\n",
        "  #----------------------------------------------------\n",
        "  def __init__(self, num_epochs):\n",
        "    timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    data = OrderedDict()\n",
        "    data['run_id'] = f'Run-{timestr}'\n",
        "    data['num_epochs'] = num_epochs\n",
        "    data['epochs'] = []\n",
        "    self.data = data\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update the information in my dictionary using the passed in data\n",
        "  #----------------------------------------------------\n",
        "  def update(self, run_data):\n",
        "    assert(isinstance(run_data, dict))\n",
        "    self.data.update(run_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Add an Epoch object to the run\n",
        "  #----------------------------------------------------\n",
        "  def add_epoch(self, epoch):\n",
        "    assert(isinstance(epoch, DebugEpoch))\n",
        "    self.data['epochs'].append(epoch)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # The current epoch is the last epoch in our list\n",
        "  #----------------------------------------------------\n",
        "  def get_current_epoch(self):\n",
        "    current_epoch_idx = len(self.data['epochs']) - 1\n",
        "    return self.data['epochs'][current_epoch_idx]\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Return the results at the end of the run. The hierarchy of\n",
        "  # objects in the run are flattened into a flat list of rows, where each row \n",
        "  # is a dictionary. There is one row per object in the heirarchy, except for the\n",
        "  # Step, whose row is merged into each Layer under it. Hence there are different\n",
        "  # types of row - a run row, batch rows and combined step+layer rows - with different\n",
        "  # fields for each type of row.\n",
        "  #\n",
        "  # Each row has some 'ID fields' and some 'data metric fields'. Note that these\n",
        "  # are IDs in the database sense, which identify a unique row. eg. a Run carries \n",
        "  # a unique 'run_id' to identify it and also carries some 'data' fields such \n",
        "  # as the 'number of epochs'. The data metric fields are what we really care about\n",
        "  # because they are values which we want to visualise and analyse.\n",
        "  #\n",
        "  # Similarly a Batch carries the 'batch_id', 'iteration number' and 'batch type' \n",
        "  # ID fields, which it then merges with the 'run_id' ID field of its parent Run\n",
        "  # to uniquely identify it.\n",
        "  #----------------------------------------------------\n",
        "  def get_results(self):\n",
        "    # Result is a list of rows\n",
        "    all_rows = []\n",
        "\n",
        "    # Prepare the Run row as a dictionary of all the non-list keys in the Run object\n",
        "    # and add it to our result list \n",
        "    run_row = OrderedDict((k,v) for k,v in self.data.items() if not isinstance(v, list))\n",
        "    run_row['row_type'] = 'run'\n",
        "    all_rows.append(run_row)\n",
        "\n",
        "    # Prepare a dictionary of all the 'unique ID fields' for a Run\n",
        "    run_id_data = {k:self.data[k] for k in self._id_names}\n",
        "    for epoch in self.data['epochs']:\n",
        "      # Get the result rows for each epoch\n",
        "      # Pass the Run ID fields to the Epoch object, so it can merge them with \n",
        "      # its own 'unique ID fields'.\n",
        "      epoch_rows = epoch.get_results(run_id_data)\n",
        "      # Add the epoch result rows to the result\n",
        "      all_rows.extend(epoch_rows)\n",
        "\n",
        "    return all_rows\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'{self.data}'\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tracks information for one epoch during a run\n",
        "#----------------------------------------------------\n",
        "class DebugEpoch():\n",
        "  # List of fields which identify an Epoch row\n",
        "  _id_names=['epoch_id']\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create an empty object with a unique epoch id.\n",
        "  # Data is stored in a dictionary\n",
        "  #----------------------------------------------------\n",
        "  def __init__(self, i_epoch):\n",
        "    data = OrderedDict()\n",
        "    # Concat the epoch number and batch number to generate a batch id\n",
        "    data['epoch_id'] = i_epoch\n",
        "    data['num_tr_batches'] = 0\n",
        "    data['num_val_batches'] = 0\n",
        "    data['batches'] = []\n",
        "    self.data = data\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update the information in my dictionary using the passed in data\n",
        "  #----------------------------------------------------\n",
        "  def update(self, epoch_data):\n",
        "    assert(isinstance(epoch_data, dict))\n",
        "    self.data.update(epoch_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Add a Batch object to the epoch\n",
        "  #----------------------------------------------------\n",
        "  def add_batch(self, batch):\n",
        "    assert(isinstance(batch, DebugBatch))\n",
        "    self.data['batches'].append(batch)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # The current batch is the last batch in our list\n",
        "  #----------------------------------------------------\n",
        "  def get_current_batch(self):\n",
        "    current_batch_idx = len(self.data['batches']) - 1\n",
        "    return self.data['batches'][current_batch_idx]\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Return the results for epoch, as a list of one epoch row, and all the \n",
        "  # batch rows within that epoch\n",
        "  #----------------------------------------------------\n",
        "  def get_results(self, run_id_data):\n",
        "    # Result is a list of rows\n",
        "    epoch_rows = []\n",
        "\n",
        "    # Prepare the data for the epoch as a dictionary of all the non-list keys in the Epoch object\n",
        "    epoch_data = OrderedDict((k,v) for k,v in self.data.items() if not isinstance(v, list))\n",
        "    # Create an epoch row by merging the Run's ID fields with the epoch data\n",
        "    epoch_row = {**run_id_data, **epoch_data}\n",
        "    epoch_row['row_type'] = 'epoch'\n",
        "    # and add it to our result list \n",
        "    epoch_rows.append(epoch_row)\n",
        "\n",
        "    # Prepare a dictionary of all the 'unique ID fields' for an Epoch\n",
        "    # Then merge it with the Run ID fields\n",
        "    epoch_id_data = {k:self.data[k] for k in self._id_names}\n",
        "    run_epoch_id_data = {**run_id_data, **epoch_id_data}\n",
        "\n",
        "    for batch in self.data['batches']:\n",
        "      # Get the result rows for each batch\n",
        "      # Pass the Run and Epoch ID fields to the Batch object, so it can merge them with \n",
        "      # its own 'unique ID fields'.\n",
        "      batch_rows = batch.get_results(run_epoch_id_data)\n",
        "      # Add the batch result rows to the result\n",
        "      epoch_rows.extend(batch_rows)\n",
        "\n",
        "    return epoch_rows\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tracks information for one mini-batch during a run\n",
        "#----------------------------------------------------\n",
        "class DebugBatch():\n",
        "  # List of fields which identify a Batch row\n",
        "  _id_names=['batch_id', 'iter', 'batch_type']\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create an empty object with a unique batch id.\n",
        "  # Data is stored in a dictionary\n",
        "  #----------------------------------------------------\n",
        "  def __init__(self, batch_type, i_epoch, i_batch, i_iter):\n",
        "    data = OrderedDict()\n",
        "    # Concat the epoch number and batch number to generate a batch id\n",
        "    data['batch_id'] = f'{i_epoch}-{i_batch}'\n",
        "    data['iter'] = i_iter\n",
        "    data['batch_type'] = batch_type\n",
        "    data['pred'] = 0.\n",
        "    data['loss'] = 0.\n",
        "    data['steps'] = []\n",
        "    self.data = data\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # \n",
        "  #----------------------------------------------------\n",
        "  def _flatten (self, data, flat_data):\n",
        "    for k, v in data.items():\n",
        "      if (isinstance(v, dict)):\n",
        "        flatten(v, flat_data)\n",
        "      elif (isinstance(v, list) and (len(v) == 1)):\n",
        "        flat_data.update({k: v[0]})\n",
        "      elif (isinstance(v, list) and (len(v) > 1)):\n",
        "        flat_data.update({f'{k}{i}': vi for i, vi in enumerate(v)})\n",
        "      else:\n",
        "        flat_data.update({k: v})\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update the information in my dictionary using the passed in data\n",
        "  #----------------------------------------------------\n",
        "  def update(self, batch_data):\n",
        "    assert(isinstance(batch_data, dict))\n",
        "\n",
        "    flat_data = {}\n",
        "    self._flatten(batch_data, flat_data)\n",
        "\n",
        "    self.data.update(flat_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Add a Step object to the batch\n",
        "  #----------------------------------------------------\n",
        "  def add_step(self, step_data):\n",
        "    steps = self.data['steps']\n",
        "    steps.append(step_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # The current step is the last step in our list. Except for a\n",
        "  # newly created batch for which no step has been added yet.\n",
        "  #----------------------------------------------------\n",
        "  def get_current_step(self):\n",
        "    num_steps = len(self.data['steps'])\n",
        "    if (num_steps == 0):\n",
        "      # No steps have been added yet, so one will have to be created\n",
        "      return None\n",
        "    else:\n",
        "      current_step_idx = num_steps - 1\n",
        "      return self.data['steps'][current_step_idx]\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Return the results for a batch, as a list of one batch row, and all the \n",
        "  # step rows within that batch\n",
        "  #----------------------------------------------------\n",
        "  def get_results(self, run_epoch_id_data):\n",
        "    # Result is a list of rows\n",
        "    batch_rows = []\n",
        "\n",
        "    # Prepare the data for the batch as a dictionary of all the non-list keys in the Batch object\n",
        "    batch_data = OrderedDict((k,v) for k,v in self.data.items() if not isinstance(v, list))\n",
        "    # Create a batch row by merging the Run's and Epoch's ID fields with the batch data\n",
        "    batch_row = {**run_epoch_id_data, **batch_data}\n",
        "    batch_row['row_type'] = 'batch'\n",
        "    # and add it to our result list \n",
        "    batch_rows.append(batch_row)\n",
        "\n",
        "    # Prepare a dictionary of all the 'unique ID fields' for a Batch\n",
        "    batch_id_data = {k:self.data[k] for k in self._id_names}\n",
        "\n",
        "    # Go through every Step, and every Layer in each Step in the batch and\n",
        "    # prepare one row per Layer. We don't create a separate row for Steps, as it\n",
        "    # doesn't have any 'data metric' fields.\n",
        "    for step in self.data['steps']:\n",
        "      # Prepare a dictionary of all the 'unique ID fields' for a Step\n",
        "      step_id_data = {k:step.data[k] for k in step._id_names}\n",
        "      for layer in step.data['layers']:\n",
        "        layer_data = layer.data\n",
        "        # Create a layer row by merging the Run and Epoch ID fields, Batch ID fields and \n",
        "        # Step ID fields with the Layer data\n",
        "        layer_row = {**run_epoch_id_data, **batch_id_data, **step_id_data, **layer_data}\n",
        "        layer_row['row_type'] = 'layer'\n",
        "        batch_rows.append(layer_row)\n",
        "\n",
        "    return batch_rows\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f'{self.data}'\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tracks information for one operation step within a batch\n",
        "# A 'step' is really any intermediate operation that you want to track during a batch. Think of it as \n",
        "# a 'milestone' or 'point in time' during the execution of a batch where you want to track the data \n",
        "# values of the layers of your model. So you can have as many as you want at any point in the training\n",
        "# loop. The 'step_operation' is a name to identify that step and can be any label that you choose.\n",
        "#\n",
        "# The typical steps are 'fwd', 'bkwd' and 'opt' for the forward pass, backward pass and optimiser update \n",
        "# operations respectively. However, you can include any other steps that you need for more complicated \n",
        "# training loops eg. for a GAN where you can have multiple backward passes or optimisation passes \n",
        "# within the same batch. So we can choose a distinct name for each operation to identify it.\n",
        "#\n",
        "# Steps are of two types, based on the type of data that they track viz. 'activation' to track the\n",
        "# output activation of a layer, and 'param' to track the parameter values and gradients of weight\n",
        "# and bias parameters.\n",
        "#\n",
        "# The 'step_id' is an integer number that is auto calculated and keeps incrementing every time a new\n",
        "# step is tracked, and is unique for a run, across all batches of all epochs. You can use it as \n",
        "# your 'timestep' on the X-axis while graphing the data values as they change during the execution\n",
        "# of a run. There are two sequences of step_id, one for the 'activation' steps and another for the\n",
        "# 'param' steps\n",
        "#----------------------------------------------------\n",
        "class DebugStep():\n",
        "    # List of fields which identify a Step row\n",
        "  _id_names=['step_id', 'step_operation', 'step_type']\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create an empty object with a unique step id, operation and\n",
        "  # step type. Data is stored in a dictionary\n",
        "  #----------------------------------------------------\n",
        "  def __init__(self, step_id, step_operation, step_type):\n",
        "    data = dict()\n",
        "    data['step_id'] = step_id\n",
        "    data['step_operation'] = step_operation\n",
        "    data['step_type'] = step_type\n",
        "    data['layers'] = []\n",
        "    self.data = data\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Add a Layer object to the step\n",
        "  #----------------------------------------------------\n",
        "  def add_layer(self, layer_data):\n",
        "    layers = self.data['layers']\n",
        "    layers.append(layer_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Does the given 'step_type' and 'step_operation' match my step type and\n",
        "  # operation?\n",
        "  #----------------------------------------------------\n",
        "  def is_same_step(self, step_type, step_operation):\n",
        "    return ((self.data['step_type'] == step_type) and\n",
        "            (self.data['step_operation'] == step_operation))\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Tracks information for one data element (either a layer or a parameter), as part of\n",
        "# an operation step within a batch.\n",
        "#\n",
        "# For instance, a 'forward' step involves multiple sequential layers each with its\n",
        "# own activation. Similarly a 'backward' step involves multiple weight and bias\n",
        "# parameters, each with its own parameter value and gradient.\n",
        "#----------------------------------------------------\n",
        "class DebugLayer():\n",
        "  # List of fields which identify a Step row\n",
        "  _id_names=['layer_name']\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a populated object with a layer name and data values. \n",
        "  # Data is stored in a dictionary\n",
        "  #----------------------------------------------------\n",
        "  def __init__(self, step_type, layer_name, layer_value, **kwargs):\n",
        "    data = dict()\n",
        "    data['layer_name'] = layer_name\n",
        "    if (step_type == 'activation'):\n",
        "      out_activation = layer_value\n",
        "      data['out_activation'] = out_activation.mean().item()\n",
        "    else:\n",
        "      param = layer_value\n",
        "      data['param_mean'] = param.data.mean().item()\n",
        "      data['param_std'] = param.data.std().item()\n",
        "      data['requires_grad'] = param.requires_grad\n",
        "      if (param.grad is not None):\n",
        "        data['grad_mean'] = param.grad.mean().item()\n",
        "        data['grad_std'] = param.data.std().item()\n",
        "\n",
        "    if (kwargs is not None):\n",
        "      data.update(kwargs)\n",
        "    self.data = data\n",
        "\n",
        "#----------------------------------------------------\n",
        "# \n",
        "# It is both a Callback as well as a regular class with additional methods that expose its own API.\n",
        "# In other words, it implements several of the Callback events as part of the training loop and also \n",
        "# has independent methods in its API which can be called directly by other components.\n",
        "#\n",
        "# These other components would usually be Callbacks that collect data metrics while processing their\n",
        "# own Callback events. They then use the DebugTrackers API to send their metrics to the DebugTracker\n",
        "# However, these components could also be Hooks which are triggered outside of a Callback event\n",
        "# and could send data to the DebugTracker to consolidate.\n",
        "#\n",
        "# Hence the Tracker works in conjunction with these other Callbacks and Hooks. By itself it\n",
        "# doesn't track much metric data of its own.\n",
        "#\n",
        "# The Tracker uses its Callback events to initialise the upper levels of the data hierarchy,\n",
        "# by creating a Run object at the beginning of the run, and Batch objects at the beginning of\n",
        "# each training and validation batch. This creates the 'skeleton' of the data and keeps it ready\n",
        "# but without any useful metrics to be tracked. Those metrics start getting added as various \n",
        "# Callbacks or Hooks start sending in their data via the Tracker API. They might update \n",
        "# metrics for the existing Run and Batch, or they might add Steps and Layers under the \n",
        "# Batches. Obviously they cannot add new Runs or Batches via the API, as those are enforced \n",
        "# within the Tracker via Callback events only.\n",
        "#\n",
        "# The API allows you to add a Layer but doesn't allow you to add a Step explicitly. The\n",
        "# Step gets added automatically by the Tracker whenever it is asked to add a Layer for \n",
        "# an operation that is different from the previous operation.\n",
        "#\n",
        "# Since everything is happening sequentially in time as we execute the training loop, the Tracker\n",
        "# has a sense of the Current Run, the Current Batch within it and the Current Step within\n",
        "# that. The Callback and Hook callers don't need to keep track of any of that state. They \n",
        "# do not need to know what the id of the current run is, or the iteration number of \n",
        "# the current batch and so on, as those are internally managed, assigned and incremented \n",
        "# by the Tracker. This simplifies the work of the callers because they can simply send any\n",
        "# new data metric they gather and the Tracker adds it to the right Run, Data or Step object\n",
        "# in the heirarchy. This also means that the API doesn't allow you to go back and update\n",
        "# previous Runs, Batches or Steps. \n",
        "# \n",
        "# Also note there is no notion of the Current Layer, so you can only add new Layers, \n",
        "# but cannot update an existing Layer. This is because a Layer has meaning only in \n",
        "# the context of an operation (ie. a Step) which is really just a distinct name for a \n",
        "# point in time within the execution of a batch. So it doesn't make sense to modify \n",
        "# a previous point in time. Callers are free to define another operation with \n",
        "# distinct labels to reflect a subsequent point in time. Since each Layer corresponds\n",
        "# to a specific data element such as a layer or a weight parameter, it is easy to\n",
        "# trace the state changes of that data element chronologically over the course of \n",
        "# multiple operations.\n",
        "#\n",
        "# In order to control how much data we collect and track, we can define some\n",
        "# simple filter criteria to select the batches and steps for which we track data. The\n",
        "# 'freq' lets us skip batches eg. 'freq=5' tracks data for 1 out of every 5 batches.\n",
        "# 'max_count' is the maximum index number of the batch within an epoch. \n",
        "# eg. 'max_count=3' will not track anything after the first 3 batches in each epoch.\n",
        "# Even for the first 3 batches, it applies the 'freq' to decide what to skip.\n",
        "# 'data_prefixes' is a list of prefix substrings to select the layer names.\n",
        "# eg. 'data_prefixes=['G_AB', 'D_AB']' tracks only those layers whose names begin\n",
        "# with either \"G_AB*\" or \"D_AB+\"\n",
        "#\n",
        "# The 'disp' is a tuple of two booleans used to turn on the Tensorboard and\n",
        "# Pandas reporters for displaying results.\n",
        "#----------------------------------------------------\n",
        "class DebugTracker(Callback):\n",
        "  def __init__(self, freq=1, max_count=5, data_prefixes=None, disp=(False, False)):\n",
        "    self.runs = []\n",
        "    self.freq = freq\n",
        "    self.max_count = max_count\n",
        "    self.data_prefixes = data_prefixes\n",
        "    # 'do' is True when the current batch is to be tracked\n",
        "    self.do = True\n",
        "    self.do_epoch = True\n",
        "    self.set_display(disp)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Start a run at the beginning of the training loop\n",
        "  #----------------------------------------------------\n",
        "  def begin_fit(self, ctx):\n",
        "    # Create a new Run object\n",
        "    new_run = self._create_run(ctx.num_epochs)\n",
        "    # Counter for validation iterations\n",
        "    self.val_iter = -1\n",
        "    if (self.tb is not None):\n",
        "      # Initialise Tensorboard for the run\n",
        "      run_name = new_run.data['run_id']\n",
        "      self.tb.start_run(f'{run_name}')\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create an Epoch object at the start of a new epoch\n",
        "  #----------------------------------------------------\n",
        "  def begin_epoch(self, ctx):\n",
        "    if (self._track_epoch(ctx.i_epoch)):\n",
        "      self._create_epoch(ctx.i_epoch)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update the number of training batches at the start of training batches within\n",
        "  # the epoch\n",
        "  #----------------------------------------------------\n",
        "  def begin_tr(self, ctx):\n",
        "    epoch_data = {}\n",
        "    epoch_data['num_tr_batches'] = ctx.num_batches\n",
        "    self.update_epoch(epoch_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a Batch object at the start of a new training batch\n",
        "  #----------------------------------------------------\n",
        "  def begin_tr_batch(self, ctx):\n",
        "    if (self._track_batch(ctx.i_epoch, ctx.i_batch)):\n",
        "      self._create_batch('train', ctx.i_epoch, ctx.i_batch, ctx.i_tr_iter)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update the number of validation batches at the start of validation batches\n",
        "  # within the epoch\n",
        "  #----------------------------------------------------\n",
        "  def begin_val(self, ctx):\n",
        "    epoch_data = {}\n",
        "    epoch_data['num_val_batches'] = ctx.num_batches\n",
        "    self.update_epoch(epoch_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a Batch object at the start of a new validation batch\n",
        "  #----------------------------------------------------\n",
        "  def begin_val_batch(self, ctx):\n",
        "    if (self._track_batch(ctx.i_epoch, ctx.i_batch)):\n",
        "      # The Trainer does not need to track validation iterations, so 'ctx' has no\n",
        "      # counter for it. We need it only to provide an incremental X-axis 'step' for \n",
        "      # plotting the Tensorboard graph of validation loss metrics. This counter is\n",
        "      # not a true count of every validation iteration, but only those iterations that\n",
        "      # the DebugTracker tracks \n",
        "      self.val_iter += 1\n",
        "      self._create_batch('val', ctx.i_epoch, ctx.i_batch, self.val_iter)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Finish a Run at the end of the training loop, and report results\n",
        "  #----------------------------------------------------\n",
        "  def end_fit(self, ctx):\n",
        "    if (self.tb is not None):\n",
        "      # Report results to Tensorboard and close the connection\n",
        "      self._tb_results()\n",
        "      self.tb.end_run()\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update metrics for a run\n",
        "  #----------------------------------------------------\n",
        "  def update_run(self, run_data):\n",
        "    current_run = self._get_current_run()\n",
        "    current_run.update(run_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update metrics for an epoch\n",
        "  #----------------------------------------------------\n",
        "  def update_epoch(self, epoch_data):\n",
        "    current_run = self._get_current_run()\n",
        "    # !!!!!! do we need a separate self.do_epoch or use a single self.do?\n",
        "    if (self.do_epoch):\n",
        "      assert(isinstance(epoch_data, dict))\n",
        "      current_epoch = self._get_current_epoch()\n",
        "      current_epoch.update(epoch_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Update metrics for a batch\n",
        "  #----------------------------------------------------\n",
        "  def update_batch(self, batch_data):\n",
        "    if (self.do):\n",
        "      assert(isinstance(batch_data, dict))\n",
        "      current_batch = self._get_current_batch()\n",
        "      current_batch.update(batch_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Add a new 'param' layer \n",
        "  #----------------------------------------------------\n",
        "  def add_param_layer(self, step_operation, param_name, param, **kwargs):\n",
        "    # Check if the batch and layer is to be tracked\n",
        "    if (self.do and self._track_layer(param_name)):\n",
        "      # Create a Layer. Internally it automatically creates a new Step if the\n",
        "      # operation is different from the previous one\n",
        "      step_type = 'param'\n",
        "      self._create_layer(step_type, step_operation, param_name, param, **kwargs)\n",
        " \n",
        "      # Report histogram data to Tensorboard in real-time. Since tensors can be\n",
        "      # quite large, we track only scalar metrics by using the mean and std.\n",
        "      # However we can send the tensor's histogram to Tensorboard while the run is\n",
        "      # in progress without saving it till the end of the run for result processing \n",
        "      if (self.tb is not None):\n",
        "        # Report the parameter data value and gradient for the current step_id\n",
        "        data_name, grad_name = param_name + '/data', param_name + '/grad'\n",
        "        step_id = self.step_id[step_type]\n",
        "        self.tb.add_hist(data_name, param.data, step_id)\n",
        "        if (param.grad is not None):\n",
        "          self.tb.add_hist(grad_name, param.grad, step_id)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Add a new 'activation' layer \n",
        "  #----------------------------------------------------\n",
        "  def add_activation_layer(self, step_operation, data_layer, out_activation, **kwargs):\n",
        "    # Check if the batch and layer is to be tracked\n",
        "    if (self.do and self._track_layer(data_layer)):\n",
        "      # Create a Layer. Internally it automatically creates a new Step if the\n",
        "      # operation is different from the previous one\n",
        "      step_type = 'activation'\n",
        "      self._create_layer(step_type, step_operation, data_layer, out_activation, **kwargs)\n",
        "\n",
        "      # Report histogram data to Tensorboard in real-time. Since tensors can be\n",
        "      # quite large, we track only scalar metrics by using the mean and std.\n",
        "      # However we can send the tensor's histogram to Tensorboard while the run is\n",
        "      # in progress without saving it till the end of the run for result processing \n",
        "      if (self.tb is not None):\n",
        "        # Report the activation value for the current step_id\n",
        "        data_name = data_layer + '/activation'\n",
        "        step_id = self.step_id[step_type]\n",
        "        self.tb.add_hist(data_name, out_activation, step_id)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Initialise the Tensorboard and Pandas Reporting objects\n",
        "  #----------------------------------------------------\n",
        "  def set_display(self, disp):\n",
        "    assert(isinstance(disp, tuple) and (len(disp) == 2))\n",
        "    assert(isinstance(disp[0], bool) and isinstance(disp[1], bool))\n",
        "    disp_tb, disp_pd = disp\n",
        "    self.tb = DebugTensorboard() if disp_tb else None\n",
        "    self.pd = DebugPandas() if disp_pd else None\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Get the flattened result rows for a run\n",
        "  #----------------------------------------------------\n",
        "  def _get_results(self, run_idx=-1):\n",
        "    run = self._get_run(run_idx)\n",
        "    all_rows = run.get_results()\n",
        "    return all_rows\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Get the result rows for a run, and display the scalar values on Tensorboard\n",
        "  #----------------------------------------------------\n",
        "  def _tb_results(self):\n",
        "    all_rows = self._get_results()\n",
        "\n",
        "    for row_data in all_rows:\n",
        "      row_type = row_data['row_type']\n",
        "\n",
        "      if (row_type == 'layer'):\n",
        "        layer_row_data = row_data\n",
        "        layer_id_names = DebugRun._id_names + DebugEpoch._id_names + DebugBatch._id_names + DebugStep._id_names + DebugLayer._id_names\n",
        "        layer_metric_data = {k:v for k,v in layer_row_data.items() if ((k not in layer_id_names) and isinstance(v, float))}\n",
        "        for k, v in layer_metric_data.items():\n",
        "          tag = layer_row_data['layer_name'] + '/' + k\n",
        "          self.tb.add_scalar(tag, v, layer_row_data['step_id'])\n",
        "\n",
        "      elif (row_type == 'batch'):\n",
        "        batch_row_data = row_data\n",
        "        batch_id_names = DebugRun._id_names + DebugEpoch._id_names + DebugBatch._id_names\n",
        "        batch_metric_data = {k:v for k,v in batch_row_data.items() if ((k not in batch_id_names) and isinstance(v, float))}\n",
        "        for k, v in batch_metric_data.items():\n",
        "          tag = batch_row_data['batch_type'] + '/' + k\n",
        "          self.tb.add_scalar(tag, v, batch_row_data['iter'])\n",
        "      \n",
        "      elif (row_type == 'epoch'):\n",
        "        epoch_row_data = row_data\n",
        "        epoch_id_names = DebugRun._id_names + DebugEpoch._id_names\n",
        "        epoch_metric_data = {k:v for k,v in epoch_row_data.items() if ((k not in epoch_id_names) and isinstance(v, float))}\n",
        "        for k, v in epoch_metric_data.items():\n",
        "          tag = 'epoch' + '/' + k\n",
        "          self.tb.add_scalar(tag, v, epoch_row_data['epoch_id'])\n",
        "\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Show results on Tensorboard for a previously saved run that has been loaded. \n",
        "  # Do not use this for results of 'live' runs as they are automatically \n",
        "  # displayed on Tensorboard\n",
        "  #----------------------------------------------------\n",
        "  def tb_saved_results(self, run_idx=-1):\n",
        "    if (self.tb is not None):\n",
        "      # Start Tensorboard for reporting results for a run\n",
        "      run = self._get_run(run_idx)\n",
        "      run_name = run.data['run_id']\n",
        "      self.tb.start_run(f'{run_name}')\n",
        "\n",
        "      # Report results to Tensorboard and close the connection\n",
        "      self._tb_results()\n",
        "      self.tb.end_run()\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Get the result rows for a run, and format them as a Pandas dataframe\n",
        "  #----------------------------------------------------\n",
        "  def pd_results(self):\n",
        "    assert(self.pd is not None)\n",
        "    all_rows = self._get_results()\n",
        "    res_dfs = self.pd.create_dfs (all_rows)\n",
        "\n",
        "    return res_dfs\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Save the Run object and its hierarchy to a pickle file\n",
        "  #----------------------------------------------------\n",
        "  def save_run(self, save_path, run_idx=-1):\n",
        "    run = self._get_run(run_idx)\n",
        "    with open(save_path, 'wb') as sf:\n",
        "      pickle.dump(run, sf)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Load a pickle dump of a previously saved Run object\n",
        "  #----------------------------------------------------\n",
        "  def load_run(self, save_path):\n",
        "    with open(save_path, 'rb') as sf:\n",
        "      run = pickle.load(sf)\n",
        "    self.runs.append(run)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a new Run object\n",
        "  #----------------------------------------------------\n",
        "  def _create_run(self, num_epochs):\n",
        "    run_idx = len(self.runs)\n",
        "    new_run = DebugRun(num_epochs)\n",
        "    self.runs.append(new_run)\n",
        "\n",
        "    # Reset the global step_id at the beginning of the run. Step IDs will start\n",
        "    # from 0 and increment for every new step for the duration of the run\n",
        "    self.step_id = {'activation': -1, 'param': -1}\n",
        "\n",
        "    return new_run\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a new Epoch object and add it to the current run\n",
        "  #----------------------------------------------------\n",
        "  def _create_epoch(self, i_epoch):\n",
        "    new_epoch = DebugEpoch(i_epoch)\n",
        "    current_run = self._get_current_run()\n",
        "    current_run.add_epoch(new_epoch)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a new Batch object and add it to the current run\n",
        "  #----------------------------------------------------\n",
        "  def _create_batch(self, batch_type, i_epoch, i_batch, i_iter):\n",
        "    new_batch = DebugBatch(batch_type, i_epoch, i_batch, i_iter)\n",
        "    current_epoch = self._get_current_epoch()\n",
        "    current_epoch.add_batch(new_batch)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Create a new Step object and add it to the current batch\n",
        "  #----------------------------------------------------\n",
        "  def _create_step(self, step_id, step_operation, step_type):\n",
        "    new_step = DebugStep(step_id, step_operation, step_type)\n",
        "    current_batch = self._get_current_batch()\n",
        "    current_batch.add_step(new_step)\n",
        "    return new_step\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # First check if a new Step object has to be created because the operation \n",
        "  # has changed from the previous. If not, get the current step.\n",
        "  # Then create a new Layer object and add it to the step as above.\n",
        "  #----------------------------------------------------\n",
        "  def _create_layer(self, step_type, step_operation, layer_name, layer_value, **kwargs):\n",
        "    new_layer = DebugLayer(step_type, layer_name, layer_value, **kwargs)\n",
        "    current_step = self._get_step(step_type, step_operation)\n",
        "    current_step.add_layer(new_layer)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Get the current step and check if the operation is the same as the previous.\n",
        "  # If it is, return the current step. If it isn't, create a new step.\n",
        "  #----------------------------------------------------\n",
        "  def _get_step(self, step_type, step_operation):\n",
        "    current_step = self._get_current_step()\n",
        "    if ((current_step is not None) and\n",
        "        current_step.is_same_step(step_type, step_operation)):\n",
        "      # current_step is None if this is a new batch with no steps so far\n",
        "      return current_step\n",
        "    else:\n",
        "      # Operation has changed, or this is a new batch with no steps so far.\n",
        "      # In either case we need to create a new step after incrementing our\n",
        "      # global step_id\n",
        "      self.step_id[step_type] += 1\n",
        "      step_id = self.step_id[step_type]\n",
        "      new_step = self._create_step(step_id, step_operation, step_type)\n",
        "      return new_step\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # A new run object is automatically created and added to the list when the\n",
        "  # training loop starts. Therefore, the last added run object in the list \n",
        "  # is the current run\n",
        "  #----------------------------------------------------\n",
        "  def _get_current_run(self):\n",
        "    current_run_idx = len(self.runs) - 1\n",
        "    return self._get_run(current_run_idx)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Get a run object, given its index in the list\n",
        "  #----------------------------------------------------\n",
        "  def _get_run(self, run_idx):\n",
        "    return self.runs[run_idx]\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # A new epoch object is automatically created and added to the list when an\n",
        "  # epoch starts. Therefore, the last added epoch object in the list is the current epoch\n",
        "  #----------------------------------------------------\n",
        "  def _get_current_epoch(self):\n",
        "    current_run = self._get_current_run()\n",
        "    current_epoch = current_run.get_current_epoch()\n",
        "    return current_epoch\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # A new batch object is automatically created and added to the list when the\n",
        "  # training or validation batch starts. Therefore, the last added batch object\n",
        "  # in the list is the current batch\n",
        "  #----------------------------------------------------\n",
        "  def _get_current_batch(self):\n",
        "    current_epoch = self._get_current_epoch()\n",
        "    current_batch = current_epoch.get_current_batch()\n",
        "    return current_batch\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # The last added step in the list is the current step\n",
        "  #----------------------------------------------------\n",
        "  def _get_current_step(self):\n",
        "    current_batch = self._get_current_batch()\n",
        "    current_step = current_batch.get_current_step()\n",
        "    return current_step\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Return True if this epoch is to be tracked based on the\n",
        "  # filter criteria\n",
        "  # !!!!!!!!!!! Implement the filter criteria\n",
        "  #----------------------------------------------------\n",
        "  def _track_epoch(self, i_epoch):\n",
        "    self.do_epoch = True\n",
        "    return self.do_epoch\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Return True if this batch is to be tracked based on the\n",
        "  # filter criteria\n",
        "  #----------------------------------------------------\n",
        "  def _track_batch(self, i_epoch, i_batch):\n",
        "    self.do = ((i_batch % self.freq == 0) and (i_batch < self.max_count))\n",
        "    return self.do\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # Return True if this layer is to be tracked based on the\n",
        "  # filter criteria\n",
        "  #----------------------------------------------------\n",
        "  def _track_layer(self, data_name):\n",
        "    do_layer = (self.data_prefixes is None) or (any(data_name.startswith(data_prefix) for data_prefix in self.data_prefixes))\n",
        "    return do_layer\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # !!!!!! TODO\n",
        "  #----------------------------------------------------\n",
        "  def _print_kw(self, kw):\n",
        "    res = ''\n",
        "    for run in self.runs:\n",
        "      for k, v in run.data.items():\n",
        "        if (isinstance(v, list)):\n",
        "          res += f'\\t\\t{k}:' + '\\n'.join([f'{v}' for i in v])\n",
        "        else:\n",
        "          res += f'{k}:{v}'\n",
        "    return res\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # !!!!!! TODO\n",
        "  #----------------------------------------------------\n",
        "  def __repr__(self):\n",
        "    runs=[f'{run.data}' for run in self.runs]\n",
        "    batches=[f'{batch.data}' for run in self.runs for batch in run.data['batches']]\n",
        "    return ('\\n'.join(runs + batches))\n",
        "\n",
        "  def temp__repr__(self):\n",
        "    return f'{self.runs}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx-5dg1V1nom"
      },
      "source": [
        "dtr = DebugTracker(disp=(False, True))\n",
        "dtr._create_run(2)\n",
        "dtr.update_run({'setting': .009})\n",
        "dtr._create_epoch(0)\n",
        "dtr.update_epoch({'num_tr_batches': 50, 'metric': 7.7})\n",
        "dtr._create_batch('train', 0, 0, 0)\n",
        "dtr.update_batch({'pred': 2.1982, 'loss': 0.0372})\n",
        "dtr.add_activation_layer('fwd', 'inp', tensor([2., 3.]))\n",
        "dtr.add_activation_layer('fwd', 'layer 0', tensor([5., 9.]), extra=9, info=46.)\n",
        "dtr._get_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VZU7XWF7EG9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1b35034c-a930-4326-8623-b59821959558"
      },
      "source": [
        "_, _, _, dtrdf = dtr.pd_results()\n",
        "dtrdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>setting</th>\n",
              "      <th>row_type</th>\n",
              "      <th>epoch_id</th>\n",
              "      <th>num_tr_batches</th>\n",
              "      <th>num_val_batches</th>\n",
              "      <th>metric</th>\n",
              "      <th>batch_id</th>\n",
              "      <th>iter</th>\n",
              "      <th>batch_type</th>\n",
              "      <th>pred</th>\n",
              "      <th>loss</th>\n",
              "      <th>step_id</th>\n",
              "      <th>step_operation</th>\n",
              "      <th>step_type</th>\n",
              "      <th>layer_name</th>\n",
              "      <th>out_activation</th>\n",
              "      <th>extra</th>\n",
              "      <th>info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.009</td>\n",
              "      <td>run</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>epoch</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>batch</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0-0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>train</td>\n",
              "      <td>2.1982</td>\n",
              "      <td>0.0372</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>layer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0-0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>train</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>fwd</td>\n",
              "      <td>activation</td>\n",
              "      <td>inp</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>layer</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0-0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>train</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>fwd</td>\n",
              "      <td>activation</td>\n",
              "      <td>layer 0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                run_id  num_epochs  setting  ... out_activation  extra  info\n",
              "0  Run-20200717_044044         2.0    0.009  ...            NaN    NaN   NaN\n",
              "1  Run-20200717_044044         NaN      NaN  ...            NaN    NaN   NaN\n",
              "2  Run-20200717_044044         NaN      NaN  ...            NaN    NaN   NaN\n",
              "3  Run-20200717_044044         NaN      NaN  ...            2.5    NaN   NaN\n",
              "4  Run-20200717_044044         NaN      NaN  ...            7.0    9.0  46.0\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Od1ROkkZGIj"
      },
      "source": [
        "#export\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Debug Callback to print yhat and loss after each batch\n",
        "#----------------------------------------------------\n",
        "class DebugYhatLossCB(Callback):\n",
        "  def __init__(self, fwd=True, bkwd=False, prefix='\\t'):\n",
        "    self.fwd, self.bkwd = fwd, bkwd\n",
        "    self.bkwd_pre = False # Don't show gradients values before backward()\n",
        "    self.prefix = prefix\n",
        "\n",
        "  def begin_tr(self, ctx):\n",
        "    if (self.fwd):\n",
        "      # Print Headers\n",
        "      print (f'{self.prefix}Total {ctx.num_epochs} epochs with {ctx.num_batches} batches')\n",
        "      print (f'{self.prefix}Batch, Pred, Loss')\n",
        "\n",
        "  def after_tr_loss(self, ctx):\n",
        "    with torch.no_grad():\n",
        "      dtr = ctx.dtr\n",
        "      if (dtr):\n",
        "        dtr.update_batch({'pred': ctx.yhat.mean().item(), 'loss': ctx.loss.item()})\n",
        "\n",
        "      if (self.fwd):\n",
        "        print (f'{self.prefix}{ctx.i_epoch:2}.{ctx.i_batch}, {ctx.yhat.mean():.4f}, {ctx.loss:.4f}')\n",
        "\n",
        "      #if (self.bkwd_pre):\n",
        "        #self.print_grad (ctx.model, before='Pre Gradients')\n",
        "\n",
        "  def after_val_loss(self, ctx):\n",
        "    dtr = ctx.dtr\n",
        "    if (dtr):\n",
        "      dtr.update_batch({'pred': ctx.yhat.mean().item(), 'loss': ctx.loss.item()})\n",
        "\n",
        "  def after_tr_backward(self, ctx):\n",
        "    with torch.no_grad():\n",
        "      if (self.bkwd and ctx.dtr):\n",
        "        dtr = ctx.dtr\n",
        "        for name, param in ctx.model.named_parameters():\n",
        "          dtr.add_param_layer('bkwd', name, param)\n",
        "\n",
        "      #self.print_grad (ctx.model)\n",
        "\n",
        "  def end_tr_batch(self, ctx):\n",
        "    if (ctx.dtr):\n",
        "      #lrs = [pg['lr'] for pg in ctx.opt.param_groups]\n",
        "      #moms = [pg['betas'][0] for pg in ctx.opt.param_groups]\n",
        "      #ctx.dtr.update_batch({'lrd': lrs, 'momd': moms})\n",
        "      hps = {hp:[pg[hp] for pg in ctx.opt.param_groups] for hp in ctx.opt.param_groups[0].keys() if hp != 'params'}\n",
        "      hps = self.format_hp(hps)\n",
        "      ctx.dtr.update_batch(hps)\n",
        "\n",
        "  @staticmethod\n",
        "  def format_hp(hps):\n",
        "    new_hps = {}\n",
        "    for hp, hp_val in hps.items():\n",
        "      if (isinstance(hp_val[0], tuple)):\n",
        "        assert(len(hp_val[0]) == 2)\n",
        "        hp1, hp2 = f'{hp}_1', f'{hp}_2'\n",
        "        if (hp == 'betas'):\n",
        "          hp1 = 'mom'\n",
        "        hp_val1, hp_val2 = zip(*hp_val)\n",
        "        new_hps[hp1] = list(hp_val1)\n",
        "        new_hps[hp2] = list(hp_val2)\n",
        "      else:\n",
        "        new_hps[hp] = hp_val\n",
        "    return new_hps\n",
        "\n",
        "  def print_grad(self, model, before='\\t\\t'):\n",
        "    hdr_name = 'Name'\n",
        "    print (f'{before}{hdr_name:12}: Shape, Requires, Leaf, Grad')\n",
        "    for name, param in model.named_parameters():\n",
        "      print (f'{before}{name:12}: {tuple(param.data.size())}, {param.requires_grad}, {param.is_leaf}, {param.grad.mean() if param.grad is not None else 0:0.4G}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFdMKvtoGJEl"
      },
      "source": [
        "dtr = DebugTracker(freq=2, data_prefixes=['2.'], disp=(True, True))\n",
        "debug_cbs = [dtr, DebugYhatLossCB(bkwd=True)]\n",
        "debug_loop = run_mnist(debug_cbs, num_epochs=2, repro=True, dtr=dtr)\n",
        "\n",
        "#dtr.tb_results()\n",
        "dcdrrun_df, dcdrbatch_df, dcdrlayer_df, dcdrdf = dtr.pd_results()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_BUNzX_KtzW"
      },
      "source": [
        "dcdrdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5W-q99l7G4u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "c9b821cc-b098-4f29-a525-8aa3467565bd"
      },
      "source": [
        "dcdrrun_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>row_type</th>\n",
              "      <th>epoch_id</th>\n",
              "      <th>num_tr_batches</th>\n",
              "      <th>num_val_batches</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>2.0</td>\n",
              "      <td>run</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>epoch</td>\n",
              "      <td>0.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Run-20200717_044044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>epoch</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 run_id  num_epochs  ... num_tr_batches  num_val_batches\n",
              "0   Run-20200717_044044         2.0  ...            NaN              NaN\n",
              "1   Run-20200717_044044         NaN  ...           98.0             10.0\n",
              "14  Run-20200717_044044         NaN  ...           98.0             10.0\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NDFiricKHD7"
      },
      "source": [
        "dcdrbatch_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgUlV7uJKPp1"
      },
      "source": [
        "dcdrlayer_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXWkWjrfXU8p"
      },
      "source": [
        "**Set up Tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxvL08OFE8zX"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tbtry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qivCJJNNzAA"
      },
      "source": [
        "!rm -R tbtry\n",
        "!ls -lR tbtry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f67GwyU4Xe0L"
      },
      "source": [
        "### Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPRG233iuTeu"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ketanhdoshi/ml/master/lib/nb_export.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYy95Q_juc1i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "783db1f5-b490-48c5-92cc-272c23381149"
      },
      "source": [
        "from nb_export import notebook2scriptSingle\n",
        "notebook2scriptSingle(gn_path + '/lib/training_lib.ipynb', gn_path + '/exp')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted gdrive/My Drive/Colab Notebooks/lib/training_lib.ipynb to gdrive/My Drive/Colab Notebooks/exp/nb_training.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-8wu2ZtMSnY"
      },
      "source": [
        "### Junk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9pUDLUVPUA5"
      },
      "source": [
        "class MetricsGrp(Callback):\n",
        "  def __init__(self, metrics):\n",
        "    self.metrics = metrics\n",
        "    # !!!!! Register callbacks for each metric\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print headers for all the result columns\n",
        "  # ----------------------------   \n",
        "  def begin_fit(self, ctx):\n",
        "    # ['epoch', 'tr_loss', 'smooth_loss', 'val_loss', 'metric1', 'metric2', ..'time']\n",
        "    headers = ['epoch']\n",
        "    for metric in self.metrics: headers += metric.header\n",
        "    headers += ['time']\n",
        "    ctx.logger(headers)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Track start time at the beginning of each epoch\n",
        "  # ----------------------------   \n",
        "  def begin_epoch(self, ctx):\n",
        "    ctx.start_time = time.time()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print results at the end of each epoch\n",
        "  # ----------------------------   \n",
        "  def end_epoch(self, ctx):\n",
        "    # Flattened metric results and epoch time taken\n",
        "    values = [results for metric in self.metrics for results in metric._results()]\n",
        "    epoch_time = [format_time(time.time() - ctx.start_time)]\n",
        "    #for metric in self.metrics: values += metric._results()\n",
        "\n",
        "    # Epoch number, formatted metric results, and epoch time\n",
        "    res = [str(ctx.i_epoch)]\n",
        "    res += [f'{val:.6f}' for val in values]\n",
        "    res += epoch_time\n",
        "\n",
        "    ctx.logger(res)\n",
        "\n",
        "    # Report metrics to the DTR\n",
        "    if (ctx.dtr): self._report(ctx.dtr, values + epoch_time)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Report metrics to the DTR\n",
        "  # ----------------------------   \n",
        "  def _report(self, dtr, results):\n",
        "    headers = [header for metric in self.metrics for header in metric.header] + ['time']\n",
        "    epoch_metrics = {header:result for header, result in zip(headers, results)}\n",
        "    dtr.update_epoch(epoch_metrics)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Base class for all Metrics callbacks\n",
        "#\n",
        "# It handles some common functionality such as managing the metric result value (one or more)\n",
        "# that it computes per epoch. It resets that value at the\n",
        "# end of each epoch. It provides abstract methods to do any necessary computations\n",
        "# at the end of each batch and at the end of each epoch. The child class provides\n",
        "# implementations for these methods. It also accumulates the inputs (ie. preds and targs)\n",
        "# after each batch, which the child class can use for its end-epoch calculations\n",
        "# if it needs.\n",
        "#----------------------------------------------------\n",
        "class MetricsBaseCB(Callback):\n",
        "  header = ['metric']\n",
        "  # Accumulated 'yhat' predictions and 'yb' targets. These are singletons which\n",
        "  # are common for all child CBs. Treated as read-only by all child CBs\n",
        "  accumulate = False\n",
        "  yhat, yb = None, None\n",
        "  last_accumulated_batch = -1\n",
        "\n",
        "  def __init__(self):\n",
        "    self.num_value = len(self.header)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset any state, when training starts and at beginning of each epoch\n",
        "  # ----------------------------   \n",
        "  def _reset(self, begin_fit=False):\n",
        "    pass\n",
        "\n",
        "  # ----------------------------\n",
        "  # Return the metric values\n",
        "  # ----------------------------   \n",
        "  def _results(self):\n",
        "    values = [self.value] if (self.num_value == 1) else self.value\n",
        "    values = [val.item() if (isinstance(val, torch.Tensor)) else val for val in values]\n",
        "    return values\n",
        "\n",
        "  # ----------------------------\n",
        "  # Do any required calculations at the end of the batch. A flag indicates if it\n",
        "  # is a training or validation batch.\n",
        "  # Functionality gets implemented within the child callback.\n",
        "  # ----------------------------   \n",
        "  def _calc_batch(self, ctx, is_val=True):\n",
        "    pass\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset the accumulated values\n",
        "  #\n",
        "  # Note that since these attributes are singletons, they must be modified using\n",
        "  # 'MetricsBaseCB.<attr>'. Modifying them via 'cls.<attr>' modifies them only\n",
        "  # for the child class, since 'cls' points to the child and not the base. Similarly\n",
        "  # modfifying them via 'self.<attr>' modifies them only for the child instance.\n",
        "  # However, to get the value they can be referenced by any of the above ways ie.\n",
        "  # 'cls.<attr>', 'self.<attr>' or 'MetricsBaseCB.<attr>' will all work.\n",
        "  # ----------------------------   \n",
        "  @classmethod\n",
        "  def _reset_accumulate(cls):\n",
        "    MetricsBaseCB.yhat, MetricsBaseCB.yb = None, None\n",
        "    MetricsBaseCB.last_accumulated_batch = -1\n",
        "\n",
        "  # ----------------------------\n",
        "  # Accumulate the target and preds after each batch so that they\n",
        "  # can be used for end-of-epoch calculations\n",
        "  # ----------------------------   \n",
        "  @classmethod\n",
        "  def _accumulate_batch(cls, ctx):\n",
        "    if (not cls.accumulate or (ctx.i_batch == cls.last_accumulated_batch)):\n",
        "      # At the end of a batch, this method gets called multiple times, once for \n",
        "      # each child instance. However the accumulation needs to be done just once\n",
        "      # per batch, as it is a singleton. So we do nothing if that batch data has\n",
        "      # already been accumulated \n",
        "      return\n",
        "\n",
        "    if (cls.yhat is None):\n",
        "      # Initialise for the first batch of the epoch. Cloning copies the type, device\n",
        "      # and size of the tensor.\n",
        "      MetricsBaseCB.yhat = ctx.yhat.clone().detach()\n",
        "      MetricsBaseCB.yb = ctx.yb.clone().detach()\n",
        "    else:\n",
        "      # Concatenate this batch data to the accumulated data from previous batches\n",
        "      MetricsBaseCB.yhat = torch.cat((cls.yhat, ctx.yhat.detach()))\n",
        "      MetricsBaseCB.yb = torch.cat((cls.yb, ctx.yb.detach()))\n",
        "\n",
        "    # Mark that data for this batch has been accumulated\n",
        "    MetricsBaseCB.last_accumulated_batch = ctx.i_batch\n",
        "\n",
        "  # ----------------------------\n",
        "  # Do any required calculations at the end of the epoch\n",
        "  # ----------------------------   \n",
        "  def _calc_epoch(self, ctx):\n",
        "    pass\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset all metrics when training starts\n",
        "  # ----------------------------   \n",
        "  def begin_fit(self, ctx):\n",
        "    self._reset(begin_fit=True)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Reset all metrics at the beginning of each epoch\n",
        "  # ----------------------------   \n",
        "  def begin_epoch(self, ctx):\n",
        "    self.value = 0. if (self.num_value == 1) else [0.] * self.num_value\n",
        "    self._reset_accumulate()\n",
        "    self._reset()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Calculate training metrics for each batch\n",
        "  # ----------------------------   \n",
        "  def after_tr_loss(self, ctx):\n",
        "    with torch.no_grad():\n",
        "      self._calc_batch(ctx, is_val=False)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Calculate validation metrics for each batch\n",
        "  # ----------------------------   \n",
        "  def after_val_loss(self, ctx):\n",
        "    self._calc_batch(ctx)\n",
        "    self._accumulate_batch(ctx)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Print results at the end of each epoch\n",
        "  # ----------------------------   \n",
        "  def end_epoch(self, ctx):\n",
        "    with torch.no_grad():\n",
        "      self._calc_epoch(ctx)\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Calculate an Average value per epoch using the given metric function\n",
        "#----------------------------------------------------\n",
        "class AverageMetricsCB(MetricsBaseCB):\n",
        "  header = ['avg']\n",
        "\n",
        "  def __init__(self, metric_fn):\n",
        "    self.metric_fn = metric_fn\n",
        "    self.header = [metric_fn.__name__]\n",
        "    super().__init__()\n",
        "\n",
        "  # ----------------------------\n",
        "  # Count of total number of sample rows in an epoch\n",
        "  # ----------------------------\n",
        "  def _reset(self, begin_fit=False):\n",
        "    self.total_sz = 0\n",
        "\n",
        "  # ----------------------------\n",
        "  # Add up the value returned by the metric function for each batch. It will be\n",
        "  # averaged at the end of the epoch. Metrics are computed only for validation batches.\n",
        "  # ----------------------------   \n",
        "  def _calc_batch(self, ctx, is_val=True):\n",
        "    if (is_val):\n",
        "      batch_sz = ctx.yb.size(0)\n",
        "      self.total_sz += batch_sz\n",
        "      self.value += self.metric_fn(ctx.yhat, ctx.yb) * batch_sz\n",
        "\n",
        "  # ----------------------------\n",
        "  # Compute the average at the end of the epoch\n",
        "  # ----------------------------\n",
        "  def _calc_epoch(self, ctx):\n",
        "    self.value = self.value / self.total_sz\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Track the Training and Validation Loss per epoch, already \n",
        "# calculated by the loss function.\n",
        "# This is the only metric which is computed for both training and validation\n",
        "#----------------------------------------------------\n",
        "class LossMetricsCB(MetricsBaseCB):\n",
        "  header = ['tr_loss', 'smooth_loss', 'val_loss']\n",
        "  beta=0.98\n",
        "\n",
        "  # ----------------------------\n",
        "  # Count of total number of sample rows in an epoch\n",
        "  # ----------------------------\n",
        "  def _reset(self, begin_fit=False):\n",
        "    self.total_sz = 0\n",
        "\n",
        "    # Initialise only once when training starts, but don't reset after each epoch\n",
        "    if (begin_fit):\n",
        "      self.mov_avg = 0\n",
        "      self.n = 0\n",
        "\n",
        "  # ----------------------------\n",
        "  # Add up the loss for each training and validation batch\n",
        "  # ----------------------------   \n",
        "  def _calc_batch(self, ctx, is_val=True):\n",
        "    if (is_val):\n",
        "      # Validation loss\n",
        "      batch_sz = ctx.yb.size(0)\n",
        "      self.total_sz += batch_sz\n",
        "      self.value[2] += ctx.loss * batch_sz\n",
        "    else:\n",
        "      # Training loss\n",
        "      loss = ctx.loss\n",
        "      self.value[0] += ctx.loss\n",
        "\n",
        "      # Smoothed training loss based on moving average\n",
        "      self.n += 1\n",
        "      self.mov_avg = self.beta * self.mov_avg + (1 - self.beta) * loss\n",
        "      self.value[1] = self.mov_avg / (1 - self.beta ** self.n)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Compute the average at the end of the epoch\n",
        "  # ----------------------------\n",
        "  def _calc_epoch(self, ctx):\n",
        "    # Calculate Training loss\n",
        "    # Smoothed Training loss is already updated after each batch\n",
        "    self.value[0] = self.value[0] / len(ctx.tr_dl)\n",
        "\n",
        "    # Calculate Validation loss\n",
        "    self.value[2] = self.value[2] / self.total_sz\n",
        "\n",
        "#----------------------------------------------------\n",
        "# Roc Auc score per epoch\n",
        "#----------------------------------------------------\n",
        "from sklearn.metrics import roc_auc_score\n",
        "class RocAucMetricsCB(MetricsBaseCB):\n",
        "  header = ['roc_auc']\n",
        "\n",
        "  def _calc_epoch(self, ctx):\n",
        "    yhat = torch.sigmoid(self.yhat)\n",
        "    #yhat = F.softmax(ctx.yhat, dim=1)[:,-1]\n",
        "    roc_score = roc_auc_score(self.yb.cpu().numpy(), yhat.cpu().numpy())\n",
        "    self.value = roc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t1PuZKbPvNj"
      },
      "source": [
        "\n",
        "#----------------------------------------------------\n",
        "# Debug Callback to print yhat and loss after each batch\n",
        "#----------------------------------------------------\n",
        "class DebugYhatLossCB(Callback):\n",
        "  def __init__(self, fwd=True, bkwd=False, prefix='\\t'):\n",
        "    self.fwd, self.bkwd = fwd, bkwd\n",
        "    self.bkwd_pre = False # Don't show gradients values before backward()\n",
        "    self.prefix = prefix\n",
        "\n",
        "  def begin_tr(self, ctx):\n",
        "    if (self.fwd):\n",
        "      # Print Headers\n",
        "      print (f'{self.prefix}Total {ctx.num_epochs} epochs with {ctx.num_batches} batches')\n",
        "      print (f'{self.prefix}Batch, Pred, Loss')\n",
        "\n",
        "  def after_tr_loss(self, ctx):\n",
        "    dtr = ctx.dtr\n",
        "    dtr.update_batch({'pred': ctx.yhat.mean().item(), 'loss': ctx.loss.item()})\n",
        "\n",
        "    if (self.fwd):\n",
        "      print (f'{self.prefix}{ctx.i_epoch:2}.{ctx.i_batch}, {ctx.yhat.mean():.4f}, {ctx.loss:.4f}')\n",
        "\n",
        "    #if (self.bkwd_pre):\n",
        "      #self.print_grad (ctx.model, before='Pre Gradients')\n",
        "\n",
        "  def after_tr_backward(self, ctx):\n",
        "    if (self.bkwd):\n",
        "      dtr = ctx.dtr\n",
        "      for name, param in ctx.model.named_parameters():\n",
        "        dtr.add_param_layer('bkwd', name, param)\n",
        "\n",
        "      #self.print_grad (ctx.model)\n",
        "\n",
        "  def print_grad(self, model, before='\\t\\t'):\n",
        "    hdr_name = 'Name'\n",
        "    print (f'{before}{hdr_name:12}: Shape, Requires, Leaf, Grad')\n",
        "    for name, param in model.named_parameters():\n",
        "      print (f'{before}{name:12}: {tuple(param.data.size())}, {param.requires_grad}, {param.is_leaf}, {param.grad.mean() if param.grad is not None else 0:0.4G}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inLMXuciVM3j"
      },
      "source": [
        "\n",
        "    batch_df = df[df['row_type'] == 'batch'][['run_id', 'batch_id', 'iter', 'batch_type', 'pred', 'loss']]\n",
        "    if ('step_type' in df.columns):\n",
        "      col_list = ['run_id', 'batch_id', 'iter', 'batch_type', 'step_operation', 'layer_name']\n",
        "      if ('param_mean' in df.columns):\n",
        "        col_list += ['param_mean', 'grad_mean']\n",
        "      if ('out_activation' in df.columns):\n",
        "        col_list += ['out_activation']\n",
        "      layer_df = df[df['row_type'] == 'layer'][col_list]\n",
        "\n",
        "\n",
        "  def add_layer(self, layer_data):\n",
        "    layers = self.data['layers']\n",
        "    layers.append(layer_data)\n",
        "\n",
        "  #----------------------------------------------------\n",
        "  # The last added step in the list is the current step\n",
        "  #----------------------------------------------------\n",
        "  def _get_run(self, run_idx):\n",
        "    return self.runs[run_idx]\n",
        "\n",
        "\n",
        "  def OLD_add_param_layer(self, operation_type, param_name, param, **kwargs):\n",
        "    if (self.do and self._track_layer(param_name)):\n",
        "      layer = dict()\n",
        "      step_type = 'param'\n",
        "      layer['step_type'] = step_type\n",
        "      layer['operation_type'] = operation_type\n",
        "      layer['data_item'] = param_name\n",
        "      layer['param_mean'] = param.data.mean().item()\n",
        "      layer['param_std'] = param.data.std().item()\n",
        "      layer['requires_grad'] = param.requires_grad\n",
        "      if (param.grad is not None):\n",
        "        layer['grad_mean'] = param.grad.mean().item()\n",
        "        layer['grad_std'] = param.data.std().item()\n",
        "      if (kwargs is not None):\n",
        "        layer.update(kwargs)\n",
        "\n",
        "      current_batch = self._get_current_batch()\n",
        "      current_iter = current_batch.data['iter'] # !!!! TODO don't access private data inside batch\n",
        "\n",
        "      step_id = self._get_step_id(step_type, current_iter, operation_type)\n",
        "      layer['step_id'] = step_id\n",
        "\n",
        "      current_batch.add_layer(layer)\n",
        "\n",
        "      self._create_layer(step_type, param_name, param, **kwargs)\n",
        " \n",
        "      if (self.tb is not None):\n",
        "        data_name, grad_name = param_name + '/data', param_name + '/grad'\n",
        "        self.tb.add_hist(data_name, param.data, step_id)\n",
        "        if (param.grad is not None):\n",
        "          self.tb.add_hist(grad_name, param.grad, step_id)\n",
        "\n",
        "  def OLD_add_activation_layer(self, operation_type, data_layer, out_activation, **kwargs):\n",
        "    if (self.do and self._track_layer(data_layer)):\n",
        "      layer = dict()\n",
        "      step_type = 'activation'\n",
        "      layer['step_type'] = step_type\n",
        "      layer['operation_type'] = operation_type\n",
        "      layer['data_item'] = data_layer\n",
        "      layer['out_activation'] = out_activation.mean().item()\n",
        "\n",
        "      if (kwargs is not None):\n",
        "        layer.update(kwargs)\n",
        "\n",
        "      current_batch = self._get_current_batch()\n",
        "      current_iter = current_batch.data['iter'] # !!!! TODO don't access private data inside batch\n",
        "\n",
        "      step_id = self._get_step_id(step_type, current_iter, operation_type)\n",
        "      layer['step_id'] = step_id\n",
        "\n",
        "      current_batch.add_layer(layer)\n",
        "\n",
        "      self._create_layer(step_type, data_layer, out_activation, **kwargs)\n",
        "\n",
        "      if (self.tb is not None):\n",
        "        data_name = data_layer + '/activation'\n",
        "        self.tb.add_hist(data_name, out_activation, step_id)\n",
        "\n",
        "\n",
        "  def OLD_get_step_id(self, step_type, current_iter, current_operation):\n",
        "    if ((current_operation != self.last_operation_type['operation_type']) or\n",
        "        (current_iter != self.last_operation_type['iter'])):\n",
        "      self.last_operation_type['operation_type'] = current_operation\n",
        "      self.last_operation_type['iter'] = current_iter\n",
        "      self.step_id[step_type] += 1\n",
        "\n",
        "      step_id = self.step_id[step_type]\n",
        "      self._create_step(step_id, current_operation, step_type)\n",
        "\n",
        "    return self.step_id[step_type]\n",
        "\n",
        "  def _create_run(self, num_epochs):\n",
        "    self.OLD_last_operation_type = {'iter': -1, 'operation_type': ''}\n",
        "\n",
        "    return new_run\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzP27LL5cLAY"
      },
      "source": [
        "**To view Tensorboard output locally, use ngrok to tunnel traffic to localhost. First, download and unzip ngrok on the Colab server**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomVFMK8agNm"
      },
      "source": [
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx9TXX0acOZv"
      },
      "source": [
        "**Get TensorBoard running in the background**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3sFSzVhlOVu"
      },
      "source": [
        "# Set the LOGDIR correctly to use Tensorboard\n",
        "LOG_DIR = 'tbtry'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTEsOw98bUY7"
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhztbwBnc_DL"
      },
      "source": [
        "**Launch ngrok background process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCkaIrwqbfzP"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BADzHi9dBh6"
      },
      "source": [
        "**We get the public URL where we can access the colab TensorBoard web page. This will output a URL you can click on**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC65XT9PbmyJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab7cef5a-1ac7-4102-bbc1-8d6da0d78836"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://978255fa.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}