{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chatbot DialogGPT.ipynb","provenance":[],"authorship_tag":"ABX9TyMfeT6+jLRJSzekXic/yicy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5f619345b31d419e89ee671d8c1ae1ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be7a6a4e47e24e4690d03a54fd4e64ef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d88d6c9d78f54676ab5974d881945a0b","IPY_MODEL_9eaa8daaad8e487286b7dafe113267f9"]}},"be7a6a4e47e24e4690d03a54fd4e64ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d88d6c9d78f54676ab5974d881945a0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e66b6f1b794349b89ca9ac1f28446210","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":554,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":554,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8be343c8856d47d79f93d98cad3b0fbe"}},"9eaa8daaad8e487286b7dafe113267f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cd462195f1134b57bedd5f011dfd4623","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 554/554 [00:00&lt;00:00, 18.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bdb70af7b20b4726b12b0433b22019ee"}},"e66b6f1b794349b89ca9ac1f28446210":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8be343c8856d47d79f93d98cad3b0fbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd462195f1134b57bedd5f011dfd4623":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bdb70af7b20b4726b12b0433b22019ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69532160a65045f4b07b763d2ec25086":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7457c63f92624b8db3bd6ca2db03c823","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5d3b7c01a0d64912b18b7e6bc3916058","IPY_MODEL_1059b80075b342cca356e233aa67889c"]}},"7457c63f92624b8db3bd6ca2db03c823":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d3b7c01a0d64912b18b7e6bc3916058":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e3c89e0f0da1492f8280788f53cd6428","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16ec1662c234458dbb382bf54d5bf02d"}},"1059b80075b342cca356e233aa67889c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a1a11943bea846489392c28fab2f41ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:00&lt;00:00, 1.08MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02db91e544f9400c83010564e1891f3d"}},"e3c89e0f0da1492f8280788f53cd6428":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16ec1662c234458dbb382bf54d5bf02d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1a11943bea846489392c28fab2f41ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"02db91e544f9400c83010564e1891f3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4294af519c4749b890689c73470cd760":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0b9b75833f72427780a319cbdaaaefe7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b06391041a4548c18dfc0154b4a85bcf","IPY_MODEL_85e23876db314ff4bf301c797bf0404f"]}},"0b9b75833f72427780a319cbdaaaefe7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b06391041a4548c18dfc0154b4a85bcf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aa95c2ab0cec455e89cb11409437ae61","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec32bab32a2a42e8bbf19d898031bb20"}},"85e23876db314ff4bf301c797bf0404f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_14a758f87a784c8fbf763e1f98c15212","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 311kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b0e73363d614e30aff47d83ff901a65"}},"aa95c2ab0cec455e89cb11409437ae61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec32bab32a2a42e8bbf19d898031bb20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14a758f87a784c8fbf763e1f98c15212":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1b0e73363d614e30aff47d83ff901a65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ed51fc2ab1c4e0299bd8b58135cefd4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8401c9bcaa404d7bb6843d592fedd91d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c9d0633ab8664a1c86da90bfd7ea0e01","IPY_MODEL_b8e14eaa11154a8ba477d599ef6a6b9e"]}},"8401c9bcaa404d7bb6843d592fedd91d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9d0633ab8664a1c86da90bfd7ea0e01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e43b5c70e7bf453d81b5285fcbf9c21c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":351265583,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":351265583,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1cc40b6a38e49c5948df113325dccc9"}},"b8e14eaa11154a8ba477d599ef6a6b9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6bd077df33314e54b39a41e1ae06fb00","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 351M/351M [00:05&lt;00:00, 66.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d2d23ef8ffa4516bb289dd4b50f75a3"}},"e43b5c70e7bf453d81b5285fcbf9c21c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1cc40b6a38e49c5948df113325dccc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6bd077df33314e54b39a41e1ae06fb00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d2d23ef8ffa4516bb289dd4b50f75a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3eda16e803a4faa9ab7432bc5d6f025":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_171cb070b84644eca8aa6aa08bda469b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b1fa646e858747d8b6d743bcf4a01790","IPY_MODEL_ff864cfe1eb046ff9c53ae56a7b82f76"]}},"171cb070b84644eca8aa6aa08bda469b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b1fa646e858747d8b6d743bcf4a01790":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b37ba62752a24ebb9fccedd902181909","_dom_classes":[],"description":"Epoch: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12f57146d99f4caeab992d88d4a263aa"}},"ff864cfe1eb046ff9c53ae56a7b82f76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5eab58e8681042519248c47725b934e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [1:58:31&lt;00:00, 2370.58s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db644a096005401aaee1ba7b335922f9"}},"b37ba62752a24ebb9fccedd902181909":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"12f57146d99f4caeab992d88d4a263aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5eab58e8681042519248c47725b934e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db644a096005401aaee1ba7b335922f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c32007e87a1448eaa1dce62c0827c7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4b65da1b3e2848a8b852ef9068200e65","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4872e805ca094e399ecefd487ff90b3d","IPY_MODEL_fa68d769cf1c476eb9630d56833bd96c"]}},"4b65da1b3e2848a8b852ef9068200e65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4872e805ca094e399ecefd487ff90b3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_716e0bbd74334a06b8e3ec80581cf048","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":23482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ac0f1a45732482eb2044a11c26aa84e"}},"fa68d769cf1c476eb9630d56833bd96c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87b1fc811ada4ea0a02f913b3b531b9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23482/23482 [39:19&lt;00:00,  9.95it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f7915d84c9824b92b427f11625432db0"}},"716e0bbd74334a06b8e3ec80581cf048":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1ac0f1a45732482eb2044a11c26aa84e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87b1fc811ada4ea0a02f913b3b531b9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f7915d84c9824b92b427f11625432db0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"103a1d91f1254a0a87b97f715a458540":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e21f069a19547d3898df12f243f7599","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_841d53a639254309a4a53cbde8fb8be3","IPY_MODEL_bd7681608f5e442186267bc1b454a733"]}},"0e21f069a19547d3898df12f243f7599":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"841d53a639254309a4a53cbde8fb8be3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ef3d832483c947e1af5c701a90e552c6","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":23482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_085d07933be04cc3b6e83564d86ac7ef"}},"bd7681608f5e442186267bc1b454a733":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4545f4efc0a42e48c00e0221f32588c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23482/23482 [39:35&lt;00:00,  9.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_df1e87c38f754ecfbcbe5c47d33c711f"}},"ef3d832483c947e1af5c701a90e552c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"085d07933be04cc3b6e83564d86ac7ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4545f4efc0a42e48c00e0221f32588c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"df1e87c38f754ecfbcbe5c47d33c711f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9ba2b8d73874fbdb58303ddcf029869":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_21ba67441b47437480bb1ace9f2425ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6ba23ff74bdb424eb5183e76ed346256","IPY_MODEL_1e09c383cbc2448c860c80b83cf21209"]}},"21ba67441b47437480bb1ace9f2425ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ba23ff74bdb424eb5183e76ed346256":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9ba4a490b9a34adb8eadf6ad5b77c981","_dom_classes":[],"description":"Iteration: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":23482,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23482,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec32ca80137244709816496293ad8ea6"}},"1e09c383cbc2448c860c80b83cf21209":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1485e40946dc4936985acf02dd0534cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23482/23482 [39:36&lt;00:00,  9.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a6224b35ed1420fbef3c95e3295e2e7"}},"9ba4a490b9a34adb8eadf6ad5b77c981":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec32ca80137244709816496293ad8ea6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1485e40946dc4936985acf02dd0534cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2a6224b35ed1420fbef3c95e3295e2e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"55943ff0658a40f0bf6d1127c85c69f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_66f16e7593cf441ba60112e686213f9c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5678e52a5ab546ffbcb208dadbe8428e","IPY_MODEL_50b0b36b2c96418180dd749e182cecb9"]}},"66f16e7593cf441ba60112e686213f9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5678e52a5ab546ffbcb208dadbe8428e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e4dfd259e9f498d898d40abf2cdd4de","_dom_classes":[],"description":"Evaluating: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":5871,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5871,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9900ed4f3d0462c9dc8147feff82260"}},"50b0b36b2c96418180dd749e182cecb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cab6daab9b86497492f606e70481c653","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5871/5871 [01:40&lt;00:00, 58.56it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_debbe88e524d44839f6a687f93d47af5"}},"1e4dfd259e9f498d898d40abf2cdd4de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a9900ed4f3d0462c9dc8147feff82260":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cab6daab9b86497492f606e70481c653":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"debbe88e524d44839f6a687f93d47af5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3a301665a39840f9b6618e4cb9e92b99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_44967ad7d2cb4f10a8366a35220f872f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ae877de03d164723aed6d9d6fb980967","IPY_MODEL_0ffbe84b1ed94ee9a57c10f3abccb2bf"]}},"44967ad7d2cb4f10a8366a35220f872f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae877de03d164723aed6d9d6fb980967":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b942bf7666f84f1ca14c7402aa88a0f0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":554,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":554,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d755cd9eda574bb0b461d1ad14b158f7"}},"0ffbe84b1ed94ee9a57c10f3abccb2bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_62e1acaef86f460fa30d22787a6bf4bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 554/554 [00:00&lt;00:00, 818B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b110ed400f104e9e9649109c50073027"}},"b942bf7666f84f1ca14c7402aa88a0f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d755cd9eda574bb0b461d1ad14b158f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62e1acaef86f460fa30d22787a6bf4bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b110ed400f104e9e9649109c50073027":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c3d897744614436a3ba6cb2c8c2bc92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c12b4d44435a41eab20012bb916a220b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9f247fdd2a374800970892234d99d9f6","IPY_MODEL_6b3de257f043480887222c5ce5747bc3"]}},"c12b4d44435a41eab20012bb916a220b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f247fdd2a374800970892234d99d9f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_859d8e84a97f45668ebe7799074cea45","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_364ed37a673442cb90cfbd6960608f9a"}},"6b3de257f043480887222c5ce5747bc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a9ac7a1ff52a4d31973a193473a8c13a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:02&lt;00:00, 404kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_edef85187d5449e492cf743142251abf"}},"859d8e84a97f45668ebe7799074cea45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"364ed37a673442cb90cfbd6960608f9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9ac7a1ff52a4d31973a193473a8c13a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"edef85187d5449e492cf743142251abf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8208a889f1884d33b2f94ed557977bc7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_001c49ed8cdc4983a2974f1281628a41","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_46990361514d4996b370b61123cb8b05","IPY_MODEL_686358fb28c04dde953a1d80a335b418"]}},"001c49ed8cdc4983a2974f1281628a41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"46990361514d4996b370b61123cb8b05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_20cb665f46d44add9308adff55d30fc2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d8adc98445ab4acb9283ef08ee226609"}},"686358fb28c04dde953a1d80a335b418":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1d319b99c4f14300b6aa3f4a9babfda2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 291kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a46c451d4f7046bea8a5c30cfa28883b"}},"20cb665f46d44add9308adff55d30fc2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d8adc98445ab4acb9283ef08ee226609":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1d319b99c4f14300b6aa3f4a9babfda2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a46c451d4f7046bea8a5c30cfa28883b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"nlhGWDu0EcNC","colab_type":"text"},"source":["Chatbot based on Pre-Trained GPT - [article](https://towardsdatascience.com/beginners-guide-to-building-a-singlish-ai-chatbot-7ecff8255ee), [notebook](https://github.com/chuachinhon/practical_nlp)"]},{"cell_type":"markdown","metadata":{"id":"MEygq7X9Hsw7","colab_type":"text"},"source":["### Imports"]},{"cell_type":"code","metadata":{"id":"wJP4yWdlDfO5","colab_type":"code","colab":{}},"source":["import os\n","import codecs\n","import json\n","import numpy as np\n","import pandas as pd\n","import re\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqf5FKdWHu3s","colab_type":"text"},"source":["### Download data"]},{"cell_type":"code","metadata":{"id":"lkS5jMBIHCZt","colab_type":"code","colab":{}},"source":["# The corpus is a collection of SMS messages by Singaporean students at a local university. The \n","# language is 'Singlish', or colloquial Singaporean English. It's a mish-mash of several languages \n","# and local slang.\n","\n","!wget 'https://github.com/chuachinhon/practical_nlp/blob/master/data/singlish.json?raw=true' -O singlish.json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EXqVyRG0Hwim","colab_type":"text"},"source":["### Extract and clean data"]},{"cell_type":"code","metadata":{"id":"E5nSo3XbHK39","colab_type":"code","colab":{}},"source":["# The SMSes are nested pretty deeply in the original json file. Next few cells are aimed at \n","# extracting the data into a dataframe format\n","\n","raw = [json.loads(line) for line in open('singlish.json', 'r')]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpz5lSRBHK4B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1597930473781,"user_tz":-330,"elapsed":11687,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"8772715a-4ee8-4c18-b697-61f0656934d6"},"source":["df_raw = pd.json_normalize(raw)\n","\n","df_raw.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>smsCorpus.@date</th>\n","      <th>smsCorpus.@version</th>\n","      <th>smsCorpus.message</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2015.03.09</td>\n","      <td>1.2</td>\n","      <td>[{'@id': 10120, 'text': {'$': 'Bugis oso near ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  smsCorpus.@date  ...                                  smsCorpus.message\n","0      2015.03.09  ...  [{'@id': 10120, 'text': {'$': 'Bugis oso near ...\n","\n","[1 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"umPhRdU4HK4G","colab_type":"code","colab":{}},"source":["raw_messages = pd.concat(\n","    df_raw[\"smsCorpus.message\"]\n","    .apply(pd.DataFrame)\n","    .tolist(),\n","    keys=df_raw[\"smsCorpus.@date\"],\n","    sort=False,\n",").reset_index(level=\"smsCorpus.@date\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YyR4LZLhHK4J","colab_type":"code","colab":{}},"source":["raw_messages['sms_text'] = [x.get('$') for x in raw_messages['text']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhjntkJsHK4M","colab_type":"code","colab":{}},"source":["source = pd.json_normalize(raw_messages['source'], meta='@id')\n","\n","destination = pd.json_normalize(raw_messages['destination'], meta='@id')\n","\n","profile = pd.json_normalize(raw_messages['messageProfile'], meta='@id')\n","\n","collection = pd.json_normalize(raw_messages['collectionMethod'], meta='@id')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TAvnfCYTHK4P","colab_type":"code","colab":{}},"source":["sms_raw = pd.concat([raw_messages, source, destination, profile, collection], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0EEQ8sAzHK4U","colab_type":"code","colab":{}},"source":["cols = [\n","    \"@id\",\n","    \"userProfile.userID.$\",\n","    \"sms_text\",\n","    \"userProfile.country.$\",\n","    \"userProfile.age.$\",\n","    \"userProfile.gender.$\",\n","    \"srcNumber.$\",\n","    \"phoneModel.@manufactuer\",\n","    \"phoneModel.@smartphone\",\n","    \"userProfile.frequency.$\",\n","]\n","\n","sms = sms_raw[cols].copy()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKNb4LFfHK4X","colab_type":"code","colab":{}},"source":["sms['sms_text'] = sms['sms_text'].astype('str')\n","\n","# simple function to clean the text and remove non-ascii characters\n","def clean_text(text):    \n","    text = text.encode(\"ascii\", errors=\"ignore\").decode(\"ascii\") #remove non-ascii, Chinese characters\n","    text = re.sub(r\"http\\S+\", \"\", text)\n","    text = re.sub(r\"\\n\", \" \", text)\n","    text = re.sub(r\"\\n\\n\", \" \", text)\n","    text = re.sub(r\"\\W\", \" \", text)\n","    text = re.sub(r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text)\n","    text = text.strip(\" \")\n","    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n","    text = re.sub(' +',' ', text).strip() # get rid of multiple spaces and replace with a single    \n","    return text\n","\n","sms[\"clean_text\"] = sms['sms_text'].map(lambda text: clean_text(text))\n","\n","sms = sms.dropna(subset=['clean_text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GtsSFsRpHK4a","colab_type":"code","colab":{}},"source":["#adding a word count col for filtering\n","\n","sms['word_count'] = sms['clean_text'].str.count(' ') + 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UCOXHhjHK4d","colab_type":"code","colab":{}},"source":["# narrowing down col selection\n","\n","cols = [\"@id\", \"userProfile.userID.$\", \"userProfile.country.$\", \"sms_text\", \"clean_text\", \"word_count\"]\n","\n","sms = sms[cols].copy()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQhnTdhfHK4g","colab_type":"code","colab":{}},"source":["# renaming cols for clarity\n","\n","sms = sms.rename(\n","    columns={\n","        \"@id\": \"data_id\",\n","        \"userProfile.userID.$\": \"user_id\",\n","        \"userProfile.country.$\": \"country\",\n","        \"sms_text\": \"sms_text\",\n","        \"clean_text\": \"clean_text\",\n","        \"word_count\": \"word_count\",\n","\n","    }\n",")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"itjohp2HHK4j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597930482026,"user_tz":-330,"elapsed":19782,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"a8c61354-b5ad-4332-823a-e505c38b78dc"},"source":["sms.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(55835, 6)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Z5gwf3RpHK4m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1597930482027,"user_tz":-330,"elapsed":19770,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"64a82c78-3b3f-4414-b90d-048109abed99"},"source":["sms.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>data_id</th>\n","      <th>user_id</th>\n","      <th>country</th>\n","      <th>sms_text</th>\n","      <th>clean_text</th>\n","      <th>word_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10120</td>\n","      <td>51</td>\n","      <td>SG</td>\n","      <td>Bugis oso near wat...</td>\n","      <td>Bugis oso near wat</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10121</td>\n","      <td>51</td>\n","      <td>SG</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>Go until jurong point crazy Available only in ...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10122</td>\n","      <td>51</td>\n","      <td>SG</td>\n","      <td>I dunno until when... Lets go learn pilates...</td>\n","      <td>I dunno until when Lets go learn pilates</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10123</td>\n","      <td>51</td>\n","      <td>SG</td>\n","      <td>Den only weekdays got special price... Haiz......</td>\n","      <td>Den only weekdays got special price Haiz Cant ...</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10124</td>\n","      <td>51</td>\n","      <td>SG</td>\n","      <td>Meet after lunch la...</td>\n","      <td>Meet after lunch la</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   data_id  ... word_count\n","0    10120  ...          4\n","1    10121  ...         20\n","2    10122  ...          8\n","3    10123  ...         25\n","4    10124  ...          4\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"CE5TQaViHK4q","colab_type":"code","colab":{}},"source":["# Filter out SMSes of 3 words or less (too few words) and keep only those sent by users in Singapore.\n","\n","crit1 = sms['word_count'] > 3\n","crit2 = sms['country'] == 'SG'\n","crit3 = sms['country'] == 'Singapore'\n","\n","sms = sms[crit1 & (crit2 | crit3)].copy().reset_index()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4m8UwPkOIVx-","colab_type":"text"},"source":["### Prepare Conversation Data - with prior message context and reply"]},{"cell_type":"code","metadata":{"id":"jDrWAEbKHK4u","colab_type":"code","colab":{}},"source":["# the model will be fed 7 previous SMSes as \"context\", in order to generate the 'response'\n","\n","contexted = []\n","\n","n = 7\n","\n","for i in range(n, len(sms['clean_text'])):\n","    row = []\n","    prev = i - 1 - n # we additionally substract 1, so row will contain current response and 7 previous responses  \n","    for j in range(i, prev, -1):\n","        row.append(sms['clean_text'][j])\n","    contexted.append(row)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z2VV-ZDRHK4w","colab_type":"code","colab":{}},"source":["columns = ['response', 'context'] \n","columns = columns + ['context/'+str(i) for i in range(n-1)]\n","\n","df = pd.DataFrame.from_records(contexted, columns=columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"klkTgRLzHK40","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597930485831,"user_tz":-330,"elapsed":23504,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"fb129787-d623-4be7-cfb5-726328848799"},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(29353, 8)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"77CyZfF5HK42","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1597930485832,"user_tz":-330,"elapsed":23488,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"f229a948-694c-415e-f9b2-12e5b22e2cae"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>response</th>\n","      <th>context</th>\n","      <th>context/0</th>\n","      <th>context/1</th>\n","      <th>context/2</th>\n","      <th>context/3</th>\n","      <th>context/4</th>\n","      <th>context/5</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hey pple or for nights Excellent location wif ...</td>\n","      <td>nights We nt staying at port step liao Too ex</td>\n","      <td>m walking in citylink now faster come down Me ...</td>\n","      <td>Meet after lunch la</td>\n","      <td>Den only weekdays got special price Haiz Cant ...</td>\n","      <td>I dunno until when Lets go learn pilates</td>\n","      <td>Go until jurong point crazy Available only in ...</td>\n","      <td>Bugis oso near wat</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Yun ah the ubi one say if wan call by tomorrow...</td>\n","      <td>Hey pple or for nights Excellent location wif ...</td>\n","      <td>nights We nt staying at port step liao Too ex</td>\n","      <td>m walking in citylink now faster come down Me ...</td>\n","      <td>Meet after lunch la</td>\n","      <td>Den only weekdays got special price Haiz Cant ...</td>\n","      <td>I dunno until when Lets go learn pilates</td>\n","      <td>Go until jurong point crazy Available only in ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Hey tmr maybe can meet you at yck</td>\n","      <td>Yun ah the ubi one say if wan call by tomorrow...</td>\n","      <td>Hey pple or for nights Excellent location wif ...</td>\n","      <td>nights We nt staying at port step liao Too ex</td>\n","      <td>m walking in citylink now faster come down Me ...</td>\n","      <td>Meet after lunch la</td>\n","      <td>Den only weekdays got special price Haiz Cant ...</td>\n","      <td>I dunno until when Lets go learn pilates</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Oh i asked for fun Haha take care</td>\n","      <td>Hey tmr maybe can meet you at yck</td>\n","      <td>Yun ah the ubi one say if wan call by tomorrow...</td>\n","      <td>Hey pple or for nights Excellent location wif ...</td>\n","      <td>nights We nt staying at port step liao Too ex</td>\n","      <td>m walking in citylink now faster come down Me ...</td>\n","      <td>Meet after lunch la</td>\n","      <td>Den only weekdays got special price Haiz Cant ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>We are supposed to meet to discuss abt our tri...</td>\n","      <td>Oh i asked for fun Haha take care</td>\n","      <td>Hey tmr maybe can meet you at yck</td>\n","      <td>Yun ah the ubi one say if wan call by tomorrow...</td>\n","      <td>Hey pple or for nights Excellent location wif ...</td>\n","      <td>nights We nt staying at port step liao Too ex</td>\n","      <td>m walking in citylink now faster come down Me ...</td>\n","      <td>Meet after lunch la</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            response  ...                                          context/5\n","0  Hey pple or for nights Excellent location wif ...  ...                                 Bugis oso near wat\n","1  Yun ah the ubi one say if wan call by tomorrow...  ...  Go until jurong point crazy Available only in ...\n","2                  Hey tmr maybe can meet you at yck  ...           I dunno until when Lets go learn pilates\n","3                  Oh i asked for fun Haha take care  ...  Den only weekdays got special price Haiz Cant ...\n","4  We are supposed to meet to discuss abt our tri...  ...                                Meet after lunch la\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"GQU2fTBxHK45","colab_type":"code","colab":{}},"source":["# Split the df into training andd validation set\n","\n","train_df, validate_df = train_test_split(df, random_state=42, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UVxqB4CEHK47","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597930485836,"user_tz":-330,"elapsed":23450,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"29a0f895-470b-4928-f75b-6ceed909ac2f"},"source":["train_df.shape, validate_df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((23482, 8), (5871, 8))"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"_9YQsAtIHK4-","colab_type":"code","colab":{}},"source":["train_df.to_csv('train_df.csv', index=False)\n","validate_df.to_csv('validate_df.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uYCI75lIJdVm","colab_type":"text"},"source":["### Install Hugging Face transformers library for pre-trained DialoGPT model\n","\n","The original code to train and use this model in the following cells came from:\n","* [project 1](https://github.com/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb) - ([blog](https://nathancooper.io/i-am-a-nerd/chatbot/deep-learning/gpt2/2020/05/12/chatbot-part-1.html)) - Open-Dialog Chatbots for Learning New Languages [Part 1]\n","* [project 2](https://colab.research.google.com/drive/15wa925dj7jvdvrz8_z3vU7btqAFQLVlG) - Make your own Rick Sanchez (bot) with Transformers and DialoGPT fine-tuning\n","\n","I haven't tried to understand the code because it is specific to Hugging Face's API, and which was probably taken from their tutorial examples.\n","\n","More [details](https://huggingface.co/transformers/model_doc/dialogpt.html) on DialoGPT model (originally by Microsoft, incorporated into transformers library by Hugging Face)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"onU41i8g1J3M","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1597930449447,"user_tz":-330,"elapsed":9209,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"6b14dfde-1a05-4b0f-ee2e-7a4d5325cfe9"},"source":["! pip -q install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 778kB 4.5MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 12.5MB/s \n","\u001b[K     |████████████████████████████████| 3.0MB 22.9MB/s \n","\u001b[K     |████████████████████████████████| 890kB 46.6MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g91QzdqU2haO","colab":{}},"source":["import glob\n","import logging\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import random\n","import re\n","import shutil\n","from typing import Dict, List, Tuple\n","import torch\n","\n","from pathlib import Path\n","\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm.notebook import tqdm, trange\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","try:\n","    from torch.utils.tensorboard import SummaryWriter\n","except ImportError:\n","    from tensorboardX import SummaryWriter\n","\n","# Configs\n","logger = logging.getLogger(__name__)\n","\n","MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n","MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"npILKYKzJ6xS","colab_type":"text"},"source":["### Model Configuration"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"utprDGf06OVt","colab":{}},"source":["# If you are using a free Colab account, switch to DialoGPT-small instead of DialoGPT-medium or large\n","# If you encounter GPU out of memory issues on Colab, reduce the batch-size.\n","# The model checkpoints will take up considerable space on your G-drive. I changed it to save every 80K-steps\n","# If you have more storage space, feel free to adjust the checkpoints interval\n","\n","class Args():\n","    def __init__(self):\n","        self.output_dir = 'output-small'\n","        self.model_type = 'gpt2'\n","        self.model_name_or_path = 'microsoft/DialoGPT-small'\n","        self.config_name = 'microsoft/DialoGPT-small'\n","        self.tokenizer_name = 'microsoft/DialoGPT-small'\n","        self.cache_dir = 'cached'\n","        self.block_size = 64\n","        self.do_train = True\n","        self.do_eval = True\n","        self.evaluate_during_training = False\n","        self.per_gpu_train_batch_size = 1\n","        self.per_gpu_eval_batch_size = 1\n","        self.gradient_accumulation_steps = 1\n","        self.learning_rate = 5e-5\n","        self.weight_decay = 0.0\n","        self.adam_epsilon = 1e-8\n","        self.max_grad_norm = 1.0\n","        self.num_train_epochs = 3\n","        self.max_steps = -1\n","        self.warmup_steps = 0\n","        self.logging_steps = 80000\n","        self.save_steps = 80000\n","        self.save_total_limit = None\n","        self.eval_all_checkpoints = False\n","        self.no_cuda = False\n","        self.overwrite_output_dir = True\n","        self.overwrite_cache = True\n","        self.should_continue = False\n","        self.seed = 66\n","        self.local_rank = -1\n","        self.fp16 = False\n","        self.fp16_opt_level = 'O1'\n","\n","args = Args()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A1lGUCLoK7fQ","colab_type":"text"},"source":["### Convert data for DialoGPT model"]},{"cell_type":"code","metadata":{"id":"PuUfBldTHZ8g","colab_type":"code","colab":{}},"source":["# GPT2 is a language model that gives the probability of some word given the context.\n","#   eg. How much wood could a woodchuck chuck, if a woodchuck could [blank]\n","# The model then gives some probability to what the next word will be, which it uses to select the word. \n","# The selected word is then added back to our sentence and we repeat the whole process again. \n","#   eg. How much wood could a woodchuck chuck, if a woodchuck could chuck [blank]\n","# This is called an autoregressive model, where the result at one time step depends on the result \n","# at a previous time step.\n","#\n","# To train the language model we need a bunch of example sentences, or chunks of text.\n","# Then we hide the last word, and use these sentences with the missing word as our inputs \n","# and the last words as the target.\n","#\n","# DialoGPT is a model that repurposes this generator, GPT2, to behave as a chatbot.\n","# Consider a sample conversation between two speakers, where we include some special tokens that \n","# signify when one of the speakers has finished talking, which is called a 'turn'.\n","#   eg. Hi, how are you? [end_of_turn] I'm good, what about you? [end_of_turn] Not so good, lots of long nights at work. [end_of_turn] Darn, that sucks :( [end_of_conversation]\n","# We can then treat this example like the previous language model....\n","#   eg. Hi, how are you? [end_of_turn] [blank]\n","# ... and use the same logic to use GPT2 to guess the next word in this conversation...\n","#   eg. Hi, how are you? [end_of_turn] I'm [blank]\n","# ... and keep feeding back the prediction of our model."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PX7jeWpYmOe_","colab":{}},"source":["# Convert the dataframes into Pytorch Dataset and Dataloader for input to the model. The dataframes\n","# contain multiple historical dialogs (with a response and multiple previous contexts). Each dialog is\n","# converted into a single conversation string that is separated a special token that tells our model \n","# when a person is finished speaking. These are then tokenized with the Transformers API.\n","\n","def construct_conv(row, tokenizer, eos = True):\n","    flatten = lambda l: [item for sublist in l for item in sublist]\n","    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n","    conv = flatten(conv)\n","    return conv\n","\n","class ConversationDataset(Dataset):\n","    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n","\n","        block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n","\n","        directory = args.cache_dir\n","        cached_features_file = os.path.join(\n","            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n","        )\n","\n","        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n","            logger.info(\"Loading features from cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"rb\") as handle:\n","                self.examples = pickle.load(handle)\n","        else:\n","            logger.info(\"Creating features from dataset file at %s\", directory)\n","\n","            self.examples = []\n","            for _, row in df.iterrows():\n","                conv = construct_conv(row, tokenizer)\n","                self.examples.append(conv)\n","\n","            logger.info(\"Saving features into cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"wb\") as handle:\n","                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, item):\n","        return torch.tensor(self.examples[item], dtype=torch.long)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QTBBlcYZ_ucS","colab_type":"text"},"source":["### Train and Evaluate Functions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"naaRHoXgnStq","colab":{}},"source":["# Take a batch of examples from our dataloader and use it both as our inputs and labels. \n","# We do this because GPT2 uses the context to predict the next token. This prediction is \n","# then added to the original context and fed back in as the new context for generating the next token.\n","#\n","# To evaluate our model, we use the metric perplexity, which is a simple, but powerful metric. \n","# Perplexity is a measure of how unsure the model is in its choice of the next token. \n","# The more unsure our model is, the higher its perplexity.\n","#\n","# Although we use DialoGPT-small here due to resource constraints, DialoGPT-medium or large\n","# give substantially better perplexity scores.\n","\n","# Cacheing and storing of data/checkpoints\n","\n","def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n","    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n","\n","\n","def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu > 0:\n","        torch.cuda.manual_seed_all(args.seed)\n","\n","\n","def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n","    ordering_and_checkpoint_path = []\n","\n","    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n","\n","    for path in glob_checkpoints:\n","        if use_mtime:\n","            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n","        else:\n","            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n","            if regex_match and regex_match.groups():\n","                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n","\n","    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n","    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n","    return checkpoints_sorted\n","\n","\n","def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n","    if not args.save_total_limit:\n","        return\n","    if args.save_total_limit <= 0:\n","        return\n","\n","    # Check if we should delete older checkpoint(s)\n","    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n","    if len(checkpoints_sorted) <= args.save_total_limit:\n","        return\n","\n","    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n","    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n","    for checkpoint in checkpoints_to_be_deleted:\n","        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n","        shutil.rmtree(checkpoint)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tXzKlXHeu0Mb","colab":{}},"source":["def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n","    \"\"\" Train the model \"\"\"\n","    if args.local_rank in [-1, 0]:\n","        tb_writer = SummaryWriter()\n","\n","    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n","    train_dataloader = DataLoader(\n","        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    if args.max_steps > 0:\n","        t_total = args.max_steps\n","        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n","    else:\n","        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n","    model.resize_token_embeddings(len(tokenizer))\n","    # add_special_tokens_(model, tokenizer)\n","\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": args.weight_decay,\n","        },\n","        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","    )\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if (\n","        args.model_name_or_path\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n","    ):\n","        # Load in optimizer and scheduler states\n","        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n","\n","    if args.fp16:\n","        try:\n","            from apex import amp\n","        except ImportError:\n","            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n","\n","    # multi-gpu training (should be after apex fp16 initialization)\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Distributed training (should be after apex fp16 initialization)\n","    if args.local_rank != -1:\n","        model = torch.nn.parallel.DistributedDataParallel(\n","            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n","        )\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_dataset))\n","    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n","    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n","    logger.info(\n","        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n","        args.train_batch_size\n","        * args.gradient_accumulation_steps\n","        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n","    )\n","    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    epochs_trained = 0\n","    steps_trained_in_current_epoch = 0\n","    # Check if continuing training from a checkpoint\n","    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n","        try:\n","            # set global_step to gobal_step of last saved checkpoint from model path\n","            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n","            global_step = int(checkpoint_suffix)\n","            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n","            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n","\n","            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n","            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n","            logger.info(\"  Continuing training from global step %d\", global_step)\n","            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n","        except ValueError:\n","            logger.info(\"  Starting fine-tuning.\")\n","\n","    tr_loss, logging_loss = 0.0, 0.0\n","\n","    model.zero_grad()\n","    train_iterator = trange(\n","        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n","    )\n","    set_seed(args)  # Added here for reproducibility\n","    for _ in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n","        for step, batch in enumerate(epoch_iterator):\n","\n","            # Skip past any already trained steps if resuming training\n","            if steps_trained_in_current_epoch > 0:\n","                steps_trained_in_current_epoch -= 1\n","                continue\n","\n","            inputs, labels = (batch, batch)\n","            if inputs.shape[1] > 1024: continue\n","            inputs = inputs.to(args.device)\n","            labels = labels.to(args.device)\n","            model.train()\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n","\n","            if args.n_gpu > 1:\n","                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n","            if args.gradient_accumulation_steps > 1:\n","                loss = loss / args.gradient_accumulation_steps\n","\n","            if args.fp16:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            tr_loss += loss.item()\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\n","                if args.fp16:\n","                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n","                else:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n","                    # Log metrics\n","                    if (\n","                        args.local_rank == -1 and args.evaluate_during_training\n","                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n","                        results = evaluate(args, model, tokenizer)\n","                        for key, value in results.items():\n","                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n","                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n","                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n","                    logging_loss = tr_loss\n","\n","                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n","                    checkpoint_prefix = \"checkpoint\"\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n","                    os.makedirs(output_dir, exist_ok=True)\n","                    model_to_save = (\n","                        model.module if hasattr(model, \"module\") else model\n","                    )  # Take care of distributed/parallel training\n","                    model_to_save.save_pretrained(output_dir)\n","                    tokenizer.save_pretrained(output_dir)\n","\n","                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n","                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n","\n","                    _rotate_checkpoints(args, checkpoint_prefix)\n","\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n","\n","            if args.max_steps > 0 and global_step > args.max_steps:\n","                epoch_iterator.close()\n","                break\n","        if args.max_steps > 0 and global_step > args.max_steps:\n","            train_iterator.close()\n","            break\n","\n","    if args.local_rank in [-1, 0]:\n","        tb_writer.close()\n","\n","    return global_step, tr_loss / global_step\n","\n","# Evaluation of model\n","\n","def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args.output_dir\n","\n","    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n","    os.makedirs(eval_output_dir, exist_ok=True)\n","    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n","    # Note that DistributedSampler samples randomly\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(\n","        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    # multi-gpu evaluate\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        inputs, labels = (batch, batch)\n","        inputs = inputs.to(args.device)\n","        labels = labels.to(args.device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs, labels=labels)\n","            lm_loss = outputs[0]\n","            eval_loss += lm_loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    perplexity = torch.exp(torch.tensor(eval_loss))\n","\n","    result = {\"perplexity\": perplexity}\n","\n","    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZGkBu-F__8GV","colab_type":"text"},"source":["### Main Runner - Train the Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-MGD6bFXV4Z-","colab":{}},"source":["# Main runner\n","\n","def main(df_trn, df_val):\n","    args = Args()\n","    \n","    if args.should_continue:\n","        sorted_checkpoints = _sorted_checkpoints(args)\n","        if len(sorted_checkpoints) == 0:\n","            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n","        else:\n","            args.model_name_or_path = sorted_checkpoints[-1]\n","\n","    if (\n","        os.path.exists(args.output_dir)\n","        and os.listdir(args.output_dir)\n","        and args.do_train\n","        and not args.overwrite_output_dir\n","        and not args.should_continue\n","    ):\n","        raise ValueError(\n","            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n","                args.output_dir\n","            )\n","        )\n","\n","    # Setup CUDA, GPU & distributed training\n","    device = torch.device(\"cuda\")\n","    args.n_gpu = torch.cuda.device_count()\n","    args.device = device\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    logger.warning(\n","        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n","        args.local_rank,\n","        device,\n","        args.n_gpu,\n","        bool(args.local_rank != -1),\n","        args.fp16,\n","    )\n","\n","    # Set seed\n","    set_seed(args)\n","\n","    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n","    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=False,\n","        config=config,\n","        cache_dir=args.cache_dir,\n","    )\n","    model.to(args.device)\n","    \n","    logger.info(\"Training/evaluation parameters %s\", args)\n","\n","    # Training\n","    if args.do_train:\n","        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n","\n","        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n","    if args.do_train:\n","        # Create output directory if needed\n","        os.makedirs(args.output_dir, exist_ok=True)\n","\n","        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","        # They can then be reloaded using `from_pretrained()`\n","        model_to_save = (\n","            model.module if hasattr(model, \"module\") else model\n","        )  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(args.output_dir)\n","        tokenizer.save_pretrained(args.output_dir)\n","\n","        # Good practice: save your training arguments together with the trained model\n","        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n","\n","        # Load a trained model and vocabulary that you have fine-tuned\n","        model = AutoModelForCausalLM.from_pretrained(args.output_dir)\n","        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n","        model.to(args.device)\n","\n","    # Evaluation\n","    results = {}\n","    if args.do_eval and args.local_rank in [-1, 0]:\n","        checkpoints = [args.output_dir]\n","        if args.eval_all_checkpoints:\n","            checkpoints = list(\n","                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n","            )\n","            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n","            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n","\n","            model = AutoModelForCausalLM.from_pretrained(checkpoint)\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"__iqR8YFV-Ex","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5f619345b31d419e89ee671d8c1ae1ac","be7a6a4e47e24e4690d03a54fd4e64ef","d88d6c9d78f54676ab5974d881945a0b","9eaa8daaad8e487286b7dafe113267f9","e66b6f1b794349b89ca9ac1f28446210","8be343c8856d47d79f93d98cad3b0fbe","cd462195f1134b57bedd5f011dfd4623","bdb70af7b20b4726b12b0433b22019ee","69532160a65045f4b07b763d2ec25086","7457c63f92624b8db3bd6ca2db03c823","5d3b7c01a0d64912b18b7e6bc3916058","1059b80075b342cca356e233aa67889c","e3c89e0f0da1492f8280788f53cd6428","16ec1662c234458dbb382bf54d5bf02d","a1a11943bea846489392c28fab2f41ce","02db91e544f9400c83010564e1891f3d","4294af519c4749b890689c73470cd760","0b9b75833f72427780a319cbdaaaefe7","b06391041a4548c18dfc0154b4a85bcf","85e23876db314ff4bf301c797bf0404f","aa95c2ab0cec455e89cb11409437ae61","ec32bab32a2a42e8bbf19d898031bb20","14a758f87a784c8fbf763e1f98c15212","1b0e73363d614e30aff47d83ff901a65","2ed51fc2ab1c4e0299bd8b58135cefd4","8401c9bcaa404d7bb6843d592fedd91d","c9d0633ab8664a1c86da90bfd7ea0e01","b8e14eaa11154a8ba477d599ef6a6b9e","e43b5c70e7bf453d81b5285fcbf9c21c","e1cc40b6a38e49c5948df113325dccc9","6bd077df33314e54b39a41e1ae06fb00","3d2d23ef8ffa4516bb289dd4b50f75a3","e3eda16e803a4faa9ab7432bc5d6f025","171cb070b84644eca8aa6aa08bda469b","b1fa646e858747d8b6d743bcf4a01790","ff864cfe1eb046ff9c53ae56a7b82f76","b37ba62752a24ebb9fccedd902181909","12f57146d99f4caeab992d88d4a263aa","5eab58e8681042519248c47725b934e6","db644a096005401aaee1ba7b335922f9","2c32007e87a1448eaa1dce62c0827c7a","4b65da1b3e2848a8b852ef9068200e65","4872e805ca094e399ecefd487ff90b3d","fa68d769cf1c476eb9630d56833bd96c","716e0bbd74334a06b8e3ec80581cf048","1ac0f1a45732482eb2044a11c26aa84e","87b1fc811ada4ea0a02f913b3b531b9f","f7915d84c9824b92b427f11625432db0","103a1d91f1254a0a87b97f715a458540","0e21f069a19547d3898df12f243f7599","841d53a639254309a4a53cbde8fb8be3","bd7681608f5e442186267bc1b454a733","ef3d832483c947e1af5c701a90e552c6","085d07933be04cc3b6e83564d86ac7ef","a4545f4efc0a42e48c00e0221f32588c","df1e87c38f754ecfbcbe5c47d33c711f","b9ba2b8d73874fbdb58303ddcf029869","21ba67441b47437480bb1ace9f2425ce","6ba23ff74bdb424eb5183e76ed346256","1e09c383cbc2448c860c80b83cf21209","9ba4a490b9a34adb8eadf6ad5b77c981","ec32ca80137244709816496293ad8ea6","1485e40946dc4936985acf02dd0534cd","2a6224b35ed1420fbef3c95e3295e2e7","55943ff0658a40f0bf6d1127c85c69f9","66f16e7593cf441ba60112e686213f9c","5678e52a5ab546ffbcb208dadbe8428e","50b0b36b2c96418180dd749e182cecb9","1e4dfd259e9f498d898d40abf2cdd4de","a9900ed4f3d0462c9dc8147feff82260","cab6daab9b86497492f606e70481c653","debbe88e524d44839f6a687f93d47af5"]},"executionInfo":{"status":"ok","timestamp":1597937957955,"user_tz":-330,"elapsed":7289815,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"ea29899a-a656-44bb-cb0b-ccd8be432849"},"source":["train_df = pd.read_csv('train_df.csv')\n","validate_df = pd.read_csv('validate_df.csv')\n","\n","\n","main(train_df, validate_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/20/2020 13:37:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","08/20/2020 13:37:49 - INFO - filelock -   Lock 140713799870784 acquired on cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5.lock\n","08/20/2020 13:37:49 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json not found in cache or force_download set to True, downloading to /content/cached/tmpf8ncpqn3\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5f619345b31d419e89ee671d8c1ae1ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=554.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 13:37:49 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json in cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n","08/20/2020 13:37:49 - INFO - transformers.file_utils -   creating metadata file for cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n","08/20/2020 13:37:49 - INFO - filelock -   Lock 140713799870784 released on cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5.lock\n","08/20/2020 13:37:49 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n","08/20/2020 13:37:49 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"vocab_size\": 50257\n","}\n","\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 13:37:50 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n","08/20/2020 13:37:50 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","08/20/2020 13:37:50 - INFO - transformers.tokenization_utils_base -   Model name 'microsoft/DialoGPT-small' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'microsoft/DialoGPT-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n","08/20/2020 13:37:50 - INFO - filelock -   Lock 140713498389304 acquired on cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n","08/20/2020 13:37:50 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json not found in cache or force_download set to True, downloading to /content/cached/tmp_0kefgc_\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69532160a65045f4b07b763d2ec25086","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 13:37:51 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json in cache at cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","08/20/2020 13:37:51 - INFO - transformers.file_utils -   creating metadata file for cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","08/20/2020 13:37:51 - INFO - filelock -   Lock 140713498389304 released on cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 13:37:51 - INFO - filelock -   Lock 140713498390200 acquired on cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","08/20/2020 13:37:51 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt not found in cache or force_download set to True, downloading to /content/cached/tmplidns9c7\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4294af519c4749b890689c73470cd760","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 13:37:52 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt in cache at cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","08/20/2020 13:37:52 - INFO - transformers.file_utils -   creating metadata file for cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","08/20/2020 13:37:52 - INFO - filelock -   Lock 140713498390200 released on cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 13:37:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json from cache at cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","08/20/2020 13:37:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt from cache at cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","08/20/2020 13:37:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/added_tokens.json from cache at None\n","08/20/2020 13:37:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/special_tokens_map.json from cache at None\n","08/20/2020 13:37:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer_config.json from cache at None\n","08/20/2020 13:37:53 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer.json from cache at None\n","08/20/2020 13:37:53 - INFO - filelock -   Lock 140713899190536 acquired on cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483.lock\n","08/20/2020 13:37:53 - INFO - transformers.file_utils -   https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin not found in cache or force_download set to True, downloading to /content/cached/tmpvbgiqsip\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ed51fc2ab1c4e0299bd8b58135cefd4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=351265583.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 13:37:58 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin in cache at cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n","08/20/2020 13:37:58 - INFO - transformers.file_utils -   creating metadata file for cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n","08/20/2020 13:37:58 - INFO - filelock -   Lock 140713899190536 released on cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483.lock\n","08/20/2020 13:37:58 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin from cache at cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 13:38:03 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","08/20/2020 13:38:03 - WARNING - transformers.modeling_utils -   Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at microsoft/DialoGPT-small and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","08/20/2020 13:38:16 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7ffa7c072f28>\n","08/20/2020 13:38:16 - INFO - __main__ -   Creating features from dataset file at cached\n","08/20/2020 13:38:45 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n","08/20/2020 13:38:45 - INFO - __main__ -   ***** Running training *****\n","08/20/2020 13:38:45 - INFO - __main__ -     Num examples = 23482\n","08/20/2020 13:38:45 - INFO - __main__ -     Num Epochs = 3\n","08/20/2020 13:38:45 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n","08/20/2020 13:38:45 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n","08/20/2020 13:38:45 - INFO - __main__ -     Gradient Accumulation steps = 1\n","08/20/2020 13:38:45 - INFO - __main__ -     Total optimization steps = 70446\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3eda16e803a4faa9ab7432bc5d6f025","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c32007e87a1448eaa1dce62c0827c7a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=23482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"103a1d91f1254a0a87b97f715a458540","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=23482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9ba2b8d73874fbdb58303ddcf029869","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=23482.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 15:37:17 - INFO - __main__ -    global_step = 70440, average loss = 2.8329429477771075\n","08/20/2020 15:37:17 - INFO - __main__ -   Saving model checkpoint to output-small\n","08/20/2020 15:37:17 - INFO - transformers.configuration_utils -   Configuration saved in output-small/config.json\n"],"name":"stderr"},{"output_type":"stream","text":["\n","\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 15:37:18 - INFO - transformers.modeling_utils -   Model weights saved in output-small/pytorch_model.bin\n","08/20/2020 15:37:19 - INFO - transformers.configuration_utils -   loading configuration file output-small/config.json\n","08/20/2020 15:37:19 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","08/20/2020 15:37:19 - INFO - transformers.modeling_utils -   loading weights file output-small/pytorch_model.bin\n","08/20/2020 15:37:23 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","08/20/2020 15:37:23 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at output-small.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","08/20/2020 15:37:23 - INFO - transformers.configuration_utils -   loading configuration file output-small/config.json\n","08/20/2020 15:37:23 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   Model name 'output-small' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   Didn't find file output-small/added_tokens.json. We won't load it.\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   Didn't find file output-small/tokenizer.json. We won't load it.\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   loading file output-small/vocab.json\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   loading file output-small/merges.txt\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   loading file None\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   loading file output-small/special_tokens_map.json\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   loading file output-small/tokenizer_config.json\n","08/20/2020 15:37:23 - INFO - transformers.tokenization_utils_base -   loading file None\n","08/20/2020 15:37:24 - INFO - __main__ -   Evaluate the following checkpoints: ['output-small']\n","08/20/2020 15:37:24 - INFO - transformers.configuration_utils -   loading configuration file output-small/config.json\n","08/20/2020 15:37:24 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","08/20/2020 15:37:24 - INFO - transformers.modeling_utils -   loading weights file output-small/pytorch_model.bin\n","08/20/2020 15:37:28 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","08/20/2020 15:37:28 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at output-small.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","08/20/2020 15:37:29 - INFO - __main__ -   Creating features from dataset file at cached\n","08/20/2020 15:37:37 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n","08/20/2020 15:37:37 - INFO - __main__ -   ***** Running evaluation  *****\n","08/20/2020 15:37:37 - INFO - __main__ -     Num examples = 5871\n","08/20/2020 15:37:37 - INFO - __main__ -     Batch size = 1\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55943ff0658a40f0bf6d1127c85c69f9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=5871.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 15:39:17 - INFO - __main__ -   ***** Eval results  *****\n","08/20/2020 15:39:17 - INFO - __main__ -     perplexity = tensor(5.6225)\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'perplexity_': tensor(5.6225)}"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"uOmFW-LTAejX","colab_type":"text"},"source":["### Chat with Bot"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nIeqMwZktv7N","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3a301665a39840f9b6618e4cb9e92b99","44967ad7d2cb4f10a8366a35220f872f","ae877de03d164723aed6d9d6fb980967","0ffbe84b1ed94ee9a57c10f3abccb2bf","b942bf7666f84f1ca14c7402aa88a0f0","d755cd9eda574bb0b461d1ad14b158f7","62e1acaef86f460fa30d22787a6bf4bb","b110ed400f104e9e9649109c50073027","2c3d897744614436a3ba6cb2c8c2bc92","c12b4d44435a41eab20012bb916a220b","9f247fdd2a374800970892234d99d9f6","6b3de257f043480887222c5ce5747bc3","859d8e84a97f45668ebe7799074cea45","364ed37a673442cb90cfbd6960608f9a","a9ac7a1ff52a4d31973a193473a8c13a","edef85187d5449e492cf743142251abf","8208a889f1884d33b2f94ed557977bc7","001c49ed8cdc4983a2974f1281628a41","46990361514d4996b370b61123cb8b05","686358fb28c04dde953a1d80a335b418","20cb665f46d44add9308adff55d30fc2","d8adc98445ab4acb9283ef08ee226609","1d319b99c4f14300b6aa3f4a9babfda2","a46c451d4f7046bea8a5c30cfa28883b"]},"executionInfo":{"status":"ok","timestamp":1597938144452,"user_tz":-330,"elapsed":141366,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"843c9007-6d5c-4cda-c1d3-e780485a26fc"},"source":["# Now that we have our model trained, we can have our first conversation with it!\n","\n","tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n","model = AutoModelForCausalLM.from_pretrained('output-small')\n","\n","# Let's chat for 5 lines\n","for step in range(10):\n","    # encode the new user input, add the eos_token and return a tensor in Pytorch\n","    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n","    # print(new_user_input_ids)\n","\n","    # append the new user input tokens to the chat history\n","    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n","\n","    # generated a response while limiting the total chat history to 1000 tokens, \n","    chat_history_ids = model.generate(\n","        bot_input_ids, max_length=500,\n","        pad_token_id=tokenizer.eos_token_id,  \n","        no_repeat_ngram_size=3,       \n","        do_sample=True, \n","        top_k=100, \n","        top_p=0.7,\n","        temperature = 0.8\n","    )\n","    \n","    # pretty print last ouput tokens from bot\n","    print(\"Beng Bot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["08/20/2020 15:40:04 - INFO - filelock -   Lock 140713768626944 acquired on /root/.cache/torch/transformers/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5.lock\n","08/20/2020 15:40:04 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp7gql89p1\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a301665a39840f9b6618e4cb9e92b99","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=554.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 15:40:04 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json in cache at /root/.cache/torch/transformers/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n","08/20/2020 15:40:04 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n","08/20/2020 15:40:04 - INFO - filelock -   Lock 140713768626944 released on /root/.cache/torch/transformers/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5.lock\n","08/20/2020 15:40:04 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at /root/.cache/torch/transformers/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n","08/20/2020 15:40:04 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","08/20/2020 15:40:04 - INFO - transformers.tokenization_utils_base -   Model name 'microsoft/DialoGPT-small' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'microsoft/DialoGPT-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 15:40:04 - INFO - filelock -   Lock 140713768628064 acquired on /root/.cache/torch/transformers/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n","08/20/2020 15:40:04 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpjc72swj7\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c3d897744614436a3ba6cb2c8c2bc92","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 15:40:05 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json in cache at /root/.cache/torch/transformers/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","08/20/2020 15:40:05 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","08/20/2020 15:40:05 - INFO - filelock -   Lock 140713768628064 released on /root/.cache/torch/transformers/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 15:40:05 - INFO - filelock -   Lock 140713768547440 acquired on /root/.cache/torch/transformers/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n","08/20/2020 15:40:05 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp2qar__vt\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8208a889f1884d33b2f94ed557977bc7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["08/20/2020 15:40:06 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt in cache at /root/.cache/torch/transformers/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","08/20/2020 15:40:06 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","08/20/2020 15:40:06 - INFO - filelock -   Lock 140713768547440 released on /root/.cache/torch/transformers/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["08/20/2020 15:40:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json from cache at /root/.cache/torch/transformers/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n","08/20/2020 15:40:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt from cache at /root/.cache/torch/transformers/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","08/20/2020 15:40:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/added_tokens.json from cache at None\n","08/20/2020 15:40:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/special_tokens_map.json from cache at None\n","08/20/2020 15:40:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer_config.json from cache at None\n","08/20/2020 15:40:07 - INFO - transformers.tokenization_utils_base -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer.json from cache at None\n","08/20/2020 15:40:07 - INFO - transformers.configuration_utils -   loading configuration file output-small/config.json\n","08/20/2020 15:40:07 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"resid_pdrop\": 0.1,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","08/20/2020 15:40:07 - INFO - transformers.modeling_utils -   loading weights file output-small/pytorch_model.bin\n","08/20/2020 15:40:12 - INFO - transformers.modeling_utils -   All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","08/20/2020 15:40:12 - INFO - transformers.modeling_utils -   All the weights of GPT2LMHeadModel were initialized from the model checkpoint at output-small.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":[">> User:eh where u\n","Beng Bot: where u going today\n",">> User:ok wanna go bugis to makan\n","Beng Bot: wat time u coming back\n",">> User:what u wanna makan\n","Beng Bot: can u give me ur tel no\n",">> User:free how can?\n","Beng Bot: can help me ask uncle he wan fetch u\n",">> User:ok see you later bro\n","Beng Bot: hey i will be late oversleep\n",">> User:q\n","Beng Bot: hey will u be late over icq\n",">> User:bye\n","Beng Bot: hi i will call u when i reach dhoby ghaut\n",">> User:what is your name\n","Beng Bot: wat is your position at dhoby Ghaut\n",">> User:i am hungry\n","Beng Bot: t been captured yet\n",">> User:time to sleep now\n","Beng Bot: where you want to go\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GKtIIkc6_wij","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}