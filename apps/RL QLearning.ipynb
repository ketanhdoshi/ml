{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RL QLearning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMNFDThj4d/kddzsQhqMTiR"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"O_K8wZhE7JWQ"},"source":["###Q Learning example based on [notebook](https://colab.research.google.com/gist/simoninithomas/466c81aa1c2a07dd14793240c6d033c5/q-learning-with-taxi-v3.ipynb), [article](https://thomassimonini.medium.com/q-learning-lets-create-an-autonomous-taxi-part-1-2-3e8f5e764358)."]},{"cell_type":"markdown","metadata":{"id":"n9666cKX7rw-"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"jMncw2d_7DvO","executionInfo":{"status":"ok","timestamp":1604572862799,"user_tz":-330,"elapsed":1850,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}}},"source":["import numpy as np\n","import gym\n","import random"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f8CPPEv07v9Z"},"source":["### Create OpenAI environment"]},{"cell_type":"code","metadata":{"id":"SRhuoSSa70IG","executionInfo":{"status":"ok","timestamp":1604572865691,"user_tz":-330,"elapsed":1607,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"61a546d3-b6a4-4e49-f20d-3173d858d56e","colab":{"base_uri":"https://localhost:8080/"}},"source":["env = gym.make(\"Taxi-v3\")\n","env.render()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| |\u001b[43m \u001b[0m: | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"59KAb3YU8cKD"},"source":["### Create Q Table"]},{"cell_type":"code","metadata":{"id":"rBroFrrZ8BA5","executionInfo":{"status":"ok","timestamp":1604572868420,"user_tz":-330,"elapsed":1216,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"48cd13b9-f3b3-4851-92d6-6726ffa89a6b","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Get number of states and actions from the environment\n","num_states = env.observation_space.n\n","num_actions = env.action_space.n\n","num_states, num_actions, env.action_space, env.observation_space"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 6, Discrete(6), Discrete(500))"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"COeh0Feg8bMp","executionInfo":{"status":"ok","timestamp":1604572897870,"user_tz":-330,"elapsed":2681,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"e190b7be-b2b3-42df-fefc-a3a0ed2a3db6","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Create our Q table with state_size rows and action_size columns (500x6)\n","Q = np.zeros((num_states, num_actions))\n","Q.shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 6)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"c6aMUoiFE9Ra"},"source":["### E-greedy policy and Q-Learning training loop"]},{"cell_type":"code","metadata":{"id":"BMg5u4yPK3s3","executionInfo":{"status":"ok","timestamp":1604574876870,"user_tz":-330,"elapsed":1240,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}}},"source":["def egreedy(state, epsilon):\n","  x = random.uniform(0,1)\n","  if (x < epsilon):\n","    action = random.randint(0, num_actions - 1)\n","  else:\n","    action = np.argmax(Q[state])\n","  return action\n","\n","def ql_loop(num_episodes, max_steps, lr, gamma):\n","  epsilon_start, epsilon_end = 1.0, .001\n","  epsilon = epsilon_start\n","\n","  for i_episode in range(num_episodes):\n","    state = env.reset()\n","\n","    # Decay the epsilon for each episode\n","    epsilon_decay = (num_episodes - i_episode) / num_episodes\n","    epsilon = epsilon_end + (epsilon_start - epsilon_end) * epsilon_decay\n","\n","    for t in range(max_steps):\n","      #env.render()\n","\n","      # Take an action with the e-greedy policy and observe the results\n","      action = egreedy(state, epsilon)\n","      #print(state, action)\n","      next_state, reward, done, info = env.step(action)\n","\n","      # Update the Q-value of the state-action taken.\n","      Q[state, action] += lr * (reward + gamma * np.max(Q[next_state]) - Q[state, action])\n","      state = next_state\n","\n","      # End of episode\n","      if done:\n","        #print(\"Episode finished after {} timesteps\".format(t+1))\n","        break\n","  env.close()"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1H-r5VAMEypF"},"source":["### Define hyperparameters and train the agent"]},{"cell_type":"code","metadata":{"id":"uBvTJacAhKd7"},"source":["num_episodes = 25000\n","max_steps = 200\n","lr = 0.01\n","gamma = 0.99\n","\n","ql_loop(num_episodes, max_steps, lr, gamma)\n","print (Q)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iEBMnKbGFE4D"},"source":["### Inference with trained agent"]},{"cell_type":"code","metadata":{"id":"H_YdZxmdFIak","executionInfo":{"status":"ok","timestamp":1604574974222,"user_tz":-330,"elapsed":1258,"user":{"displayName":"Ketan Doshi","photoUrl":"","userId":"05524438722017440561"}},"outputId":"8e891a51-8315-40c0-86c8-ae90c84c91cf","colab":{"base_uri":"https://localhost:8080/"}},"source":["def inference(num_episodes, max_steps):\n","  total_rewards = 0\n","  for i_episode in range(num_episodes):\n","    state = env.reset()\n","\n","    for t in range(max_steps):\n","      env.render()\n","\n","      # Take an action with exploration\n","      action = np.argmax(Q[state])\n","      next_state, reward, done, info = env.step(action)\n","      total_rewards += reward\n","      state = next_state\n","\n","      # End of episode\n","      if done:\n","        print(\"Episode finished after {} timesteps\".format(t+1))\n","        break\n","  env.close()\n","  print (f'Average rewards = {total_rewards/num_episodes}')\n","\n","inference(5, 200)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : :\u001b[43m \u001b[0m: |\n","| | : | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : :\u001b[43m \u001b[0m: : |\n","| | : | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| :\u001b[43m \u001b[0m: : : |\n","| | : | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","|\u001b[43m \u001b[0m: : : : |\n","| | : | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","|\u001b[43m \u001b[0m| : | : |\n","|\u001b[34;1mY\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[42mY\u001b[0m| : |B: |\n","+---------+\n","  (Pickup)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","|\u001b[42m_\u001b[0m| : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","|\u001b[42m_\u001b[0m: : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| :\u001b[42m_\u001b[0m: : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : :\u001b[42m_\u001b[0m: : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : :\u001b[42m_\u001b[0m: |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : : |\n","| : : : :\u001b[42m_\u001b[0m|\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :\u001b[35mG\u001b[0m|\n","| : | : :\u001b[42m_\u001b[0m|\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|R: | : :\u001b[35m\u001b[42mG\u001b[0m\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","Episode finished after 15 timesteps\n","+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| :\u001b[43m \u001b[0m| : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","\n","+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| :\u001b[43m \u001b[0m: : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : :\u001b[43m \u001b[0m: : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : :\u001b[43m \u001b[0m: |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| : | : : |\n","| : : : :\u001b[43m \u001b[0m|\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :\u001b[34;1mG\u001b[0m|\n","| : | : :\u001b[43m \u001b[0m|\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|R: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|R: | : :\u001b[42mG\u001b[0m|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (Pickup)\n","+---------+\n","|R: | :\u001b[42m_\u001b[0m:G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|R: | : :G|\n","| : | :\u001b[42m_\u001b[0m: |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : |\u001b[42m_\u001b[0m: : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : :\u001b[42m_\u001b[0m: : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| :\u001b[42m_\u001b[0m: : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","|\u001b[42m_\u001b[0m: : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","|\u001b[42m_\u001b[0m| : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35m\u001b[42mY\u001b[0m\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","Episode finished after 16 timesteps\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : |\u001b[43m \u001b[0m: : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : :\u001b[43m \u001b[0m: : |\n","| | : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : :\u001b[43m \u001b[0m: |\n","| | : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (East)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : |\u001b[43m \u001b[0m: |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[42mB\u001b[0m: |\n","+---------+\n","  (Pickup)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : |\u001b[42m_\u001b[0m: |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : :\u001b[42m_\u001b[0m: |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : :\u001b[42m_\u001b[0m: : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| :\u001b[42m_\u001b[0m: : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","|\u001b[42m_\u001b[0m: : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (West)\n","+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","|\u001b[42m_\u001b[0m: | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |B: |\n","+---------+\n","  (North)\n","Episode finished after 13 timesteps\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : |\u001b[43m \u001b[0m: |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : :\u001b[43m \u001b[0m: |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","| : | : : |\n","| : :\u001b[43m \u001b[0m: : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (West)\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","| : | : : |\n","| :\u001b[43m \u001b[0m: : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (West)\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","| : | : : |\n","|\u001b[43m \u001b[0m: : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (West)\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","|\u001b[43m \u001b[0m: | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[42mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (Pickup)\n","+---------+\n","|R: | : :G|\n","|\u001b[42m_\u001b[0m: | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","|\u001b[42m_\u001b[0m: : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| :\u001b[42m_\u001b[0m: : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : :\u001b[42m_\u001b[0m: : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : :\u001b[42m_\u001b[0m: |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : |\u001b[42m_\u001b[0m: |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n","+---------+\n","  (South)\n","Episode finished after 15 timesteps\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","|\u001b[43m \u001b[0m| : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","| : | : : |\n","|\u001b[43m \u001b[0m: : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[34;1mR\u001b[0m: | : :G|\n","|\u001b[43m \u001b[0m: | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (North)\n","+---------+\n","|\u001b[42mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (Pickup)\n","+---------+\n","|R: | : :G|\n","|\u001b[42m_\u001b[0m: | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","|\u001b[42m_\u001b[0m: : : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| :\u001b[42m_\u001b[0m: : : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : :\u001b[42m_\u001b[0m: : |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : :\u001b[42m_\u001b[0m: |\n","| | : | : |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (East)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : |\u001b[42m_\u001b[0m: |\n","|Y| : |\u001b[35mB\u001b[0m: |\n","+---------+\n","  (South)\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n","+---------+\n","  (South)\n","Episode finished after 12 timesteps\n","Average rewards = 6.8\n"],"name":"stdout"}]}]}