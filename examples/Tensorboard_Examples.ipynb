{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorboard Examples.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PnN0kbiRZdQz",
        "ADgDwEX1KttM",
        "tuv_t56OKxFy",
        "Adcl9KqHK1-E",
        "r_VAo0ldW0OA",
        "mWYh_e8dF7qE",
        "HCr--JdWXeNJ",
        "xXWkWjrfXU8p"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketanhdoshi/ml/blob/master/examples/Tensorboard_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnN0kbiRZdQz"
      },
      "source": [
        "### Visualise with Tensorboard\n",
        "This notebook has to be copied into other notebooks where you want to use Tensorboard\n",
        "\n",
        "The next few examples are from this [article](https://www.easy-tensorflow.com/tf-tutorials/basics/introduction-to-tensorboard)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TaMseb6ZOD3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4da36417-10b5-4727-e26c-b7e95f23afca"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3sFSzVhlOVu"
      },
      "source": [
        "# Set the LOGDIR correctly to use Tensorboard\n",
        "LOG_DIR = 'tbtry'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADgDwEX1KttM"
      },
      "source": [
        "### Visualise a graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_IYPVnhtTMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30d212e5-af43-46d1-f75e-2a24e152b76e"
      },
      "source": [
        "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
        "\n",
        "# create graph\n",
        "a = tf.constant(2, name=\"const_a\")\n",
        "b = tf.constant(3, name=\"const_b\")\n",
        "c = tf.add(a, b, name=\"addop\")\n",
        "\n",
        "# launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # or creating the writer inside the session\n",
        "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
        "    print(sess.run(c))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuv_t56OKxFy"
      },
      "source": [
        "### Visualise the Learning - Scalar and Histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gte_vVyVJAXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e859b6dc-09c3-4201-acff-3bbe06dfd24f"
      },
      "source": [
        "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
        "\n",
        "# ---------------- Create the Variables ---------------\n",
        "# create the scalar variable\n",
        "x_scalar = tf.get_variable('x_scalar', shape=[], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
        "\n",
        "# create the matrix variable\n",
        "x_matrix = tf.get_variable('x_matrix', shape=[30, 40], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
        "\n",
        "# ---------------- Create the Summary ---------------\n",
        "# create the scalar summary\n",
        "scalar_summary = tf.summary.scalar(name='My_first_scalar_summary', tensor=x_scalar)\n",
        "\n",
        "# A histogram summary for the non-scalar (i.e. 2D or matrix) tensor\n",
        "histogram_summary = tf.summary.histogram('My_histogram_summary', x_matrix)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # create the writer inside the session\n",
        "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
        "\n",
        "    for step in range(100):\n",
        "        # loop over several initializations of the variable\n",
        "        sess.run(init)\n",
        "\n",
        "        # evaluate the summaries\n",
        "        summary1, summary2 = sess.run([scalar_summary, histogram_summary])\n",
        "\n",
        "        # add the summary to the writer (i.e. to the event file)\n",
        "        writer.add_summary(summary1, step)\n",
        "        writer.add_summary(summary2, step)\n",
        "    print('Done with writing the summaries')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with writing the summaries\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adcl9KqHK1-E"
      },
      "source": [
        "### Visualise the Learning - Merged Scalar and Histogram\n",
        "\n",
        "You need to run each summary and then use your writer to write each of them on the disk. In practice, you might use tens and hundreds of such summaries to track different parameters in your model. This makes running and writing the summaries extremly inefficient. The way around it is to merge all summaries in your graph and run them at once inside your session. This can be done using tf.summary.merge_all()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UHwRscJK5jl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "012fe571-ea5d-4cac-b974-85efda4aa3cc"
      },
      "source": [
        "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
        "\n",
        "# create the variables\n",
        "x_scalar = tf.get_variable('x_scalar', shape=[], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
        "x_matrix = tf.get_variable('x_matrix', shape=[30, 40], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
        "\n",
        "# ____step 1:____ create the summaries\n",
        "# A scalar summary for the scalar tensor\n",
        "scalar_summary = tf.summary.scalar('My_scalar_summary', x_scalar)\n",
        "# A histogram summary for the non-scalar (i.e. 2D or matrix) tensor\n",
        "histogram_summary = tf.summary.histogram('My_histogram_summary', x_matrix)\n",
        "\n",
        "# ____step 2:____ merge all summaries\n",
        "merged = tf.summary.merge_all()\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # ____step 3:____ creating the writer inside the session\n",
        "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
        "    for step in range(100):\n",
        "        # loop over several initializations of the variable\n",
        "        sess.run(init)\n",
        "        # ____step 4:____ evaluate the merged summaries\n",
        "        summary = sess.run(merged)\n",
        "        # ____step 5:____ add summary to the writer (i.e. to the event file) to write on the disc\n",
        "        writer.add_summary(summary, step)\n",
        "    print('Done writing the summaries')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done writing the summaries\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_VAo0ldW0OA"
      },
      "source": [
        "### Visualise the Learning - Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrsoegiIW4zu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2716f916-6342-4ff2-b2c4-8530d935e06f"
      },
      "source": [
        "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
        "\n",
        "# create the variables\n",
        "w_gs = tf.get_variable('W_Grayscale', shape=[30, 10], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
        "w_c = tf.get_variable('W_Color', shape=[50, 30], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
        "\n",
        "# ___step 0:___ reshape it to 4D-tensors\n",
        "w_gs_reshaped = tf.reshape(w_gs, (3, 10, 10, 1))\n",
        "w_c_reshaped = tf.reshape(w_c, (5, 10, 10, 3))\n",
        "\n",
        "# ____step 1:____ create the summaries\n",
        "gs_summary = tf.summary.image('Grayscale', w_gs_reshaped)\n",
        "c_summary = tf.summary.image('Color', w_c_reshaped)\n",
        "\n",
        "# create the op for initializing all variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# launch the graph in a session\n",
        "with tf.Session() as sess:\n",
        "    # ____step 3:____ creating the writer inside the session\n",
        "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
        "    # initialize all variables\n",
        "    sess.run(init)\n",
        "    # ____step 4:____ evaluate the merged op to get the summaries\n",
        "    summary1, summary2 = sess.run([gs_summary, c_summary])\n",
        "    # ____step 5:____ add summary to the writer (i.e. to the event file) to write on the disc\n",
        "    writer.add_summary(summary1, step)\n",
        "    writer.add_summary(summary2, step)\n",
        "    print('Done writing the summaries')\n",
        "\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done writing the summaries\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWYh_e8dF7qE"
      },
      "source": [
        "### Histogram with [moving](https://www.tensorflow.org/guide/tensorboard_histograms) mean\n",
        "\n",
        "Create two different histograms and a scalar. Also do two trial runs which are saved in different folders. This allows you to toggle between those runs in the Tensorboard visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE713V7OGEQ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e7cece29-e34f-4c97-8fbb-c0af802af68a"
      },
      "source": [
        "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
        "\n",
        "k = tf.placeholder(tf.float32)\n",
        "\n",
        "# Make a normal distribution, with a shifting mean\n",
        "mean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)\n",
        "# Record that distribution into a histogram summary\n",
        "tf.summary.histogram(\"normal/moving_mean\", mean_moving_normal)\n",
        "\n",
        "# Make another normal distribution, with a shifting mean\n",
        "mean_moving_normal_two = tf.random_normal(shape=[1000], mean=(12*k), stddev=4)\n",
        "# Record that distribution into a histogram summary\n",
        "tf.summary.histogram(\"normal/moving_mean_two\", mean_moving_normal_two)\n",
        "\n",
        "# create a scalar variable\n",
        "moving_scalar = tf.get_variable('moving_scalar', shape=[], initializer=tf.truncated_normal_initializer(mean=0, stddev=1))\n",
        "\n",
        "moving_scalar = tf.add (moving_scalar, k)\n",
        "\n",
        "# create the scalar summary\n",
        "tf.summary.scalar(name='moving_scalar_summary', tensor=moving_scalar)\n",
        "\n",
        "summaries = tf.summary.merge_all()\n",
        "\n",
        "# Setup a session and summary writer\n",
        "with tf.Session() as sess:\n",
        "  for trial in range(2):\n",
        "    gfolder = LOG_DIR + '/trial_' + str(trial)\n",
        "    writer = tf.summary.FileWriter(gfolder, sess.graph)\n",
        "\n",
        "    # Initialise the scalar to some value\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Setup a loop and write the summaries to disk\n",
        "    N = 12\n",
        "    for step in range(N):\n",
        "      k_val = step/float(N)      \n",
        "      summ = sess.run(summaries, feed_dict={k: k_val})\n",
        "      writer.add_summary(summ, global_step=step)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "folder is  tbtry/trial_0\n",
            "scalar is  Tensor(\"Add:0\", dtype=float32)\n",
            "folder is  tbtry/trial_1\n",
            "scalar is  Tensor(\"Add:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCr--JdWXeNJ"
      },
      "source": [
        "### [Example](https://www.tensorflow.org/guide/tensorboard_histograms) of bi-modal distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PtxzxBoXlrG"
      },
      "source": [
        "tf.reset_default_graph()   # To clear the defined variables and operations of the previous cell\n",
        "\n",
        "k = tf.placeholder(tf.float32)\n",
        "\n",
        "# Make a normal distribution, with a shifting mean\n",
        "mean_moving_normal = tf.random_normal(shape=[1000], mean=(5*k), stddev=1)\n",
        "# Record that distribution into a histogram summary\n",
        "tf.summary.histogram(\"normal/moving_mean\", mean_moving_normal)\n",
        "\n",
        "# Make a normal distribution with shrinking variance\n",
        "variance_shrinking_normal = tf.random_normal(shape=[1000], mean=0, stddev=1-(k))\n",
        "# Record that distribution too\n",
        "tf.summary.histogram(\"normal/shrinking_variance\", variance_shrinking_normal)\n",
        "\n",
        "# Let's combine both of those distributions into one dataset\n",
        "normal_combined = tf.concat([mean_moving_normal, variance_shrinking_normal], 0)\n",
        "# We add another histogram summary to record the combined distribution\n",
        "tf.summary.histogram(\"normal/bimodal\", normal_combined)\n",
        "\n",
        "summaries = tf.summary.merge_all()\n",
        "\n",
        "# Setup a session and summary writer\n",
        "sess = tf.Session()\n",
        "writer = tf.summary.FileWriter(LOG_DIR)\n",
        "\n",
        "# Setup a loop and write the summaries to disk\n",
        "N = 12\n",
        "for step in range(N):\n",
        "  k_val = step/float(N)\n",
        "  summ = sess.run(summaries, feed_dict={k: k_val})\n",
        "  writer.add_summary(summ, global_step=step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGyIUvGrRMwE"
      },
      "source": [
        "!rm -r tbtry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXWkWjrfXU8p"
      },
      "source": [
        "### Set up Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzP27LL5cLAY"
      },
      "source": [
        "**To view Tensorboard output locally, use ngrok to tunnel traffic to localhost. First, download and unzip ngrok on the Colab server**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomVFMK8agNm"
      },
      "source": [
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx9TXX0acOZv"
      },
      "source": [
        "**Get TensorBoard running in the background**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTEsOw98bUY7"
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhztbwBnc_DL"
      },
      "source": [
        "**Launch ngrok background process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCkaIrwqbfzP"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BADzHi9dBh6"
      },
      "source": [
        "**We get the public URL where we can access the colab TensorBoard web page. This will output a URL you can click on**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC65XT9PbmyJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23de8d33-ea7c-4f7e-e1cb-a9762bf751af"
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://2536f14f.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}